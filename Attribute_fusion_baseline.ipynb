{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12b9db3c",
   "metadata": {},
   "source": [
    "## 地震属性融合：基线模型测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保src目录在Python路径中\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"  # 黑体 SimHei 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d3e60",
   "metadata": {},
   "source": [
    "## 全井震数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入处理好的井点数据\n",
    "file_well = \"data/well_processed.xlsx\"\n",
    "data_well = pd.read_excel(file_well)\n",
    "\n",
    "# 显示数据基本信息\n",
    "print(f\"数据形状: {data_well.shape}\")\n",
    "print(\"数据列名:\", data_well.columns.tolist())\n",
    "data_well.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2278e1b",
   "metadata": {},
   "source": [
    "## 分类函数（根据经验）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606936c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_lithofacies(sand_thickness, sand_ratio):\n",
    "    if sand_thickness <= 0.1:\n",
    "        return \"Mudstone\"\n",
    "    elif sand_ratio >= 70:\n",
    "        return \"Sandstone\"\n",
    "    elif sand_ratio <= 30:\n",
    "        return \"Mudstone\"\n",
    "    else:\n",
    "        return \"Interbedded\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cf4a9a",
   "metadata": {},
   "source": [
    "## 数据预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义列名映射（确保使用正确的列名）\n",
    "sand_thickness_col = data_well.columns[5]  # 第六列是砂厚\n",
    "sand_ratio_col = data_well.columns[6]  # 第七列是砂地比\n",
    "\n",
    "# 根据classify_lithofacies函数添加岩性标签\n",
    "data_well_processed = data_well.copy()\n",
    "data_well_processed[\"Lithofacies\"] = data_well_processed.apply(\n",
    "    lambda row: classify_lithofacies(row[sand_thickness_col], row[sand_ratio_col]), axis=1\n",
    ")\n",
    "\n",
    "# 创建数值标签映射\n",
    "lithofacies_mapping = {\"Mudstone\": 0, \"Sandstone\": 1, \"Interbedded\": 2}\n",
    "data_well_processed[\"Lithofacies_Code\"] = data_well_processed[\"Lithofacies\"].map(lithofacies_mapping)\n",
    "\n",
    "# 重命名列\n",
    "data_well_processed = data_well_processed.rename(\n",
    "    columns={\n",
    "        \"Thickness of facies(1: Fine sand)\": \"Sand Thickness\",\n",
    "        \"facies(1: Fine sand)\": \"Sand Ratio\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 显示前几行结果查看处理效果\n",
    "print(f\"处理后的数据形状: {data_well_processed.shape}\")\n",
    "\n",
    "# 将处理后的数据保存到output目录\n",
    "data_well_processed.to_csv(os.path.join(output_dir, \"processed_well_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_well_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec87eef9",
   "metadata": {},
   "source": [
    "## 基线模型测试：回归任务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfafa22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 读取处理好的数据\n",
    "unique_surfaces = data_well_processed[\"Surface\"].unique()\n",
    "\n",
    "# 初始化结果DataFrame\n",
    "results_columns = [\n",
    "    \"Surface\",\n",
    "    \"Target\",\n",
    "    \"Model\",\n",
    "    \"R2_mean\",\n",
    "    \"RMSE_mean\",\n",
    "    \"MAE_mean\",\n",
    "    \"Top_Features\",\n",
    "]\n",
    "results_df = pd.DataFrame(columns=results_columns)\n",
    "\n",
    "\n",
    "# 定义模型评估函数\n",
    "def evaluate_model(model, X, y, cv=5):\n",
    "    # 定义评估指标\n",
    "    scoring = {\n",
    "        \"r2\": \"r2\",\n",
    "        \"neg_rmse\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_mae\": \"neg_mean_absolute_error\",\n",
    "    }\n",
    "\n",
    "    # 执行交叉验证\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "    # 提取并转换结果\n",
    "    r2_mean = cv_results[\"test_r2\"].mean()\n",
    "    rmse_mean = -cv_results[\"test_neg_rmse\"].mean()\n",
    "    mae_mean = -cv_results[\"test_neg_mae\"].mean()\n",
    "\n",
    "    return r2_mean, rmse_mean, mae_mean\n",
    "\n",
    "\n",
    "# 定义特征重要性获取函数\n",
    "def get_top_features(X, rf_model, xgb_model, n_top=10):\n",
    "    # 获取随机森林特征重要性\n",
    "    rf_importance = rf_model.feature_importances_\n",
    "    rf_indices = np.argsort(rf_importance)[::-1]\n",
    "\n",
    "    # 获取XGBoost特征重要性\n",
    "    xgb_importance = xgb_model.feature_importances_\n",
    "    xgb_indices = np.argsort(xgb_importance)[::-1]\n",
    "\n",
    "    # 计算平均排名\n",
    "    feature_names = X.columns\n",
    "    rank_dict = {}\n",
    "\n",
    "    for i, feature_idx in enumerate(rf_indices):\n",
    "        feature_name = feature_names[feature_idx]\n",
    "        rank_dict[feature_name] = rank_dict.get(feature_name, 0) + i\n",
    "\n",
    "    for i, feature_idx in enumerate(xgb_indices):\n",
    "        feature_name = feature_names[feature_idx]\n",
    "        rank_dict[feature_name] = rank_dict.get(feature_name, 0) + i\n",
    "\n",
    "    # 根据平均排名排序并获取前N个特征\n",
    "    sorted_features = sorted(rank_dict.items(), key=lambda x: x[1])\n",
    "    top_features = [f[0] for f in sorted_features[:n_top]]\n",
    "\n",
    "    return top_features\n",
    "\n",
    "\n",
    "# 定义IQR方法移除离群值的函数\n",
    "def remove_outliers_iqr(df, column, factor=3.0):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "\n",
    "    # 返回处于范围内的值和离群值掩码\n",
    "    mask = (df[column] >= lower_bound) & (df[column] <= upper_bound)\n",
    "    return df[mask], ~mask\n",
    "\n",
    "\n",
    "# 修改交叉验证和索引处理的部分\n",
    "# 循环处理每个层位\n",
    "for surface in unique_surfaces:\n",
    "    print(f\"\\n处理层位: {surface}\")\n",
    "\n",
    "    # 提取当前层位的数据\n",
    "    surface_data = data_well_processed[data_well_processed[\"Surface\"] == surface].copy()\n",
    "    print(f\"该层位样本数: {len(surface_data)}\")\n",
    "\n",
    "    # 非特征列列表\n",
    "    non_feature_cols = [\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        \"Z\",\n",
    "        \"Surface\",\n",
    "        \"Well\",\n",
    "        \"Sand Thickness\",\n",
    "        \"Sand Ratio\",\n",
    "        \"Lithofacies\",\n",
    "        \"Lithofacies_Code\",\n",
    "    ]\n",
    "\n",
    "    # 计算每列的缺失值百分比\n",
    "    missing_percent = surface_data.isnull().mean() * 100\n",
    "\n",
    "    # 删除缺失值超过30%的列\n",
    "    cols_to_drop = missing_percent[missing_percent > 30].index.tolist()\n",
    "    surface_data = surface_data.drop(columns=[col for col in cols_to_drop if col not in non_feature_cols])\n",
    "    print(f\"删除了缺失值超过30%的列: {[col for col in cols_to_drop if col not in non_feature_cols]}\")\n",
    "\n",
    "    # 获取所有特征列\n",
    "    feature_cols = [col for col in surface_data.columns if col not in non_feature_cols]\n",
    "    print(f\"保留的特征数量: {len(feature_cols)}\")\n",
    "\n",
    "    # 对每个特征列处理离群值并填充缺失值\n",
    "    for col in feature_cols:\n",
    "        # 移除离群值\n",
    "        clean_data, outlier_mask = remove_outliers_iqr(surface_data, col)\n",
    "\n",
    "        # 计算清洗后数据的平均值\n",
    "        col_mean = clean_data[col].mean()\n",
    "\n",
    "        # 填充原始数据中的缺失值\n",
    "        surface_data[col].fillna(col_mean, inplace=True)\n",
    "\n",
    "        # 输出离群值信息\n",
    "        if outlier_mask.sum() > 0:\n",
    "            print(f\"特征 '{col}' 中发现 {outlier_mask.sum()} 个离群值，已使用平均值 {col_mean:.4f} 进行填充\")\n",
    "\n",
    "    # 确认没有缺失值\n",
    "    assert surface_data.isnull().sum().sum() == 0, \"数据中仍然存在缺失值!\"\n",
    "\n",
    "    # 对两个目标变量分别进行建模\n",
    "    for target in [\"Sand Thickness\", \"Sand Ratio\"]:\n",
    "        print(f\"\\n目标变量: {target}\")\n",
    "\n",
    "        # 准备特征和目标变量\n",
    "        X = surface_data[feature_cols]\n",
    "        y = surface_data[target]\n",
    "\n",
    "        # 基于岩性分为两类\n",
    "        class_a_mask = surface_data[\"Lithofacies_Code\"] == 0\n",
    "        class_b_mask = surface_data[\"Lithofacies_Code\"].isin([1, 2])\n",
    "\n",
    "        class_a_indices = np.where(class_a_mask)[0]\n",
    "        class_b_indices = np.where(class_b_mask)[0]\n",
    "\n",
    "        print(f\"泥岩(Lithofacies_Code=0)样本数: {len(class_a_indices)}\")\n",
    "        print(f\"非泥岩(Lithofacies_Code=1,2)样本数: {len(class_b_indices)}\")\n",
    "\n",
    "        # 创建标准K折交叉验证\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        # 确定是否能够进行分层交叉验证\n",
    "        if len(class_a_indices) >= 5 and len(class_b_indices) >= 5:\n",
    "            print(\"使用分层交叉验证（按岩性类别划分）\")\n",
    "\n",
    "            # 创建自定义交叉验证分割\n",
    "            train_indices_list = []\n",
    "            test_indices_list = []\n",
    "\n",
    "            # 对类别A进行K折划分\n",
    "            a_folds = list(kf.split(class_a_indices))\n",
    "\n",
    "            # 对类别B进行K折划分\n",
    "            b_folds = list(kf.split(class_b_indices))\n",
    "\n",
    "            # 确保折数匹配\n",
    "            n_folds = min(len(a_folds), len(b_folds))\n",
    "\n",
    "            for i in range(n_folds):\n",
    "                # 获取类别A的训练/测试索引\n",
    "                a_train_idx, a_test_idx = a_folds[i]\n",
    "                # 将索引映射到原始数据集中的实际位置\n",
    "                a_train = class_a_indices[a_train_idx]\n",
    "                a_test = class_a_indices[a_test_idx]\n",
    "\n",
    "                # 获取类别B的训练/测试索引\n",
    "                b_train_idx, b_test_idx = b_folds[i]\n",
    "                # 将索引映射到原始数据集中的实际位置\n",
    "                b_train = class_b_indices[b_train_idx]\n",
    "                b_test = class_b_indices[b_test_idx]\n",
    "\n",
    "                # 合并两类的训练和测试索引\n",
    "                train_indices = np.concatenate([a_train, b_train])\n",
    "                test_indices = np.concatenate([a_test, b_test])\n",
    "\n",
    "                train_indices_list.append(train_indices)\n",
    "                test_indices_list.append(test_indices)\n",
    "\n",
    "            # 使用自定义的交叉验证索引\n",
    "            cv_splits = [(train, test) for train, test in zip(train_indices_list, test_indices_list)]\n",
    "\n",
    "        else:\n",
    "            print(\"警告：某个岩性类别样本数不足5个，使用标准交叉验证\")\n",
    "            # 使用标准KFold直接生成划分\n",
    "            cv_splits = list(kf.split(X))\n",
    "\n",
    "        # 1. 随机森林模型训练与评估\n",
    "        rf_model = RandomForestRegressor(n_estimators=50, max_depth=3, min_samples_leaf=3, random_state=42)\n",
    "\n",
    "        r2_rf, rmse_rf, mae_rf = evaluate_model(rf_model, X, y, cv=cv_splits)\n",
    "        print(f\"随机森林 - R²: {r2_rf:.4f}, RMSE: {rmse_rf:.4f}, MAE: {mae_rf:.4f}\")\n",
    "\n",
    "        # 使用全部数据拟合随机森林模型以获取特征重要性\n",
    "        rf_model.fit(X, y)\n",
    "\n",
    "        # 2. XGBoost模型训练与评估\n",
    "        xgb_model = XGBRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.1,\n",
    "            min_child_weight=3,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        r2_xgb, rmse_xgb, mae_xgb = evaluate_model(xgb_model, X, y, cv=cv_splits)\n",
    "        print(f\"XGBoost - R²: {r2_xgb:.4f}, RMSE: {rmse_xgb:.4f}, MAE: {mae_xgb:.4f}\")\n",
    "\n",
    "        # 使用全部数据拟合XGBoost模型以获取特征重要性\n",
    "        xgb_model.fit(X, y)\n",
    "\n",
    "        # 获取Top 10特征\n",
    "        top_features = get_top_features(X, rf_model, xgb_model, n_top=5)\n",
    "        print(f\"Top 10特征: {top_features}\")\n",
    "\n",
    "        # 3. 使用Top 10特征训练SVR模型\n",
    "        X_top = X[top_features]\n",
    "\n",
    "        # 标准化特征\n",
    "        scaler = StandardScaler()\n",
    "        X_top_scaled = scaler.fit_transform(X_top)\n",
    "\n",
    "        # 设置SVR参数网格\n",
    "        param_grid = {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"epsilon\": [0.01, 0.1],\n",
    "            \"kernel\": [\"rbf\"],\n",
    "            \"gamma\": [\"scale\", 0.01, 0.1],\n",
    "        }\n",
    "\n",
    "        # 网格搜索\n",
    "        svr = SVR()\n",
    "        grid_search = GridSearchCV(svr, param_grid, cv=cv_splits, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "\n",
    "        grid_search.fit(X_top_scaled, y)\n",
    "        best_svr = grid_search.best_estimator_\n",
    "        print(f\"SVR最佳参数: {grid_search.best_params_}\")\n",
    "\n",
    "        # 使用最佳SVR模型进行评估\n",
    "        r2_svr, rmse_svr, mae_svr = evaluate_model(best_svr, X_top_scaled, y, cv=cv_splits)\n",
    "        print(f\"SVR(Top 10特征) - R²: {r2_svr:.4f}, RMSE: {rmse_svr:.4f}, MAE: {mae_svr:.4f}\")\n",
    "\n",
    "        # 将结果添加到结果DataFrame\n",
    "        for model_name, r2, rmse, mae in [\n",
    "            (\"RandomForest\", r2_rf, rmse_rf, mae_rf),\n",
    "            (\"XGBoost\", r2_xgb, rmse_xgb, mae_xgb),\n",
    "            (\"SVR_Top10\", r2_svr, rmse_svr, mae_svr),\n",
    "        ]:\n",
    "            results_df = pd.concat(\n",
    "                [\n",
    "                    results_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\n",
    "                            \"Surface\": [surface],\n",
    "                            \"Target\": [target],\n",
    "                            \"Model\": [model_name],\n",
    "                            \"R2_mean\": [r2],\n",
    "                            \"RMSE_mean\": [rmse],\n",
    "                            \"MAE_mean\": [mae],\n",
    "                            \"Top_Features\": [\",\".join(top_features)],\n",
    "                        }\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "# 保存结果\n",
    "results_file = os.path.join(output_dir, \"regression_results.csv\")\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\n结果已保存到: {results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9fe7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化模型性能对比 - 只展示R²指标\n",
    "plt.figure(figsize=(20, 8))  # 增加图表宽度以容纳多个层位\n",
    "\n",
    "# R²对比\n",
    "pivot_r2 = results_df.pivot_table(index=[\"Surface\", \"Target\"], columns=\"Model\", values=\"R2_mean\")\n",
    "pivot_r2.plot(kind=\"bar\", ax=plt.gca())\n",
    "plt.title(\"各模型R^2对比\", fontsize=14)\n",
    "plt.ylabel(\"R^2值\", fontsize=12)\n",
    "plt.xlabel(\"层位和目标变量\", fontsize=12)\n",
    "\n",
    "# 调整y轴范围以显示负值\n",
    "plt.ylim([-1, 1])  # 设置y轴范围，确保能显示负值\n",
    "\n",
    "# 添加水平线标记0值\n",
    "plt.axhline(y=0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
    "\n",
    "# 添加图例并调整位置\n",
    "plt.legend(title=\"模型\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "# 调整布局和标签\n",
    "plt.xticks(rotation=90)  # 旋转x轴标签以避免重叠\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存和显示\n",
    "plt.savefig(os.path.join(output_dir, \"r2_model_comparison.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35951f",
   "metadata": {},
   "source": [
    "## 基线模型测试：分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入分类所需的库\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 初始化分类结果DataFrame\n",
    "classification_results_columns = [\n",
    "    \"Surface\",\n",
    "    \"Model\",\n",
    "    \"Accuracy_mean\",\n",
    "    \"F1_macro_mean\",\n",
    "    \"Precision_macro_mean\",\n",
    "    \"Recall_macro_mean\",\n",
    "    \"Top_Features\",\n",
    "    \"Classes_Present\",  # 添加一列记录存在的类别\n",
    "]\n",
    "classification_results_df = pd.DataFrame(columns=classification_results_columns)\n",
    "\n",
    "\n",
    "# 定义分类模型评估函数\n",
    "def evaluate_classification_model(model, X, y, cv=5):\n",
    "    # 定义评估指标\n",
    "    scoring = {\n",
    "        \"accuracy\": \"accuracy\",\n",
    "        \"f1_macro\": \"f1_macro\",\n",
    "        \"precision_macro\": \"precision_macro\",\n",
    "        \"recall_macro\": \"recall_macro\",\n",
    "    }\n",
    "\n",
    "    # 执行交叉验证\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "\n",
    "    # 提取结果\n",
    "    accuracy_mean = cv_results[\"test_accuracy\"].mean()\n",
    "    f1_macro_mean = cv_results[\"test_f1_macro\"].mean()\n",
    "    precision_macro_mean = cv_results[\"test_precision_macro\"].mean()\n",
    "    recall_macro_mean = cv_results[\"test_recall_macro\"].mean()\n",
    "\n",
    "    return accuracy_mean, f1_macro_mean, precision_macro_mean, recall_macro_mean\n",
    "\n",
    "\n",
    "# 循环处理每个层位进行岩性分类\n",
    "print(\"\\n=============== 开始岩性分类任务 ===============\")\n",
    "\n",
    "for surface in unique_surfaces:\n",
    "    print(f\"\\n处理层位: {surface}\")\n",
    "\n",
    "    # 提取当前层位的数据\n",
    "    surface_data = data_well_processed[data_well_processed[\"Surface\"] == surface].copy()\n",
    "    print(f\"该层位样本数: {len(surface_data)}\")\n",
    "\n",
    "    # 检查类别分布\n",
    "    class_counts = surface_data[\"Lithofacies_Code\"].value_counts()\n",
    "    print(f\"岩性类别分布:\\n{class_counts}\")\n",
    "\n",
    "    # 记录存在的类别\n",
    "    classes_present = sorted(class_counts.index.tolist())\n",
    "    classes_present_str = \", \".join(map(str, classes_present))\n",
    "    print(f\"存在的类别: {classes_present_str}\")\n",
    "\n",
    "    # 检查是否所有类别都有至少2个样本\n",
    "    if len(class_counts) < 2 or any(count < 2 for count in class_counts.values):\n",
    "        print(f\"跳过层位 {surface}: 某些岩性类别样本数不足2个，无法进行分类\")\n",
    "        continue\n",
    "\n",
    "    # 非特征列列表\n",
    "    non_feature_cols = [\n",
    "        \"X\",\n",
    "        \"Y\",\n",
    "        \"Z\",\n",
    "        \"Surface\",\n",
    "        \"Well\",\n",
    "        \"Sand Thickness\",\n",
    "        \"Sand Ratio\",\n",
    "        \"Lithofacies\",\n",
    "        \"Lithofacies_Code\",\n",
    "    ]\n",
    "\n",
    "    # 计算每列的缺失值百分比\n",
    "    missing_percent = surface_data.isnull().mean() * 100\n",
    "\n",
    "    # 删除缺失值超过30%的列\n",
    "    cols_to_drop = missing_percent[missing_percent > 30].index.tolist()\n",
    "    surface_data = surface_data.drop(columns=[col for col in cols_to_drop if col not in non_feature_cols])\n",
    "    print(f\"删除了缺失值超过30%的列: {[col for col in cols_to_drop if col not in non_feature_cols]}\")\n",
    "\n",
    "    # 获取所有特征列\n",
    "    feature_cols = [col for col in surface_data.columns if col not in non_feature_cols]\n",
    "    print(f\"保留的特征数量: {len(feature_cols)}\")\n",
    "\n",
    "    # 对每个特征列处理离群值并填充缺失值\n",
    "    for col in feature_cols:\n",
    "        # 移除离群值\n",
    "        clean_data, outlier_mask = remove_outliers_iqr(surface_data, col)\n",
    "\n",
    "        # 计算清洗后数据的平均值\n",
    "        col_mean = clean_data[col].mean()\n",
    "\n",
    "        # 填充原始数据中的缺失值\n",
    "        surface_data[col].fillna(col_mean, inplace=True)\n",
    "\n",
    "        # 输出离群值信息\n",
    "        if outlier_mask.sum() > 0:\n",
    "            print(f\"特征 '{col}' 中发现 {outlier_mask.sum()} 个离群值，已使用平均值 {col_mean:.4f} 进行填充\")\n",
    "\n",
    "    # 确认没有缺失值\n",
    "    assert surface_data.isnull().sum().sum() == 0, \"数据中仍然存在缺失值!\"\n",
    "\n",
    "    # 准备特征和目标变量\n",
    "    X = surface_data[feature_cols]\n",
    "    y_original = surface_data[\"Lithofacies_Code\"]  # 保存原始标签\n",
    "\n",
    "    # 对标签进行重新编码，使其从0开始连续\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_original)\n",
    "\n",
    "    # 打印标签编码映射关系\n",
    "    print(f\"标签编码映射: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}\")\n",
    "\n",
    "    # 设置分层K折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_splits = list(skf.split(X, y))\n",
    "\n",
    "    # 1. 随机森林分类模型\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5, min_samples_leaf=2, class_weight=\"balanced\", random_state=42\n",
    "    )\n",
    "\n",
    "    accuracy_rf, f1_rf, precision_rf, recall_rf = evaluate_classification_model(rf_clf, X, y, cv=cv_splits)\n",
    "    print(\n",
    "        f\"随机森林 - 准确率: {accuracy_rf:.4f}, F1(宏平均): {f1_rf:.4f}, \"\n",
    "        f\"精确率: {precision_rf:.4f}, 召回率: {recall_rf:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 使用全部数据拟合随机森林模型以获取特征重要性\n",
    "    rf_clf.fit(X, y)\n",
    "\n",
    "    # 2. XGBoost分类模型 - 确保目标类别数量正确\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        scale_pos_weight=1,\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=len(np.unique(y)),  # 明确指定类别数量\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    accuracy_xgb, f1_xgb, precision_xgb, recall_xgb = evaluate_classification_model(xgb_clf, X, y, cv=cv_splits)\n",
    "    print(\n",
    "        f\"XGBoost - 准确率: {accuracy_xgb:.4f}, F1(宏平均): {f1_xgb:.4f}, \"\n",
    "        f\"精确率: {precision_xgb:.4f}, 召回率: {recall_xgb:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 使用全部数据拟合XGBoost模型以获取特征重要性\n",
    "    xgb_clf.fit(X, y)\n",
    "\n",
    "    # 获取Top 10特征\n",
    "    top_features = get_top_features(X, rf_clf, xgb_clf, n_top=5)\n",
    "    print(f\"Top 10特征: {top_features}\")\n",
    "\n",
    "    # 3. 使用Top 10特征训练SVM模型\n",
    "    X_top = X[top_features]\n",
    "\n",
    "    # 标准化特征\n",
    "    scaler = StandardScaler()\n",
    "    X_top_scaled = scaler.fit_transform(X_top)\n",
    "\n",
    "    # 设置SVC参数网格\n",
    "    param_grid = {\"C\": [0.1, 1, 10], \"gamma\": [\"scale\", 0.01, 0.1], \"kernel\": [\"rbf\"], \"class_weight\": [\"balanced\"]}\n",
    "\n",
    "    # 网格搜索\n",
    "    svc = SVC(probability=True)\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=cv_splits, scoring=\"f1_macro\", n_jobs=-1)\n",
    "\n",
    "    grid_search.fit(X_top_scaled, y)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    print(f\"SVC最佳参数: {grid_search.best_params_}\")\n",
    "\n",
    "    # 使用最佳SVC模型进行评估\n",
    "    accuracy_svc, f1_svc, precision_svc, recall_svc = evaluate_classification_model(\n",
    "        best_svc, X_top_scaled, y, cv=cv_splits\n",
    "    )\n",
    "    print(\n",
    "        f\"SVC(Top 10特征) - 准确率: {accuracy_svc:.4f}, F1(宏平均): {f1_svc:.4f}, \"\n",
    "        f\"精确率: {precision_svc:.4f}, 召回率: {recall_svc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # 将结果添加到结果DataFrame\n",
    "    for model_name, accuracy, f1, precision, recall in [\n",
    "        (\"RandomForest\", accuracy_rf, f1_rf, precision_rf, recall_rf),\n",
    "        (\"XGBoost\", accuracy_xgb, f1_xgb, precision_xgb, recall_xgb),\n",
    "        (\"SVC_Top10\", accuracy_svc, f1_svc, precision_svc, recall_svc),\n",
    "    ]:\n",
    "        classification_results_df = pd.concat(\n",
    "            [\n",
    "                classification_results_df,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Surface\": [surface],\n",
    "                        \"Model\": [model_name],\n",
    "                        \"Accuracy_mean\": [accuracy],\n",
    "                        \"F1_macro_mean\": [f1],\n",
    "                        \"Precision_macro_mean\": [precision],\n",
    "                        \"Recall_macro_mean\": [recall],\n",
    "                        \"Top_Features\": [\",\".join(top_features)],\n",
    "                        \"Classes_Present\": [classes_present_str],\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "# 保存分类结果\n",
    "classification_results_file = os.path.join(output_dir, \"classification_results.csv\")\n",
    "classification_results_df.to_csv(classification_results_file, index=False)\n",
    "print(f\"\\n分类结果已保存到: {classification_results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5923522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化分类模型性能对比\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# F1分数对比\n",
    "pivot_f1 = classification_results_df.pivot_table(index=[\"Surface\"], columns=\"Model\", values=\"F1_macro_mean\")\n",
    "pivot_f1.plot(kind=\"bar\", ax=plt.gca())\n",
    "plt.title(\"各模型F1分数对比\", fontsize=14)\n",
    "plt.ylabel(\"F1分数(宏平均)\", fontsize=12)\n",
    "plt.xlabel(\"层位\", fontsize=12)\n",
    "\n",
    "# 调整y轴范围\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# 添加水平线标记0.5值\n",
    "plt.axhline(y=0.5, color=\"gray\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "# 添加图例并调整位置\n",
    "plt.legend(title=\"模型\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "# 调整布局和标签\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存和显示\n",
    "plt.savefig(os.path.join(output_dir, \"f1_classification_comparison.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671e541",
   "metadata": {},
   "source": [
    "## H6-2 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ad426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")  # 确保src目录在Python路径中\n",
    "from data_utils import parse_petrel_file, preprocess_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "import os\n",
    "\n",
    "# 设置输出目录\n",
    "prediction_dir = os.path.join(output_dir, \"predictions\")\n",
    "if not os.path.exists(prediction_dir):\n",
    "    os.makedirs(prediction_dir)\n",
    "\n",
    "\n",
    "# 定义可视化函数\n",
    "def plot_prediction_map(x, y, z, values, title, filename, cmap=\"viridis\", vmin=None, vmax=None, classes=None):\n",
    "    \"\"\"\n",
    "    绘制预测结果的空间分布图\n",
    "\n",
    "    参数:\n",
    "        x, y, z: 坐标数组\n",
    "        values: 预测值数组\n",
    "        title: 图表标题\n",
    "        filename: 保存文件名\n",
    "        cmap: 颜色映射\n",
    "        vmin, vmax: 值的范围\n",
    "        classes: 分类任务的类别标签\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # 对于分类结果使用离散颜色映射\n",
    "    if classes is not None:\n",
    "        # 创建离散颜色映射\n",
    "        n_classes = len(classes)\n",
    "        if n_classes <= 3:  # 对于我们的3类问题\n",
    "            colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]  # 蓝色、橙色、绿色\n",
    "            cmap = ListedColormap(colors[:n_classes])\n",
    "        else:\n",
    "            cmap = plt.cm.get_cmap(\"tab10\", n_classes)\n",
    "\n",
    "        scatter = plt.scatter(x, y, c=values, cmap=cmap, s=10, alpha=0.7)\n",
    "\n",
    "        # 添加图例\n",
    "        handles = [\n",
    "            plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=cmap(i), markersize=8, label=classes[i])\n",
    "            for i in range(n_classes)\n",
    "        ]\n",
    "        plt.legend(handles=handles, title=\"岩性\", loc=\"upper right\")\n",
    "\n",
    "    else:  # 对于回归结果使用连续颜色映射\n",
    "        scatter = plt.scatter(x, y, c=values, cmap=cmap, s=10, alpha=0.7, vmin=vmin, vmax=vmax)\n",
    "        plt.colorbar(scatter, label=title)\n",
    "\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"X坐标\", fontsize=12)\n",
    "    plt.ylabel(\"Y坐标\", fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图像\n",
    "    plt.savefig(os.path.join(prediction_dir, filename), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 1. 加载H6-2的地震数据\n",
    "print(\"正在加载H6-2地震属性数据...\")\n",
    "seismic_file = \"data/H6-2_attr\"\n",
    "seismic_data = parse_petrel_file(seismic_file)\n",
    "\n",
    "if seismic_data is None:\n",
    "    raise ValueError(\"无法解析地震属性文件\")\n",
    "\n",
    "print(f\"地震数据形状: {seismic_data.shape}\")\n",
    "print(f\"地震数据列: {seismic_data.columns.tolist()}\")\n",
    "\n",
    "# 2. 加载H6-2层的训练数据和模型\n",
    "print(\"\\n加载H6-2层的训练数据...\")\n",
    "h6_2_data = data_well_processed[data_well_processed[\"Surface\"] == \"H6-2\"].copy()\n",
    "print(f\"H6-2训练数据样本数: {len(h6_2_data)}\")\n",
    "\n",
    "# 3. 准备预测特征\n",
    "print(\"\\n准备预测特征...\")\n",
    "# 非特征列列表\n",
    "non_feature_cols = [\"X\", \"Y\", \"Z\", \"Surface\", \"Well\", \"Sand Thickness\", \"Sand Ratio\", \"Lithofacies\", \"Lithofacies_Code\"]\n",
    "\n",
    "# 获取训练集中使用的特征列\n",
    "feature_cols = [col for col in h6_2_data.columns if col not in non_feature_cols]\n",
    "print(f\"特征数量: {len(feature_cols)}\")\n",
    "\n",
    "# 对地震数据进行预处理\n",
    "# 首先找出地震数据中与训练数据对应的特征列\n",
    "seismic_feature_cols = []\n",
    "for col in feature_cols:\n",
    "    if col in seismic_data.columns:\n",
    "        seismic_feature_cols.append(col)\n",
    "    else:\n",
    "        print(f\"警告: 特征 '{col}' 在地震数据中不存在\")\n",
    "\n",
    "print(f\"地震数据中可用特征: {len(seismic_feature_cols)}\")\n",
    "\n",
    "# 4. 使用训练好的模型进行预测\n",
    "# 提取坐标和特征\n",
    "X_coords = seismic_data[\"X\"].values\n",
    "Y_coords = seismic_data[\"Y\"].values\n",
    "Z_coords = seismic_data[\"Z\"].values\n",
    "\n",
    "# 确保没有缺失值\n",
    "seismic_features = seismic_data[seismic_feature_cols].copy()\n",
    "for col in seismic_feature_cols:\n",
    "    if seismic_features[col].isnull().any():\n",
    "        mean_val = seismic_features[col].mean()\n",
    "        seismic_features[col] = seismic_features[col].fillna(mean_val)\n",
    "        print(f\"特征 '{col}' 中的缺失值已填充为均值: {mean_val:.4f}\")\n",
    "\n",
    "print(\"\\n开始进行预测...\")\n",
    "\n",
    "# 5. 砂厚预测 (Sand Thickness)\n",
    "print(\"\\n预测砂厚...\")\n",
    "\n",
    "# 训练随机森林模型 (使用所有H6-2的数据)\n",
    "X_train = h6_2_data[seismic_feature_cols]\n",
    "y_sand_thickness = h6_2_data[\"Sand Thickness\"]\n",
    "\n",
    "# 清理训练数据中的任何缺失值\n",
    "for col in seismic_feature_cols:\n",
    "    if X_train[col].isnull().any():\n",
    "        mean_val = X_train[col].mean()\n",
    "        X_train[col] = X_train[col].fillna(mean_val)\n",
    "\n",
    "# 训练砂厚预测模型\n",
    "rf_sand_thickness = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=2, random_state=42)\n",
    "rf_sand_thickness.fit(X_train, y_sand_thickness)\n",
    "\n",
    "# 预测砂厚\n",
    "sand_thickness_pred = rf_sand_thickness.predict(seismic_features)\n",
    "print(f\"砂厚预测范围: {sand_thickness_pred.min():.4f} - {sand_thickness_pred.max():.4f}\")\n",
    "\n",
    "# 可视化砂厚预测结果\n",
    "plot_prediction_map(\n",
    "    X_coords,\n",
    "    Y_coords,\n",
    "    Z_coords,\n",
    "    sand_thickness_pred,\n",
    "    \"H6-2层砂厚预测 (m)\",\n",
    "    \"H6-2_sand_thickness_prediction.png\",\n",
    "    cmap=\"plasma\",\n",
    "    vmin=0,\n",
    "    vmax=max(sand_thickness_pred.max(), y_sand_thickness.max()) * 1.1,\n",
    ")\n",
    "\n",
    "# 6. 砂地比预测 (Sand Ratio)\n",
    "print(\"\\n预测砂地比...\")\n",
    "\n",
    "# 训练砂地比预测模型\n",
    "y_sand_ratio = h6_2_data[\"Sand Ratio\"]\n",
    "rf_sand_ratio = RandomForestRegressor(n_estimators=100, max_depth=5, min_samples_leaf=2, random_state=42)\n",
    "rf_sand_ratio.fit(X_train, y_sand_ratio)\n",
    "\n",
    "# 预测砂地比\n",
    "sand_ratio_pred = rf_sand_ratio.predict(seismic_features)\n",
    "print(f\"砂地比预测范围: {sand_ratio_pred.min():.4f} - {sand_ratio_pred.max():.4f}\")\n",
    "\n",
    "# 确保预测值在有效范围内 (0-100%)\n",
    "sand_ratio_pred = np.clip(sand_ratio_pred, 0, 100)\n",
    "\n",
    "# 可视化砂地比预测结果\n",
    "plot_prediction_map(\n",
    "    X_coords,\n",
    "    Y_coords,\n",
    "    Z_coords,\n",
    "    sand_ratio_pred,\n",
    "    \"H6-2层砂地比预测 (%)\",\n",
    "    \"H6-2_sand_ratio_prediction.png\",\n",
    "    cmap=\"YlOrBr\",\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    ")\n",
    "\n",
    "# 7. 岩相预测\n",
    "print(\"\\n预测岩相...\")\n",
    "\n",
    "# 训练岩相分类模型\n",
    "y_lithofacies = h6_2_data[\"Lithofacies_Code\"]\n",
    "rf_lithofacies = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=5, min_samples_leaf=2, class_weight=\"balanced\", random_state=42\n",
    ")\n",
    "rf_lithofacies.fit(X_train, y_lithofacies)\n",
    "\n",
    "# 预测岩相\n",
    "lithofacies_pred = rf_lithofacies.predict(seismic_features)\n",
    "lithofacies_prob = rf_lithofacies.predict_proba(seismic_features)\n",
    "\n",
    "# 统计预测的岩性分布\n",
    "unique_lithofacies, counts = np.unique(lithofacies_pred, return_counts=True)\n",
    "print(\"岩性预测分布:\")\n",
    "for lith, count in zip(unique_lithofacies, counts):\n",
    "    lithofacies_name = \"未知\"\n",
    "    if lith == 0:\n",
    "        lithofacies_name = \"泥岩\"\n",
    "    elif lith == 1:\n",
    "        lithofacies_name = \"砂岩\"\n",
    "    elif lith == 2:\n",
    "        lithofacies_name = \"砂泥互层\"\n",
    "\n",
    "    percentage = count / len(lithofacies_pred) * 100\n",
    "    print(f\"  - {lithofacies_name} (编码 {lith}): {count} 个点 ({percentage:.2f}%)\")\n",
    "\n",
    "# 可视化岩相预测结果\n",
    "lithofacies_names = [\"泥岩\", \"砂岩\", \"砂泥互层\"]\n",
    "plot_prediction_map(\n",
    "    X_coords,\n",
    "    Y_coords,\n",
    "    Z_coords,\n",
    "    lithofacies_pred,\n",
    "    \"H6-2层岩相预测\",\n",
    "    \"H6-2_lithofacies_prediction.png\",\n",
    "    classes=lithofacies_names,\n",
    ")\n",
    "\n",
    "# 8. 将预测结果合并到DataFrame并保存\n",
    "prediction_df = pd.DataFrame(\n",
    "    {\n",
    "        \"X\": X_coords,\n",
    "        \"Y\": Y_coords,\n",
    "        \"Z\": Z_coords,\n",
    "        \"Sand_Thickness_Pred\": sand_thickness_pred,\n",
    "        \"Sand_Ratio_Pred\": sand_ratio_pred,\n",
    "        \"Lithofacies_Pred\": lithofacies_pred,\n",
    "    }\n",
    ")\n",
    "\n",
    "# 添加岩相概率列\n",
    "for i, name in enumerate(lithofacies_names):\n",
    "    if i < lithofacies_prob.shape[1]:  # 确保概率矩阵有足够的列\n",
    "        prediction_df[f\"{name}_Prob\"] = lithofacies_prob[:, i]\n",
    "\n",
    "# 保存预测结果\n",
    "prediction_file = os.path.join(prediction_dir, \"H6-2_predictions.csv\")\n",
    "prediction_df.to_csv(prediction_file, index=False)\n",
    "print(f\"\\n预测结果已保存到: {prediction_file}\")\n",
    "\n",
    "# 9. 生成砂厚和砂地比的联合图\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# 创建两个子图\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_coords, Y_coords, c=sand_thickness_pred, cmap=\"viridis\", s=10, alpha=0.7)\n",
    "plt.colorbar(label=\"砂厚 (m)\")\n",
    "plt.title(\"H6-2层砂厚预测\", fontsize=14)\n",
    "plt.xlabel(\"X坐标\", fontsize=12)\n",
    "plt.ylabel(\"Y坐标\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_coords, Y_coords, c=sand_ratio_pred, cmap=\"viridis\", s=10, alpha=0.7, vmin=0, vmax=100)\n",
    "plt.colorbar(label=\"砂地比 (%)\")\n",
    "plt.title(\"H6-2层砂地比预测\", fontsize=14)\n",
    "plt.xlabel(\"X坐标\", fontsize=12)\n",
    "plt.ylabel(\"Y坐标\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(prediction_dir, \"H6-2_combined_predictions.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# 10. 砂厚与砂地比的散点关系图\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(\n",
    "    sand_thickness_pred,\n",
    "    sand_ratio_pred,\n",
    "    c=lithofacies_pred,\n",
    "    cmap=ListedColormap([\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"]),\n",
    "    s=10,\n",
    "    alpha=0.6,\n",
    ")\n",
    "\n",
    "# 添加图例\n",
    "handles = [\n",
    "    plt.Line2D([0], [0], marker=\"o\", color=\"w\", markerfacecolor=c, markersize=8, label=l)\n",
    "    for c, l in zip([\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"], lithofacies_names)\n",
    "]\n",
    "plt.legend(handles=handles, title=\"岩性\", loc=\"upper left\")\n",
    "\n",
    "plt.title(\"H6-2层砂厚与砂地比关系图\", fontsize=14)\n",
    "plt.xlabel(\"砂厚 (m)\", fontsize=12)\n",
    "plt.ylabel(\"砂地比 (%)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(prediction_dir, \"H6-2_thickness_ratio_relationship.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nH6-2层预测与可视化完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-af",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
