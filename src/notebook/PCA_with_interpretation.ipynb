{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5992e30",
   "metadata": {},
   "source": [
    "# PCA + 根据现有井点进行聚类解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保src目录在Python路径中\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "\n",
    "# 导入模块\n",
    "from src.data_utils import (\n",
    "    extract_seismic_attributes_for_wells,\n",
    "    extract_uniform_seismic_samples,\n",
    "    filter_anomalous_attributes,\n",
    "    filter_outlier_wells,\n",
    "    filter_seismic_by_wells,\n",
    "    identify_attributes,\n",
    "    parse_petrel_file,\n",
    "    preprocess_features,\n",
    ")\n",
    "from src.gmm_clustering import evaluate_gmm_clusters, perform_gmm_clustering\n",
    "from src.pca_analysis import perform_pca_analysis\n",
    "from src.sigmoid import SigmoidModel\n",
    "from src.visualization import (\n",
    "    visualize_attribute_map,\n",
    "    visualize_feature_distribution,\n",
    "    visualize_gmm_clustering,\n",
    "    visualize_pca_clustering,\n",
    ")\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"  # 黑体 SimHei 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 层位配置 ====================\n",
    "# 修改这里可以更换不同的层位\n",
    "SURFACE_NAME = \"H6-2\"  # 例如: \"H2-4\", \"H5-1\", \"H6-2\"等\n",
    "# ================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0806e0aa",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58afd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据层位名称生成相关路径和配置\n",
    "data_dir = \"../../data\"\n",
    "data_tmp_dir = \"data_tmp\"\n",
    "output_dir = f\"{SURFACE_NAME.replace('-', '_')}_ps_output\"  # H2-4 -> H2_4_ps_output\n",
    "\n",
    "# 创建目录\n",
    "if not os.path.exists(data_tmp_dir):\n",
    "    os.makedirs(data_tmp_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(f\"当前处理层位: {SURFACE_NAME}\")\n",
    "print(f\"输出目录: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f36e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入地震数据\n",
    "data_seismic_url = os.path.join(data_dir, SURFACE_NAME)\n",
    "print(f\"地震数据路径: {data_seismic_url}\")\n",
    "\n",
    "data_seismic_attr = parse_petrel_file(data_seismic_url)\n",
    "\n",
    "# 导入井点位置\n",
    "data_well_position = pd.read_excel(os.path.join(data_dir, \"well_without_attr.xlsx\"))\n",
    "\n",
    "# 选择对应层位的行，丢弃砂厚为 NaN 的行\n",
    "data_well_purpose_surface_position = (\n",
    "    data_well_position[data_well_position[\"Surface\"] == SURFACE_NAME]\n",
    "    .replace(-999, np.nan)  # 将-999替换为NaN\n",
    "    .dropna(subset=[\"Sand Thickness\"])  # 丢弃砂厚为NaN的行\n",
    "    .reset_index(drop=True)  # 重置索引\n",
    ")\n",
    "\n",
    "print(f\"层位 {SURFACE_NAME} 的井点数量: {len(data_well_purpose_surface_position)}\")\n",
    "data_well_purpose_surface_position.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13b836",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0749d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先获取地震属性列表\n",
    "attribute_names, _ = identify_attributes(data_seismic_url)\n",
    "\n",
    "processed_features, stats, report = preprocess_features(\n",
    "    data=data_seismic_attr,\n",
    "    attribute_columns=attribute_names,\n",
    "    missing_values=[-999],\n",
    "    missing_threshold=0.6,\n",
    "    outlier_method=\"iqr\",\n",
    "    outlier_threshold=2.0,\n",
    "    outlier_treatment=\"clip\",  # 边界截断\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 提取筛选后的属性\n",
    "attribute_names_processed = [col for col in processed_features.columns]\n",
    "\n",
    "# 将处理后的属性数据与原始坐标数据合并\n",
    "data_seismic_attr_processed = data_seismic_attr[[\"X\", \"Y\"]].copy()  # type: ignore\n",
    "for col in processed_features.columns:\n",
    "    data_seismic_attr_processed[col] = processed_features[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为筛选后的井点提取地震属性\n",
    "data_well_attr = extract_seismic_attributes_for_wells(\n",
    "    well_data=data_well_purpose_surface_position,\n",
    "    seismic_data=data_seismic_attr_processed,\n",
    "    max_distance=50,\n",
    "    num_points=5,\n",
    ")\n",
    "\n",
    "# 保存处理结果\n",
    "data_well_attr.to_excel(os.path.join(data_tmp_dir, f\"{SURFACE_NAME.replace('-', '_')}_wells_attr.xlsx\"), index=False)\n",
    "print(\"筛选后井点的地震属性已保存到 {data_tmp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859fec81",
   "metadata": {},
   "source": [
    "## PCA 降维，PC1 作为融合属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30df613",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = perform_pca_analysis(\n",
    "    data=data_seismic_attr_processed,\n",
    "    attribute_columns=attribute_names_processed,\n",
    "    variance_threshold=0.8,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319de09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化所有主成分在地理空间的分布\n",
    "print(\"\\n可视化主成分分布...\")\n",
    "\n",
    "# 创建包含主成分的新数据框\n",
    "data_seismic_attr_with_PC = data_seismic_attr_processed.copy()\n",
    "\n",
    "# 添加所有主成分列到地震数据中\n",
    "n_components = pca_results[\"features_pca\"].shape[1]\n",
    "for i in range(n_components):\n",
    "    pc_data = pca_results[\"features_pca\"][:, i]  # 第i个主成分\n",
    "    data_seismic_attr_with_PC[f\"PC{i + 1}\"] = pc_data\n",
    "\n",
    "print(f\"添加主成分后数据形状: {data_seismic_attr_with_PC.shape}\")\n",
    "print(f\"新增列: {[col for col in data_seismic_attr_with_PC.columns if col.startswith('PC')]}\")\n",
    "print(f\"总共添加了 {n_components} 个主成分\")\n",
    "\n",
    "# 定义不同主成分使用的色彩图谱，确保视觉区分\n",
    "colormaps = [\"viridis\", \"plasma\", \"inferno\", \"magma\", \"cividis\", \"turbo\", \"coolwarm\", \"seismic\", \"RdYlBu\", \"Spectral\"]\n",
    "\n",
    "# 循环可视化所有主成分\n",
    "for i in range(n_components):\n",
    "    pc_name = f\"PC{i + 1}\"\n",
    "    print(f\"\\n可视化 {pc_name} 分布...\")\n",
    "\n",
    "    # 选择色彩图谱（循环使用）\n",
    "    cmap = colormaps[i % len(colormaps)]\n",
    "\n",
    "    # 计算该主成分的数值范围\n",
    "    pc_min = data_seismic_attr_with_PC[pc_name].min()\n",
    "    pc_max = data_seismic_attr_with_PC[pc_name].max()\n",
    "    pc_range = pc_max - pc_min\n",
    "\n",
    "    # 设置合适的色彩范围（可以根据数据分布调整）\n",
    "    if pc_range > 0:\n",
    "        # 使用数据的95%分位数范围，避免极值影响可视化效果\n",
    "        pc_5th = data_seismic_attr_with_PC[pc_name].quantile(0.05)\n",
    "        pc_95th = data_seismic_attr_with_PC[pc_name].quantile(0.95)\n",
    "        vrange = (pc_5th, pc_95th)\n",
    "    else:\n",
    "        vrange = None\n",
    "\n",
    "    # 可视化该主成分的空间分布\n",
    "    visualize_attribute_map(\n",
    "        data_points=data_seismic_attr_with_PC,\n",
    "        attribute_name=pc_name,  # 要可视化的属性列名\n",
    "        attribute_label=f\"第{i + 1}主成分 ({pc_name})\",  # 在图例和颜色条中的显示名称\n",
    "        real_wells=data_well_purpose_surface_position,  # 真实井点数据\n",
    "        pseudo_wells=None,  # 暂时没有虚拟井点\n",
    "        target_column=\"Sand Thickness\",  # 井点的目标列\n",
    "        output_dir=output_dir,\n",
    "        filename_prefix=f\"pc{i + 1}\",  # 输出文件前缀\n",
    "        class_thresholds=[1, 13.75],  # 砂厚分类阈值\n",
    "        figsize=(14, 12),\n",
    "        dpi=300,\n",
    "        cmap=cmap,  # 使用不同的色彩图区分不同主成分\n",
    "        point_size=10,  # 地震数据点大小\n",
    "        well_size=50,  # 井点标记大小\n",
    "        vrange=vrange,  # 使用计算得到的合适范围\n",
    "    )\n",
    "\n",
    "    # 打印该主成分的统计信息\n",
    "    print(f\"  {pc_name} 值范围: {pc_min:.4f} 到 {pc_max:.4f}\")\n",
    "    print(f\"  {pc_name} 均值: {data_seismic_attr_with_PC[pc_name].mean():.4f}\")\n",
    "    print(f\"  {pc_name} 标准差: {data_seismic_attr_with_PC[pc_name].std():.4f}\")\n",
    "\n",
    "    # 显示该主成分的解释方差比\n",
    "    explained_variance = pca_results[\"explained_variance_ratio\"][i]\n",
    "    cumulative_variance = pca_results[\"explained_variance_ratio_cumsum\"][i]\n",
    "    print(f\"  {pc_name} 解释方差比: {explained_variance:.4f} ({explained_variance * 100:.2f}%)\")\n",
    "    print(f\"  累积解释方差比: {cumulative_variance:.4f} ({cumulative_variance * 100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n=== 主成分可视化完成 ===\")\n",
    "print(f\"输出目录: {output_dir}\")\n",
    "print(f\"完整数据变量: data_seismic_attr_with_PC (包含原始属性+所有主成分)\")\n",
    "print(f\"数据形状: {data_seismic_attr_with_PC.shape}\")\n",
    "print(f\"主成分列: {[col for col in data_seismic_attr_with_PC.columns if col.startswith('PC')]}\")\n",
    "\n",
    "# 显示主成分贡献度摘要\n",
    "print(f\"\\n=== 主成分贡献度摘要 ===\")\n",
    "for i in range(n_components):\n",
    "    pc_name = f\"PC{i + 1}\"\n",
    "    explained_var = pca_results[\"explained_variance_ratio\"][i]\n",
    "    cumulative_var = pca_results[\"explained_variance_ratio_cumsum\"][i]\n",
    "    print(\n",
    "        f\"{pc_name}: 解释方差 {explained_var:.3f} ({explained_var * 100:.1f}%), 累积 {cumulative_var:.3f} ({cumulative_var * 100:.1f}%)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b470ea",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f7624",
   "metadata": {},
   "source": [
    "## 在井控区进行 GMM 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f08240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选离群井\n",
    "data_well_attr_filtered = filter_outlier_wells(data_well_attr, method=\"iqr\")\n",
    "\n",
    "# 显示筛选前后的井点数量\n",
    "print(f\"筛选前井点数量: {len(data_well_attr)}\")\n",
    "print(f\"筛选后井点数量: {len(data_well_attr_filtered)}\")\n",
    "\n",
    "# 可视化筛选前后的井点分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 计算坐标范围（使用所有井点的数据来确定范围）\n",
    "x_min = data_well_attr[\"X\"].min()\n",
    "x_max = data_well_attr[\"X\"].max()\n",
    "y_min = data_well_attr[\"Y\"].min()\n",
    "y_max = data_well_attr[\"Y\"].max()\n",
    "\n",
    "# 可选：添加一些边距使图更美观\n",
    "margin = 0.05  # 5%的边距\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "x_min -= x_range * margin\n",
    "x_max += x_range * margin\n",
    "y_min -= y_range * margin\n",
    "y_max += y_range * margin\n",
    "\n",
    "# 绘制筛选前的井点分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data_well_attr[\"X\"], data_well_attr[\"Y\"], c=\"blue\")\n",
    "plt.title(\"筛选前井点分布\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "# 绘制筛选后的井点分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(data_well_attr_filtered[\"X\"], data_well_attr_filtered[\"Y\"], c=\"red\")\n",
    "plt.title(\"筛选后井点分布\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"well_filtering_comparison.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限制工区范围\n",
    "data_seismic_attr_with_PC_filtered, area_bounds = filter_seismic_by_wells(\n",
    "    seismic_data=data_seismic_attr_with_PC,\n",
    "    well_data=data_well_attr_filtered,\n",
    "    expansion_factor=2,  # 扩展100%\n",
    "    plot=True,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "\n",
    "# 后续可以直接使用area_bounds中的边界信息\n",
    "print(\"区域边界信息:\")\n",
    "for key, value in area_bounds.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认只使用PC1和PC2进行聚类评估\n",
    "\n",
    "# 提取用于聚类的特征\n",
    "clustering_features = data_seismic_attr_with_PC_filtered[[\"PC1\", \"PC2\"]].values\n",
    "\n",
    "# 提取井控区的地震坐标\n",
    "data_seismic_attr_with_PC_filtered_coords = data_seismic_attr_with_PC_filtered[[\"X\", \"Y\"]]\n",
    "\n",
    "# 评估聚类数\n",
    "gmm_evaluation = evaluate_gmm_clusters(\n",
    "    features_for_clustering=clustering_features, max_clusters=4, output_dir=output_dir\n",
    ")\n",
    "\n",
    "# 获取推荐的聚类数\n",
    "best_n = gmm_evaluation[\"best_n_components\"]\n",
    "print(f\"推荐使用 {best_n} 个聚类\")\n",
    "\n",
    "# 执行GMM聚类\n",
    "gmm_results = perform_gmm_clustering(\n",
    "    features=clustering_features,\n",
    "    coords=data_seismic_attr_with_PC_filtered_coords,\n",
    "    n_clusters=best_n,\n",
    ")\n",
    "gmm_results[\"result_df\"].to_csv(os.path.join(output_dir, \"gmm_best_clusters.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834378bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PCA可视化，需要将井点数据投影到PCA空间\n",
    "# 首先提取井点的属性列\n",
    "data_well_attr_filtered_features = data_well_attr_filtered[attribute_names_processed].values\n",
    "# 使用相同的标准化器和PCA模型变换井点数据\n",
    "data_well_attr_filtered_features_scaled = pca_results[\"scaler\"].transform(data_well_attr_filtered_features)\n",
    "data_well_attr_filtered_pca_features = pca_results[\"pca\"].transform(data_well_attr_filtered_features_scaled)\n",
    "\n",
    "# 2. 在PCA空间中可视化聚类结果\n",
    "visualize_pca_clustering(\n",
    "    features_pca=clustering_features,\n",
    "    cluster_labels=gmm_results[\"cluster_labels\"],\n",
    "    n_clusters=best_n,\n",
    "    output_dir=output_dir,\n",
    "    well_data=data_well_attr_filtered,\n",
    "    well_pca_features=data_well_attr_filtered_pca_features,\n",
    "    target_column=\"Sand Thickness\",\n",
    "    class_thresholds=[1, 13.75],\n",
    ")\n",
    "\n",
    "# 3. 在地理空间中可视化聚类结果\n",
    "visualize_gmm_clustering(\n",
    "    clustering_results=gmm_results,\n",
    "    output_dir=output_dir,\n",
    "    prefix=\"pca\",\n",
    "    well_data=data_well_attr_filtered,\n",
    "    target_column=\"Sand Thickness\",\n",
    "    class_thresholds=[1, 13.75],\n",
    "    point_size=100,\n",
    "    well_size=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75576ee",
   "metadata": {},
   "source": [
    "## 结果分析与解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA载荷解释分析\n",
    "print(\"======== PCA载荷解释分析 ========\")\n",
    "\n",
    "# 定义属性解释映射\n",
    "attribute_interpretations = {\n",
    "    \"Maximum amplitude\": {\n",
    "        \"high_positive\": \"强波峰\",\n",
    "        \"near_zero\": \"与波峰强度无关\",\n",
    "        \"high_negative\": \"弱波峰\",\n",
    "    },\n",
    "    \"Maximum amplitude-dq\": {\n",
    "        \"high_positive\": \"强波峰\",\n",
    "        \"near_zero\": \"与波峰强度无关\",\n",
    "        \"high_negative\": \"弱波峰\",\n",
    "    },\n",
    "    \"Minimum amplitude\": {\n",
    "        \"high_positive\": \"弱波谷\",\n",
    "        \"near_zero\": \"与波谷强度无关\",\n",
    "        \"high_negative\": \"强波谷\",\n",
    "    },\n",
    "    \"Minimum amplitude-dq\": {\n",
    "        \"high_positive\": \"弱波谷\",\n",
    "        \"near_zero\": \"与波谷强度无关\",\n",
    "        \"high_negative\": \"强波谷\",\n",
    "    },\n",
    "    \"RMS amplitude\": {\"high_positive\": \"强能量\", \"near_zero\": \"与能量无关\", \"high_negative\": \"弱能量\"},\n",
    "    \"RMS amplitude-dq\": {\"high_positive\": \"强能量\", \"near_zero\": \"与能量无关\", \"high_negative\": \"弱能量\"},\n",
    "    \"Sum of energy\": {\"high_positive\": \"强能量\", \"near_zero\": \"与能量无关\", \"high_negative\": \"弱能量\"},\n",
    "    \"Sum of energy-dq\": {\"high_positive\": \"强能量\", \"near_zero\": \"与能量无关\", \"high_negative\": \"弱能量\"},\n",
    "    \"Harmonic mean-ge\": {\n",
    "        \"high_positive\": \"强遗传反演数值\",\n",
    "        \"near_zero\": \"与遗传反演数值无关\",\n",
    "        \"high_negative\": \"弱遗传反演数值\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def get_loading_category(loading_value, threshold=0.3):\n",
    "    \"\"\"根据载荷值返回类别\"\"\"\n",
    "    if loading_value > threshold:\n",
    "        return \"high_positive\"\n",
    "    elif loading_value < -threshold:\n",
    "        return \"high_negative\"\n",
    "    else:\n",
    "        return \"near_zero\"\n",
    "\n",
    "\n",
    "def resolve_conflicts(loadings_dict, attr_interpretations):\n",
    "    \"\"\"解决冲突的载荷解释\"\"\"\n",
    "    resolved_interpretations = {}\n",
    "\n",
    "    # 处理叠前叠后冲突\n",
    "    pre_post_pairs = [\n",
    "        (\"Maximum amplitude\", \"Maximum amplitude-dq\"),\n",
    "        (\"Minimum amplitude\", \"Minimum amplitude-dq\"),\n",
    "        (\"RMS amplitude\", \"RMS amplitude-dq\"),\n",
    "        (\"Sum of energy\", \"Sum of energy-dq\"),\n",
    "    ]\n",
    "\n",
    "    # 处理能量属性冲突 - 修改为四元组，处理所有可能的能量属性组合\n",
    "    energy_groups = [[\"RMS amplitude\", \"RMS amplitude-dq\", \"Sum of energy\", \"Sum of energy-dq\"]]\n",
    "\n",
    "    used_attributes = set()\n",
    "\n",
    "    # 先处理能量属性冲突（优先级更高）\n",
    "    for energy_group in energy_groups:\n",
    "        available_energy_attrs = {attr: loadings_dict[attr] for attr in energy_group if attr in loadings_dict}\n",
    "\n",
    "        if len(available_energy_attrs) > 1:  # 如果有多个能量属性\n",
    "            # 选择载荷绝对值最大的\n",
    "            selected_attr = max(available_energy_attrs.keys(), key=lambda x: abs(available_energy_attrs[x]))\n",
    "            selected_loading = available_energy_attrs[selected_attr]\n",
    "\n",
    "            if selected_attr in attr_interpretations:\n",
    "                category = get_loading_category(selected_loading)\n",
    "                conflict_note = f\"从{len(available_energy_attrs)}个能量属性中选择载荷最大的 (|{selected_loading:.3f}|)\"\n",
    "\n",
    "                resolved_interpretations[selected_attr] = {\n",
    "                    \"loading\": selected_loading,\n",
    "                    \"interpretation\": attr_interpretations[selected_attr][category],\n",
    "                    \"conflict_resolved\": conflict_note,\n",
    "                }\n",
    "\n",
    "                # 标记所有能量属性为已使用\n",
    "                used_attributes.update(energy_group)\n",
    "\n",
    "    # 再处理叠前叠后冲突\n",
    "    for post_attr, pre_attr in pre_post_pairs:\n",
    "        if (\n",
    "            post_attr in loadings_dict\n",
    "            and pre_attr in loadings_dict\n",
    "            and post_attr not in used_attributes\n",
    "            and pre_attr not in used_attributes\n",
    "        ):\n",
    "            post_loading = abs(loadings_dict[post_attr])\n",
    "            pre_loading = abs(loadings_dict[pre_attr])\n",
    "\n",
    "            if post_loading >= pre_loading:\n",
    "                selected_attr = post_attr\n",
    "                selected_loading = loadings_dict[post_attr]\n",
    "            else:\n",
    "                selected_attr = pre_attr\n",
    "                selected_loading = loadings_dict[pre_attr]\n",
    "\n",
    "            if selected_attr in attr_interpretations:\n",
    "                category = get_loading_category(selected_loading)\n",
    "                resolved_interpretations[selected_attr] = {\n",
    "                    \"loading\": selected_loading,\n",
    "                    \"interpretation\": attr_interpretations[selected_attr][category],\n",
    "                    \"conflict_resolved\": f\"选择载荷更大的属性 (|{selected_loading:.3f}|)\",\n",
    "                }\n",
    "                used_attributes.add(post_attr)\n",
    "                used_attributes.add(pre_attr)\n",
    "\n",
    "    # 处理其他没有冲突的属性\n",
    "    for attr, loading in loadings_dict.items():\n",
    "        if attr not in used_attributes and attr in attr_interpretations:\n",
    "            category = get_loading_category(loading)\n",
    "            resolved_interpretations[attr] = {\n",
    "                \"loading\": loading,\n",
    "                \"interpretation\": attr_interpretations[attr][category],\n",
    "                \"conflict_resolved\": None,\n",
    "            }\n",
    "\n",
    "    return resolved_interpretations\n",
    "\n",
    "\n",
    "# 获取PC1和PC2的载荷\n",
    "component_contributions = pca_results[\"component_contributions\"]\n",
    "available_attributes = list(component_contributions.columns)\n",
    "\n",
    "print(f\"可用的地震属性: {available_attributes}\")\n",
    "\n",
    "# 分析PC1和PC2\n",
    "for pc_name in [\"PC1\", \"PC2\"]:\n",
    "    if pc_name in component_contributions.index:\n",
    "        print(f\"\\n======== {pc_name} 载荷解释 ========\")\n",
    "\n",
    "        # 获取该主成分的载荷\n",
    "        pc_loadings = component_contributions.loc[pc_name].to_dict()\n",
    "\n",
    "        # 过滤出绝对值大于0.1的载荷（避免显示太多微小载荷）\n",
    "        significant_loadings = {attr: loading for attr, loading in pc_loadings.items() if abs(loading) > 0.1}\n",
    "\n",
    "        if not significant_loadings:\n",
    "            print(f\"{pc_name} 没有显著的载荷 (>0.1)\")\n",
    "            continue\n",
    "\n",
    "        # 解决冲突并生成解释\n",
    "        resolved_interpretations = resolve_conflicts(significant_loadings, attribute_interpretations)\n",
    "\n",
    "        if not resolved_interpretations:\n",
    "            print(f\"{pc_name} 没有可解释的地震属性\")\n",
    "            continue\n",
    "\n",
    "        # 按载荷绝对值排序\n",
    "        sorted_interpretations = sorted(\n",
    "            resolved_interpretations.items(), key=lambda x: abs(x[1][\"loading\"]), reverse=True\n",
    "        )\n",
    "\n",
    "        # 输出表格\n",
    "        print(f\"\\n{pc_name} 载荷解释表:\")\n",
    "        print(\"-\" * 90)\n",
    "        print(f\"{'地震属性':<25} {'载荷值':<10} {'地质解释':<15} {'备注':<20}\")\n",
    "        print(\"-\" * 90)\n",
    "\n",
    "        for attr, info in sorted_interpretations:\n",
    "            loading = info[\"loading\"]\n",
    "            interpretation = info[\"interpretation\"]\n",
    "            conflict_note = info[\"conflict_resolved\"] if info[\"conflict_resolved\"] else \"\"\n",
    "\n",
    "            print(f\"{attr:<25}  {loading:>8.3f}          {interpretation:<15} {conflict_note:<20}\")\n",
    "\n",
    "        print(\"-\" * 90)\n",
    "\n",
    "        # 生成PC总体解释\n",
    "        all_interpretations = [info[\"interpretation\"] for attr, info in sorted_interpretations]\n",
    "\n",
    "        print(f\"\\n{pc_name} 总体地质意义:\")\n",
    "        print(f\"主要反映: {', '.join(all_interpretations)}\")\n",
    "\n",
    "        # 计算该PC的解释方差比\n",
    "        pc_index = int(pc_name.replace(\"PC\", \"\")) - 1\n",
    "        if pc_index < len(pca_results[\"explained_variance_ratio\"]):\n",
    "            variance_explained = pca_results[\"explained_variance_ratio\"][pc_index]\n",
    "            print(f\"解释方差比: {variance_explained:.3f} ({variance_explained * 100:.1f}%)\")\n",
    "\n",
    "\n",
    "print(\"\\n======== PCA载荷解释分析完成 ========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c65f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======== 井控区结果分析 ========\")\n",
    "\n",
    "# 1. 为井点分配聚类标签\n",
    "well_cluster_labels = gmm_results[\"gmm\"].predict(data_well_attr_filtered_pca_features[:, :2])  # 使用前两个主成分\n",
    "\n",
    "# 2. 创建用于可视化的数据框\n",
    "well_analysis_data = data_well_attr_filtered.copy()\n",
    "well_analysis_data[\"PC1\"] = data_well_attr_filtered_pca_features[:, 0]  # 第一主成分\n",
    "well_analysis_data[\"PC2\"] = data_well_attr_filtered_pca_features[:, 1]  # 第二主成分\n",
    "well_analysis_data[\"Cluster\"] = well_cluster_labels  # 聚类标签\n",
    "\n",
    "print(f\"井点数据形状: {well_analysis_data.shape}\")\n",
    "print(f\"井点聚类分布:\")\n",
    "cluster_stats = {}\n",
    "for cluster in sorted(np.unique(well_cluster_labels)):\n",
    "    count = sum(well_cluster_labels == cluster)\n",
    "    cluster_stats[cluster] = count\n",
    "    print(f\"  聚类 {cluster}: {count} 个井点\")\n",
    "\n",
    "\n",
    "# 3. 定义相关性分析函数\n",
    "def analyze_correlation(x_data, y_data, x_name, y_name, threshold=0.35):\n",
    "    \"\"\"分析两个变量的相关性\"\"\"\n",
    "    correlation_coef, p_value = pearsonr(x_data, y_data)\n",
    "\n",
    "    # 判断相关性显著性\n",
    "    is_significant = abs(correlation_coef) >= threshold\n",
    "\n",
    "    # 判断相关性强度和方向\n",
    "    if is_significant:\n",
    "        direction = \"正相关\" if correlation_coef > 0 else \"负相关\"\n",
    "        if abs(correlation_coef) >= 0.7:\n",
    "            strength = \"强\"\n",
    "        elif abs(correlation_coef) >= 0.5:\n",
    "            strength = \"中等\"\n",
    "        else:\n",
    "            strength = \"弱\"\n",
    "        result = f\"{strength}{direction}\"\n",
    "    else:\n",
    "        result = \"无显著相关性\"\n",
    "\n",
    "    return {\n",
    "        \"correlation\": correlation_coef,\n",
    "        \"p_value\": p_value,\n",
    "        \"is_significant\": is_significant,\n",
    "        \"result\": result,\n",
    "        \"description\": f\"{x_name}与{y_name}: r={correlation_coef:.4f}, {result}\",\n",
    "    }\n",
    "\n",
    "\n",
    "# 4. 创建聚类标签映射\n",
    "cluster_labels_dict = {cluster: f\"聚类 {cluster}\" for cluster in sorted(np.unique(well_cluster_labels))}\n",
    "\n",
    "# 5. 分析结果存储\n",
    "correlation_results = {}\n",
    "\n",
    "print(\"\\n======== PC1 相关性分析 ========\")\n",
    "\n",
    "# 5.1 PC1 vs 砂厚（聚类上色）\n",
    "print(\"\\n可视化PC1 vs 砂厚（按聚类着色）...\")\n",
    "fig1 = visualize_feature_distribution(\n",
    "    data=well_analysis_data,\n",
    "    x_feature=\"PC1\",\n",
    "    y_feature=\"Sand Thickness\",\n",
    "    color_feature=\"Cluster\",\n",
    "    figsize=(12, 8),\n",
    "    point_size=100,\n",
    "    alpha=0.7,\n",
    "    colormap=\"tab10\",\n",
    "    title=\"井控区：PC1 vs 砂厚（按聚类分类）\",\n",
    "    save_path=os.path.join(output_dir, \"well_pc1_vs_sand_thickness_by_cluster.png\"),\n",
    "    discrete_colors=True,\n",
    "    color_labels=cluster_labels_dict,\n",
    ")\n",
    "\n",
    "# PC1整体相关性分析\n",
    "pc1_overall = analyze_correlation(well_analysis_data[\"PC1\"], well_analysis_data[\"Sand Thickness\"], \"PC1\", \"砂厚\")\n",
    "correlation_results[\"PC1_overall\"] = pc1_overall\n",
    "print(f\"PC1整体相关性: {pc1_overall['description']}\")\n",
    "\n",
    "# 5.2 PC1 vs 砂厚（分聚类分析）\n",
    "print(\"\\n分聚类PC1相关性分析:\")\n",
    "for cluster in sorted(np.unique(well_cluster_labels)):\n",
    "    cluster_mask = well_analysis_data[\"Cluster\"] == cluster\n",
    "    cluster_data = well_analysis_data[cluster_mask]\n",
    "\n",
    "    if len(cluster_data) >= 5:  # 只有样本数>=5才进行可视化和分析\n",
    "        print(f\"\\n--- 聚类 {cluster} (n={len(cluster_data)}) ---\")\n",
    "\n",
    "        # 可视化单独聚类\n",
    "        fig_cluster = visualize_feature_distribution(\n",
    "            data=cluster_data,\n",
    "            x_feature=\"PC1\",\n",
    "            y_feature=\"Sand Thickness\",\n",
    "            color_feature=\"Sand Thickness\",\n",
    "            figsize=(10, 6),\n",
    "            point_size=100,\n",
    "            alpha=0.8,\n",
    "            colormap=\"viridis\",\n",
    "            title=f\"聚类 {cluster}：PC1 vs 砂厚\",\n",
    "            save_path=os.path.join(output_dir, f\"well_pc1_vs_sand_thickness_cluster_{cluster}.png\"),\n",
    "            discrete_colors=False,\n",
    "        )\n",
    "\n",
    "        # 相关性分析\n",
    "        pc1_cluster = analyze_correlation(\n",
    "            cluster_data[\"PC1\"], cluster_data[\"Sand Thickness\"], f\"PC1(聚类{cluster})\", \"砂厚\"\n",
    "        )\n",
    "        correlation_results[f\"PC1_cluster_{cluster}\"] = pc1_cluster\n",
    "        print(f\"  {pc1_cluster['description']}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\n--- 聚类 {cluster} (n={len(cluster_data)}) ---\")\n",
    "        print(f\"  样本数过少(<5)，跳过可视化和相关性分析\")\n",
    "\n",
    "print(\"\\n======== PC2 相关性分析 ========\")\n",
    "\n",
    "# 5.3 PC2 vs 砂厚（聚类上色）\n",
    "print(\"\\n可视化PC2 vs 砂厚（按聚类着色）...\")\n",
    "fig2 = visualize_feature_distribution(\n",
    "    data=well_analysis_data,\n",
    "    x_feature=\"PC2\",\n",
    "    y_feature=\"Sand Thickness\",\n",
    "    color_feature=\"Cluster\",\n",
    "    figsize=(12, 8),\n",
    "    point_size=100,\n",
    "    alpha=0.7,\n",
    "    colormap=\"tab10\",\n",
    "    title=\"井控区：PC2 vs 砂厚（按聚类分类）\",\n",
    "    save_path=os.path.join(output_dir, \"well_pc2_vs_sand_thickness_by_cluster.png\"),\n",
    "    discrete_colors=True,\n",
    "    color_labels=cluster_labels_dict,\n",
    ")\n",
    "\n",
    "# PC2整体相关性分析\n",
    "pc2_overall = analyze_correlation(well_analysis_data[\"PC2\"], well_analysis_data[\"Sand Thickness\"], \"PC2\", \"砂厚\")\n",
    "correlation_results[\"PC2_overall\"] = pc2_overall\n",
    "print(f\"PC2整体相关性: {pc2_overall['description']}\")\n",
    "\n",
    "# 5.4 PC2 vs 砂厚（分聚类分析）\n",
    "print(\"\\n分聚类PC2相关性分析:\")\n",
    "for cluster in sorted(np.unique(well_cluster_labels)):\n",
    "    cluster_mask = well_analysis_data[\"Cluster\"] == cluster\n",
    "    cluster_data = well_analysis_data[cluster_mask]\n",
    "\n",
    "    if len(cluster_data) >= 5:  # 只有样本数>=5才进行可视化和分析\n",
    "        print(f\"\\n--- 聚类 {cluster} (n={len(cluster_data)}) ---\")\n",
    "\n",
    "        # 可视化单独聚类\n",
    "        fig_cluster = visualize_feature_distribution(\n",
    "            data=cluster_data,\n",
    "            x_feature=\"PC2\",\n",
    "            y_feature=\"Sand Thickness\",\n",
    "            color_feature=\"Sand Thickness\",\n",
    "            figsize=(10, 6),\n",
    "            point_size=100,\n",
    "            alpha=0.8,\n",
    "            colormap=\"viridis\",\n",
    "            title=f\"聚类 {cluster}：PC2 vs 砂厚\",\n",
    "            save_path=os.path.join(output_dir, f\"well_pc2_vs_sand_thickness_cluster_{cluster}.png\"),\n",
    "            discrete_colors=False,\n",
    "        )\n",
    "\n",
    "        # 相关性分析\n",
    "        pc2_cluster = analyze_correlation(\n",
    "            cluster_data[\"PC2\"], cluster_data[\"Sand Thickness\"], f\"PC2(聚类{cluster})\", \"砂厚\"\n",
    "        )\n",
    "        correlation_results[f\"PC2_cluster_{cluster}\"] = pc2_cluster\n",
    "        print(f\"  {pc2_cluster['description']}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\n--- 聚类 {cluster} (n={len(cluster_data)}) ---\")\n",
    "        print(f\"  样本数过少(<5)，跳过可视化和相关性分析\")\n",
    "\n",
    "# 6. 生成解释变量\n",
    "interpretation_summary = {\n",
    "    \"correlation_analysis\": {\n",
    "        \"PC1_overall_correlation\": pc1_overall[\"correlation\"],\n",
    "        \"PC1_overall_significant\": pc1_overall[\"is_significant\"],\n",
    "        \"PC1_overall_result\": pc1_overall[\"result\"],\n",
    "        \"PC2_overall_correlation\": pc2_overall[\"correlation\"],\n",
    "        \"PC2_overall_significant\": pc2_overall[\"is_significant\"],\n",
    "        \"PC2_overall_result\": pc2_overall[\"result\"],\n",
    "    },\n",
    "    \"cluster_analysis\": {\n",
    "        \"total_wells\": len(well_analysis_data),\n",
    "        \"n_clusters\": len(cluster_stats),\n",
    "        \"cluster_distribution\": cluster_stats,\n",
    "        \"significant_correlations\": {},\n",
    "    },\n",
    "    \"detailed_results\": correlation_results,\n",
    "}\n",
    "\n",
    "# 收集显著相关性结果\n",
    "for key, result in correlation_results.items():\n",
    "    if result[\"is_significant\"]:\n",
    "        interpretation_summary[\"cluster_analysis\"][\"significant_correlations\"][key] = {\n",
    "            \"correlation\": result[\"correlation\"],\n",
    "            \"result\": result[\"result\"],\n",
    "        }\n",
    "\n",
    "# 7. 分聚类统计分析\n",
    "print(f\"\\n======== 分聚类统计分析 ========\")\n",
    "for cluster in sorted(np.unique(well_cluster_labels)):\n",
    "    cluster_mask = well_analysis_data[\"Cluster\"] == cluster\n",
    "    cluster_data = well_analysis_data[cluster_mask]\n",
    "\n",
    "    pc1_mean = cluster_data[\"PC1\"].mean()\n",
    "    pc1_std = cluster_data[\"PC1\"].std()\n",
    "    pc2_mean = cluster_data[\"PC2\"].mean()\n",
    "    pc2_std = cluster_data[\"PC2\"].std()\n",
    "    sand_mean = cluster_data[\"Sand Thickness\"].mean()\n",
    "    sand_std = cluster_data[\"Sand Thickness\"].std()\n",
    "\n",
    "    print(f\"聚类 {cluster} (n={len(cluster_data)}):\")\n",
    "    print(f\"  PC1: {pc1_mean:.4f} ± {pc1_std:.4f}\")\n",
    "    print(f\"  PC2: {pc2_mean:.4f} ± {pc2_std:.4f}\")\n",
    "    print(f\"  砂厚: {sand_mean:.4f} ± {sand_std:.4f}\")\n",
    "\n",
    "# 8. 保存分析结果到文件\n",
    "well_analysis_data.to_csv(os.path.join(output_dir, \"well_analysis_with_clusters.csv\"), index=False)\n",
    "\n",
    "print(f\"\\n======== 相关性分析摘要 ========\")\n",
    "print(f\"PC1整体相关性: {pc1_overall['result']} (r={pc1_overall['correlation']:.4f})\")\n",
    "print(f\"PC2整体相关性: {pc2_overall['result']} (r={pc2_overall['correlation']:.4f})\")\n",
    "\n",
    "significant_count = len(interpretation_summary[\"cluster_analysis\"][\"significant_correlations\"])\n",
    "print(f\"显著相关性数量: {significant_count}\")\n",
    "\n",
    "if significant_count > 0:\n",
    "    print(\"显著相关性详情:\")\n",
    "    for key, result in interpretation_summary[\"cluster_analysis\"][\"significant_correlations\"].items():\n",
    "        print(f\"  {key}: {result['result']} (r={result['correlation']:.4f})\")\n",
    "\n",
    "print(f\"\\n======== 分析完成 ========\")\n",
    "print(f\"井点分析数据已保存到: well_analysis_with_clusters.csv\")\n",
    "print(f\"可视化图片已保存到输出目录: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253307f1",
   "metadata": {},
   "source": [
    "## 输出主成分数据与解释到 Petrel 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee48acb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"======== 输出主成分数据到Petrel文件 ========\")\n",
    "\n",
    "\n",
    "# 1. 准备PCA载荷解释数据\n",
    "def generate_pca_interpretation_text(pc_name, component_contributions, attribute_interpretations):\n",
    "    \"\"\"生成PCA载荷解释文本\"\"\"\n",
    "    if pc_name not in component_contributions.index:\n",
    "        return f\"{pc_name} 数据不可用\"\n",
    "\n",
    "    # 获取该主成分的载荷\n",
    "    pc_loadings = component_contributions.loc[pc_name].to_dict()\n",
    "\n",
    "    # 过滤出绝对值大于0.1的载荷\n",
    "    significant_loadings = {attr: loading for attr, loading in pc_loadings.items() if abs(loading) > 0.1}\n",
    "\n",
    "    if not significant_loadings:\n",
    "        return f\"{pc_name} 没有显著的载荷 (>0.1)\"\n",
    "\n",
    "    # 解决冲突并生成解释\n",
    "    resolved_interpretations = resolve_conflicts(significant_loadings, attribute_interpretations)\n",
    "\n",
    "    if not resolved_interpretations:\n",
    "        return f\"{pc_name} 没有可解释的地震属性\"\n",
    "\n",
    "    # 按载荷绝对值排序\n",
    "    sorted_interpretations = sorted(resolved_interpretations.items(), key=lambda x: abs(x[1][\"loading\"]), reverse=True)\n",
    "\n",
    "    # 生成文本\n",
    "    interpretation_text = []\n",
    "    interpretation_text.append(f\"{pc_name} 载荷解释:\")\n",
    "    for attr, info in sorted_interpretations:\n",
    "        loading = info[\"loading\"]\n",
    "        interpretation = info[\"interpretation\"]\n",
    "        conflict_note = info[\"conflict_resolved\"] if info[\"conflict_resolved\"] else \"\"\n",
    "\n",
    "        line = f\"  {attr}: {loading:.3f} -> {interpretation}\"\n",
    "        if conflict_note:\n",
    "            line += f\" ({conflict_note})\"\n",
    "        interpretation_text.append(line)\n",
    "\n",
    "    # 生成总体解释\n",
    "    all_interpretations = [info[\"interpretation\"] for attr, info in sorted_interpretations]\n",
    "    interpretation_text.append(f\"  总体地质意义: {', '.join(all_interpretations)}\")\n",
    "\n",
    "    # 添加解释方差比\n",
    "    pc_index = int(pc_name.replace(\"PC\", \"\")) - 1\n",
    "    if pc_index < len(pca_results[\"explained_variance_ratio\"]):\n",
    "        variance_explained = pca_results[\"explained_variance_ratio\"][pc_index]\n",
    "        interpretation_text.append(f\"  解释方差比: {variance_explained:.3f} ({variance_explained * 100:.1f}%)\")\n",
    "\n",
    "    return \"\\n\".join(interpretation_text)\n",
    "\n",
    "\n",
    "# 2. 直接使用当前环境中的相关性分析结果\n",
    "correlation_summary = \"\"\n",
    "try:\n",
    "    # 直接使用前面生成的interpretation_summary变量\n",
    "    correlation_summary = f\"\"\"\n",
    "井控区相关性分析结果:\n",
    "  PC1整体相关性: {interpretation_summary[\"correlation_analysis\"][\"PC1_overall_result\"]} (r={interpretation_summary[\"correlation_analysis\"][\"PC1_overall_correlation\"]:.4f})\n",
    "  PC2整体相关性: {interpretation_summary[\"correlation_analysis\"][\"PC2_overall_result\"]} (r={interpretation_summary[\"correlation_analysis\"][\"PC2_overall_correlation\"]:.4f})\n",
    "  总井点数: {interpretation_summary[\"cluster_analysis\"][\"total_wells\"]}\n",
    "  聚类数: {interpretation_summary[\"cluster_analysis\"][\"n_clusters\"]}\n",
    "  显著相关性数量: {len(interpretation_summary[\"cluster_analysis\"][\"significant_correlations\"])}\"\"\"\n",
    "\n",
    "    if interpretation_summary[\"cluster_analysis\"][\"significant_correlations\"]:\n",
    "        correlation_summary += \"\\n  显著相关性详情:\"\n",
    "        for key, result in interpretation_summary[\"cluster_analysis\"][\"significant_correlations\"].items():\n",
    "            correlation_summary += f\"\\n    {key}: {result['result']} (r={result['correlation']:.4f})\"\n",
    "\n",
    "except Exception as e:\n",
    "    correlation_summary = f\"井控区相关性分析结果读取失败: {str(e)}\"\n",
    "\n",
    "# 3. 为PC1和PC2分别创建输出文件\n",
    "for pc_name in [\"PC1\", \"PC2\"]:\n",
    "    if pc_name not in data_seismic_attr_with_PC.columns:\n",
    "        print(f\"警告: {pc_name} 数据不存在，跳过输出\")\n",
    "        continue\n",
    "\n",
    "    # 生成文件名\n",
    "    filename = f\"{SURFACE_NAME.replace('-', '_')}_{pc_name}.txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # 生成PCA载荷解释\n",
    "    pca_interpretation = generate_pca_interpretation_text(\n",
    "        pc_name, pca_results[\"component_contributions\"], attribute_interpretations\n",
    "    )\n",
    "\n",
    "    # 准备输出数据\n",
    "    output_data = data_seismic_attr_with_PC[[\"X\", \"Y\", pc_name]].copy()\n",
    "\n",
    "    # 写入文件\n",
    "    with open(filepath, \"w\", encoding=\"gbk\") as f:\n",
    "        # 写入文件头注释\n",
    "        f.write(f\"# -*- coding: gbk -*-\\n\")\n",
    "        f.write(f\"# Petrel 地震属性数据文件\\n\")\n",
    "        f.write(f\"# 文件名: {filename}\\n\")\n",
    "        f.write(f\"# 创建时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"# 层位: {SURFACE_NAME}\\n\")\n",
    "        f.write(f\"# 属性: {pc_name} (第{pc_name[2:]}主成分)\\n\")\n",
    "        f.write(f\"# 数据点数: {len(output_data)}\\n\")\n",
    "        f.write(f\"# 坐标系统: 原始地震数据坐标系\\n\")\n",
    "        f.write(f\"#\\n\")\n",
    "        f.write(f\"# ==================== PCA分析结果 ====================\\n\")\n",
    "\n",
    "        # 写入PCA解释\n",
    "        for line in pca_interpretation.split(\"\\n\"):\n",
    "            f.write(f\"# {line}\\n\")\n",
    "\n",
    "        f.write(f\"#\\n\")\n",
    "        f.write(f\"# ==================== 数据统计信息 ====================\\n\")\n",
    "        f.write(f\"# {pc_name} 最小值: {output_data[pc_name].min():.6f}\\n\")\n",
    "        f.write(f\"# {pc_name} 最大值: {output_data[pc_name].max():.6f}\\n\")\n",
    "        f.write(f\"# {pc_name} 均值: {output_data[pc_name].mean():.6f}\\n\")\n",
    "        f.write(f\"# {pc_name} 标准差: {output_data[pc_name].std():.6f}\\n\")\n",
    "\n",
    "        f.write(f\"#\\n\")\n",
    "        f.write(f\"# ==================== 井控区分析结果 ====================\\n\")\n",
    "        for line in correlation_summary.split(\"\\n\"):\n",
    "            if line.strip():\n",
    "                f.write(f\"# {line}\\n\")\n",
    "\n",
    "        f.write(f\"#\\n\")\n",
    "        f.write(f\"# ==================== 数据格式说明 ====================\\n\")\n",
    "        f.write(f\"# 列1: X坐标\\n\")\n",
    "        f.write(f\"# 列2: Y坐标\\n\")\n",
    "        f.write(f\"# 列3: {pc_name}值\\n\")\n",
    "        f.write(f\"# 数据行数: {len(output_data)}\\n\")\n",
    "        f.write(f\"# 缺失值标识: 无\\n\")\n",
    "        f.write(f\"#\\n\")\n",
    "        f.write(f\"# ==================== 数据开始 ====================\\n\")\n",
    "\n",
    "        # 写入列标题\n",
    "        f.write(\"X\\tY\\t\" + pc_name + \"\\n\")\n",
    "\n",
    "        # 写入数据\n",
    "        for _, row in output_data.iterrows():\n",
    "            f.write(f\"{row['X']:.6f}\\t{row['Y']:.6f}\\t{row[pc_name]:.6f}\\n\")\n",
    "\n",
    "    print(f\"✓ {pc_name} 数据已输出到: {filepath}\")\n",
    "    print(f\"  - 数据点数: {len(output_data)}\")\n",
    "    print(f\"  - {pc_name} 值范围: [{output_data[pc_name].min():.4f}, {output_data[pc_name].max():.4f}]\")\n",
    "\n",
    "# 4. 生成合并的解释报告文件\n",
    "report_filename = f\"{SURFACE_NAME.replace('-', '_')}_PCA_analysis_report.txt\"\n",
    "report_filepath = os.path.join(output_dir, report_filename)\n",
    "\n",
    "with open(report_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"PCA分析完整报告\\n\")\n",
    "    f.write(f\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"层位: {SURFACE_NAME}\\n\")\n",
    "    f.write(f\"分析时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"数据点总数: {len(data_seismic_attr_with_PC)}\\n\")\n",
    "    f.write(f\"输出主成分数: {pca_results['n_components']}\\n\\n\")\n",
    "\n",
    "    # 写入主成分贡献度摘要\n",
    "    f.write(f\"主成分贡献度摘要:\\n\")\n",
    "    for i in range(pca_results[\"n_components\"]):\n",
    "        pc_name = f\"PC{i + 1}\"\n",
    "        explained_var = pca_results[\"explained_variance_ratio\"][i]\n",
    "        cumulative_var = pca_results[\"explained_variance_ratio_cumsum\"][i]\n",
    "        f.write(\n",
    "            f\"  {pc_name}: 解释方差 {explained_var:.3f} ({explained_var * 100:.1f}%), 累积 {cumulative_var:.3f} ({cumulative_var * 100:.1f}%)\\n\"\n",
    "        )\n",
    "\n",
    "    f.write(f\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "    # 写入PC1和PC2的详细解释\n",
    "    for pc_name in [\"PC1\", \"PC2\"]:\n",
    "        if pc_name in pca_results[\"component_contributions\"].index:\n",
    "            f.write(f\"\\n{pc_name} 详细解释:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            pca_interpretation = generate_pca_interpretation_text(\n",
    "                pc_name, pca_results[\"component_contributions\"], attribute_interpretations\n",
    "            )\n",
    "            f.write(pca_interpretation + \"\\n\")\n",
    "\n",
    "    # 写入井控区分析结果\n",
    "    f.write(f\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"井控区分析结果:\\n\")\n",
    "    f.write(correlation_summary + \"\\n\")\n",
    "\n",
    "print(f\"✓ 完整分析报告已输出到: {report_filepath}\")\n",
    "\n",
    "print(f\"\\n======== 主成分数据输出完成 ========\")\n",
    "print(f\"输出文件:\")\n",
    "print(f\"  - PC1数据: {SURFACE_NAME.replace('-', '_')}_PC1.txt\")\n",
    "print(f\"  - PC2数据: {SURFACE_NAME.replace('-', '_')}_PC2.txt\")\n",
    "print(f\"  - 分析报告: {SURFACE_NAME.replace('-', '_')}_PCA_analysis_report.txt\")\n",
    "print(f\"输出目录: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-af",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
