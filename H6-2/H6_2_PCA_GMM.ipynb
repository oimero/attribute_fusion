{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c25782a",
   "metadata": {},
   "source": [
    "# PCA + GMM 再测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52717610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保src目录在Python路径中\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# 导入模块\n",
    "from src.data_utils import (\n",
    "    extract_seismic_attributes_for_wells,\n",
    "    extract_uniform_seismic_samples,\n",
    "    filter_anomalous_attributes,\n",
    "    filter_outlier_wells,\n",
    "    filter_seismic_by_wells,\n",
    "    identify_attributes,\n",
    "    parse_petrel_file,\n",
    "    preprocess_features,\n",
    ")\n",
    "from src.feature_selection import select_best_features\n",
    "from src.gmm_clustering import evaluate_gmm_clusters, perform_gmm_clustering\n",
    "from src.pca_analysis import perform_pca_analysis\n",
    "from src.visualization import visualize_attribute_map, visualize_gmm_clustering, visualize_pca_clustering\n",
    "\n",
    "data_dir = \"..\\\\data\"\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"  # 黑体 SimHei 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474aaecf",
   "metadata": {},
   "source": [
    "## 导入地震数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seismic_url = os.path.join(data_dir, \"6.2\")\n",
    "\n",
    "data_seismic_attr = parse_petrel_file(data_seismic_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac4b168",
   "metadata": {},
   "source": [
    "## 导入井点位置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c828d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_well_position = pd.read_excel(os.path.join(data_dir, \"well_without_attr.xlsx\"))\n",
    "\n",
    "# 选择对应层位的行，丢弃砂厚为 NaN 的行\n",
    "data_well_purpose_surface_position = (\n",
    "    data_well_position[data_well_position[\"Surface\"] == \"H6-2\"]\n",
    "    .replace(-999, np.nan)  # 将-999替换为NaN\n",
    "    .dropna(subset=[\"Sand Thickness\"])  # 丢弃砂厚为NaN的行\n",
    "    .reset_index(drop=True)  # 重置索引\n",
    ")\n",
    "data_well_purpose_surface_position.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdeacfb",
   "metadata": {},
   "source": [
    "## 筛除离群井\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe88af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选离群井\n",
    "data_well_purpose_surface_filtered = filter_outlier_wells(data_well_purpose_surface_position, method=\"iqr\")\n",
    "\n",
    "# 显示筛选前后的井点数量\n",
    "print(f\"筛选前井点数量: {len(data_well_purpose_surface_position)}\")\n",
    "print(f\"筛选后井点数量: {len(data_well_purpose_surface_filtered)}\")\n",
    "\n",
    "# 可视化筛选前后的井点分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 计算坐标范围（使用所有井点的数据来确定范围）\n",
    "x_min = data_well_purpose_surface_position[\"X\"].min()\n",
    "x_max = data_well_purpose_surface_position[\"X\"].max()\n",
    "y_min = data_well_purpose_surface_position[\"Y\"].min()\n",
    "y_max = data_well_purpose_surface_position[\"Y\"].max()\n",
    "\n",
    "# 可选：添加一些边距使图更美观\n",
    "margin = 0.05  # 5%的边距\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "x_min -= x_range * margin\n",
    "x_max += x_range * margin\n",
    "y_min -= y_range * margin\n",
    "y_max += y_range * margin\n",
    "\n",
    "# 绘制筛选前的井点分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data_well_purpose_surface_position[\"X\"], data_well_purpose_surface_position[\"Y\"], c=\"blue\")\n",
    "plt.title(\"筛选前井点分布\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "# 绘制筛选后的井点分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(data_well_purpose_surface_filtered[\"X\"], data_well_purpose_surface_filtered[\"Y\"], c=\"red\")\n",
    "plt.title(\"筛选后井点分布\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"well_filtering_comparison.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417bfe2",
   "metadata": {},
   "source": [
    "## 处理属性缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425febc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先获取地震属性列表\n",
    "attribute_names, _ = identify_attributes(data_seismic_url)\n",
    "\n",
    "# 使用preprocess_features处理地震数据\n",
    "processed_seismic, attr_stats = preprocess_features(\n",
    "    data=data_seismic_attr,\n",
    "    attribute_columns=attribute_names,\n",
    "    missing_values=[-999],\n",
    "    missing_threshold=0.6,  # 缺失值超过60%的列将被删除\n",
    "    outlier_method=\"iqr\",\n",
    "    outlier_threshold=1.5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 提取筛选后的属性\n",
    "attribute_names_filtered = [col for col in processed_seismic.columns]\n",
    "\n",
    "# 将处理后的属性数据与原始坐标数据合并\n",
    "processed_seismic_full = data_seismic_attr[[\"X\", \"Y\"]].copy()\n",
    "for col in processed_seismic.columns:\n",
    "    processed_seismic_full[col] = processed_seismic[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea1706",
   "metadata": {},
   "source": [
    "## 根据井点分布，缩小工区范围\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限制工区范围\n",
    "seismic_attr_filtered, area_bounds = filter_seismic_by_wells(\n",
    "    seismic_data=processed_seismic_full,\n",
    "    well_data=data_well_purpose_surface_filtered,\n",
    "    expansion_factor=1.5,  # 扩展50%\n",
    "    plot=True,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "\n",
    "# 后续可以直接使用area_bounds中的边界信息\n",
    "print(\"区域边界信息:\")\n",
    "for key, value in area_bounds.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098f98d",
   "metadata": {},
   "source": [
    "## 提取井点处地震属性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为筛选前的井点提取地震属性\n",
    "well_attr = extract_seismic_attributes_for_wells(\n",
    "    well_data=data_well_purpose_surface_position,\n",
    "    seismic_data=processed_seismic_full,\n",
    "    max_distance=50,\n",
    "    num_points=5,\n",
    ")\n",
    "\n",
    "# 为筛选后的井点提取地震属性\n",
    "well_attr_filtered = extract_seismic_attributes_for_wells(\n",
    "    well_data=data_well_purpose_surface_filtered, seismic_data=processed_seismic_full, max_distance=50, num_points=5\n",
    ")\n",
    "\n",
    "# 保存处理结果\n",
    "well_attr.to_excel(os.path.join(data_dir, \"wells_attr.xlsx\"), index=False)\n",
    "print(\"筛选前井点的地震属性已保存到 wells_attr.xlsx\")\n",
    "well_attr_filtered.to_excel(os.path.join(data_dir, \"wells_attr_filtered.xlsx\"), index=False)\n",
    "print(\"筛选后井点的地震属性已保存到 wells_attr_filtered.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97531786",
   "metadata": {},
   "source": [
    "## 生成统计摘要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebefe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出质量良好的属性\n",
    "good_attributes, anomalous_attributes, attribute_stats = filter_anomalous_attributes(\n",
    "    seismic_data=seismic_attr_filtered,\n",
    "    well_data=well_attr_filtered,\n",
    "    common_attributes=attribute_names_filtered,\n",
    "    ratio_threshold=5.0,  # 均值比值阈值\n",
    "    range_ratio_threshold=10.0,  # 数值范围比值阈值\n",
    "    std_ratio_threshold=10.0,  # 标准差比值阈值\n",
    "    output_dir=None,  # 输出图表目录\n",
    "    verbose=True,  # 打印详细信息\n",
    ")\n",
    "\n",
    "print(\"\\n筛选后保留的质量良好属性:\")\n",
    "for attr in good_attributes:\n",
    "    print(f\"- {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2770db5",
   "metadata": {},
   "source": [
    "## PCA 降维\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3faf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = perform_pca_analysis(\n",
    "    data=seismic_attr_filtered,\n",
    "    attribute_columns=good_attributes,\n",
    "    variance_threshold=0.75,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89045439",
   "metadata": {},
   "source": [
    "## GMM 聚类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10980a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先评估最佳聚类数\n",
    "# gmm_evaluation = evaluate_gmm_clusters(features_pca=pca_results[\"features_pca\"], max_clusters=10, output_dir=output_dir)\n",
    "\n",
    "# 使用不同的聚类数执行GMM聚类\n",
    "# 根据BIC/AIC结果选择的最佳聚类数\n",
    "# best_n = gmm_evaluation[\"best_n_components\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = 3  # 聚类数量\n",
    "\n",
    "# 1. 执行GMM聚类\n",
    "gmm_results = perform_gmm_clustering(\n",
    "    features=pca_results[\"features_pca\"],\n",
    "    coords=pca_results[\"coords_clean\"],\n",
    "    n_clusters=best_n,\n",
    ")\n",
    "gmm_results[\"result_df\"].to_csv(os.path.join(output_dir, \"gmm_best_clusters.csv\"), index=False)\n",
    "\n",
    "# 2. PCA可视化，需要将井点数据投影到PCA空间\n",
    "# 首先提取井点的属性列\n",
    "well_features = well_attr_filtered[pca_results[\"features_clean\"].columns].values\n",
    "# 使用相同的标准化器和PCA模型变换井点数据\n",
    "well_features_scaled = pca_results[\"scaler\"].transform(well_features)\n",
    "well_pca_features = pca_results[\"pca\"].transform(well_features_scaled)\n",
    "\n",
    "# 3. 在PCA空间中可视化聚类结果\n",
    "visualize_pca_clustering(\n",
    "    clustering_results=gmm_results,\n",
    "    pca_results=pca_results,\n",
    "    n_clusters=best_n,\n",
    "    output_dir=output_dir,\n",
    "    prefix=\"pca\",\n",
    "    well_data=data_well_purpose_surface_filtered,\n",
    "    well_pca_features=well_pca_features,\n",
    "    target_column=\"Sand Thickness\",\n",
    "    class_thresholds=[0.1, 10],\n",
    ")\n",
    "\n",
    "# 4. 在地理空间中可视化聚类结果\n",
    "visualize_gmm_clustering(\n",
    "    clustering_results=gmm_results,\n",
    "    output_dir=output_dir,\n",
    "    prefix=\"pca\",\n",
    "    well_data=data_well_purpose_surface_filtered,\n",
    "    target_column=\"Sand Thickness\",\n",
    "    class_thresholds=[0.1, 10],\n",
    "    point_size=120,\n",
    "    well_size=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92c0dbd",
   "metadata": {},
   "source": [
    "## 依靠 PCA 进行 sigmoid 拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_distribution(\n",
    "    data,\n",
    "    x_feature,\n",
    "    y_feature,\n",
    "    figsize=(10, 6),\n",
    "    point_size=50,\n",
    "    alpha=0.6,\n",
    "    colormap=\"viridis\",\n",
    "    title=None,\n",
    "    save_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    通用的特征分布可视化函数\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        包含特征数据的DataFrame\n",
    "    x_feature : str\n",
    "        x轴特征名\n",
    "    y_feature : str\n",
    "        y轴特征名（用作颜色映射）\n",
    "    figsize : tuple, default=(10, 6)\n",
    "        图形大小\n",
    "    point_size : int, default=50\n",
    "        点的大小\n",
    "    alpha : float, default=0.6\n",
    "        透明度\n",
    "    colormap : str, default=\"viridis\"\n",
    "        颜色映射\n",
    "    title : str, optional\n",
    "        图表标题，如果None则自动生成\n",
    "    save_path : str, optional\n",
    "        保存路径\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure : 生成的图形对象\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # 创建散点图，颜色表示y特征\n",
    "    scatter = plt.scatter(\n",
    "        data[x_feature],\n",
    "        data[y_feature],\n",
    "        c=data[y_feature],\n",
    "        s=point_size,\n",
    "        alpha=alpha,\n",
    "        cmap=colormap,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    plt.colorbar(scatter, label=f\"{y_feature}\")\n",
    "    plt.xlabel(f\"{x_feature}\")\n",
    "    plt.ylabel(f\"{y_feature}\")\n",
    "\n",
    "    if title is None:\n",
    "        title = f\"特征分布: {x_feature} vs {y_feature}\"\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 添加统计信息\n",
    "    stats_text = f\"样本数: {len(data)}\\n\"\n",
    "    stats_text += f\"{y_feature}范围: {data[y_feature].min():.2f} - {data[y_feature].max():.2f}\\n\"\n",
    "    stats_text += f\"{x_feature}范围: {data[x_feature].min():.2f} - {data[x_feature].max():.2f}\"\n",
    "\n",
    "    plt.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        stats_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    return plt.gcf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22411962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidModel:\n",
    "    \"\"\"\n",
    "    智能Sigmoid拟合模型\n",
    "\n",
    "    支持自动检测PC值与地质类型关系，智能添加虚拟点稳定拟合过程。\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        原始输入数据\n",
    "    feature_columns : list\n",
    "        特征列名列表\n",
    "    target_column : str\n",
    "        目标变量列名\n",
    "    fit_params : np.array or None\n",
    "        拟合参数 [L, k, x0]\n",
    "    r2_score : float or None\n",
    "        模型R²评分\n",
    "    current_data : pd.DataFrame or None\n",
    "        包含虚拟点的当前工作数据\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, feature_columns, target_column):\n",
    "        \"\"\"\n",
    "        初始化Sigmoid模型\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            输入数据，必须包含特征列和目标列\n",
    "        feature_columns : list\n",
    "            特征列名列表，通常为PCA组件['PC1', 'PC2', ...]\n",
    "        target_column : str\n",
    "            目标变量列名，如'Sand Thickness'\n",
    "\n",
    "        Raises:\n",
    "        -------\n",
    "        ValueError\n",
    "            当数据中缺少必要列时抛出异常\n",
    "        \"\"\"\n",
    "        self.data = data.copy()\n",
    "        self.feature_columns = feature_columns\n",
    "        self.target_column = target_column\n",
    "        self.fit_params = None\n",
    "        self.r2_score = None\n",
    "        self.current_data = None  # 添加虚拟点后的数据\n",
    "\n",
    "        # 检查必要的列是否存在\n",
    "        missing_cols = [col for col in feature_columns + [target_column] if col not in data.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"数据中缺少以下列: {missing_cols}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x, L, k, x0):\n",
    "        \"\"\"\n",
    "        标准三参数Sigmoid函数\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array-like\n",
    "            输入变量\n",
    "        L : float\n",
    "            最大渐近值，表示砂厚的理论上限\n",
    "        k : float\n",
    "            增长率，正值表示正向增长，负值表示负向增长\n",
    "        x0 : float\n",
    "            中点位置，Sigmoid函数的拐点\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        array-like\n",
    "            Sigmoid函数值，范围在[0, L]之间\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        函数形式: f(x) = L / (1 + exp(-k * (x - x0)))\n",
    "        \"\"\"\n",
    "        return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "    def auto_detect_pc_geology_relationship(self, primary_feature=\"PC1\", threshold_percentile=25):\n",
    "        \"\"\"\n",
    "        自动检测PC值与地质类型的关系\n",
    "\n",
    "        通过分析PC值的分布与砂厚的关系，自动判断低PC值和高PC值分别对应\n",
    "        泥岩还是砂岩，避免虚拟点添加错误。\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        primary_feature : str, default=\"PC1\"\n",
    "            用于分析的主要特征名称\n",
    "        threshold_percentile : float, default=25\n",
    "            用于划分低值和高值区间的百分位数阈值\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            包含关系映射的字典\n",
    "            - 'low_pc_type': str, 低PC值对应的地质类型 ('mud' 或 'sand')\n",
    "            - 'high_pc_type': str, 高PC值对应的地质类型 ('mud' 或 'sand')\n",
    "            - 'low_threshold': float, 低值区间阈值\n",
    "            - 'high_threshold': float, 高值区间阈值\n",
    "            - 'low_avg_thickness': float, 低PC值区间平均砂厚\n",
    "            - 'high_avg_thickness': float, 高PC值区间平均砂厚\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        分析逻辑：\n",
    "        1. 计算指定百分位数的PC值阈值\n",
    "        2. 比较低PC值区间和高PC值区间的平均砂厚\n",
    "        3. 砂厚较小的区间判定为泥岩，砂厚较大的区间判定为砂岩\n",
    "        \"\"\"\n",
    "        # 计算低PC1值和高PC1值区间的平均砂厚\n",
    "        pc_values = self.data[primary_feature]\n",
    "        sand_thickness = self.data[self.target_column]\n",
    "\n",
    "        low_threshold = np.percentile(pc_values, threshold_percentile)\n",
    "        high_threshold = np.percentile(pc_values, 100 - threshold_percentile)\n",
    "\n",
    "        # 低PC1区间的平均砂厚\n",
    "        low_pc_mask = pc_values <= low_threshold\n",
    "        low_pc_avg_thickness = sand_thickness[low_pc_mask].mean()\n",
    "\n",
    "        # 高PC1区间的平均砂厚\n",
    "        high_pc_mask = pc_values >= high_threshold\n",
    "        high_pc_avg_thickness = sand_thickness[high_pc_mask].mean()\n",
    "\n",
    "        print(f\"PC值与地质类型关系分析({primary_feature}):\")\n",
    "        print(f\"  低PC值区间({primary_feature} ≤ {low_threshold:.2f}): 平均砂厚 {low_pc_avg_thickness:.2f}m\")\n",
    "        print(f\"  高PC值区间({primary_feature} ≥ {high_threshold:.2f}): 平均砂厚 {high_pc_avg_thickness:.2f}m\")\n",
    "\n",
    "        # 判断关系\n",
    "        if low_pc_avg_thickness < high_pc_avg_thickness:\n",
    "            # 标准关系：低PC1=泥岩，高PC1=砂岩\n",
    "            relationship = {\"low_pc_type\": \"mud\", \"high_pc_type\": \"sand\", \"relationship_type\": \"standard\"}\n",
    "            print(\"  → 检测到标准关系：低PC值=泥岩，高PC值=砂岩\")\n",
    "        else:\n",
    "            # 反向关系：低PC1=砂岩，高PC1=泥岩\n",
    "            relationship = {\"low_pc_type\": \"sand\", \"high_pc_type\": \"mud\", \"relationship_type\": \"reversed\"}\n",
    "            print(\"  → 检测到反向关系：低PC值=砂岩，高PC值=泥岩\")\n",
    "\n",
    "        # 添加统计信息\n",
    "        relationship.update(\n",
    "            {\n",
    "                \"low_threshold\": low_threshold,\n",
    "                \"high_threshold\": high_threshold,\n",
    "                \"low_avg_thickness\": low_pc_avg_thickness,\n",
    "                \"high_avg_thickness\": high_pc_avg_thickness,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return relationship\n",
    "\n",
    "    def add_virtual_points_smart(\n",
    "        self,\n",
    "        mud_range=None,  # 手动指定泥岩区间 (start, end)\n",
    "        sand_range=None,  # 手动指定砂岩区间 (start, end)\n",
    "        n_points=20,\n",
    "        noise_factor=0.1,\n",
    "        auto_detect=True,\n",
    "        primary_feature=None,\n",
    "        placement_strategy=\"conservative\",  # \"conservative\" 或 \"extended\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        智能添加虚拟点，支持手动设置和自动策略\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        mud_range : tuple or None, default=None\n",
    "            手动指定泥岩虚拟点范围 (start, end)\n",
    "            例如: (-2, 0) 表示在PC1值-2到0之间添加泥岩虚拟点\n",
    "        sand_range : tuple or None, default=None\n",
    "            手动指定砂岩虚拟点范围 (start, end)\n",
    "            例如: (2, 4) 表示在PC1值2到4之间添加砂岩虚拟点\n",
    "        n_points : int, default=20\n",
    "            每个区间生成的虚拟点数量\n",
    "        noise_factor : float, default=0.1\n",
    "            噪音因子，用于为虚拟点添加随机变化\n",
    "        auto_detect : bool, default=True\n",
    "            是否自动检测PC值与地质类型的关系\n",
    "        primary_feature : str or None, default=None\n",
    "            用于添加虚拟点的主要特征，如果为None则使用第一个特征\n",
    "        placement_strategy : str, default=\"conservative\"\n",
    "            自动放置策略（仅在未手动指定范围时生效）:\n",
    "            - \"conservative\": 在数据范围内侧保守放置（推荐）\n",
    "            - \"extended\": 在数据范围外侧延伸放置\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        tuple\n",
    "            (enhanced_data, pc_geology_relationship)\n",
    "            - enhanced_data: pd.DataFrame, 包含虚拟点的增强数据集\n",
    "            - pc_geology_relationship: dict, PC值与地质类型的关系信息\n",
    "\n",
    "        Examples:\n",
    "        ---------\n",
    "        # 手动指定泥岩区间\n",
    "        data, relationship = model.add_virtual_points_smart(mud_range=(-5, 0), n_points=10)\n",
    "\n",
    "        # 手动指定砂岩和泥岩区间\n",
    "        data, relationship = model.add_virtual_points_smart(\n",
    "            mud_range=(-2, 0), sand_range=(2, 5), n_points=10\n",
    "        )\n",
    "\n",
    "        # 使用保守的自动策略\n",
    "        data, relationship = model.add_virtual_points_smart(\n",
    "            placement_strategy=\"conservative\", n_points=15\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "        if primary_feature is None:\n",
    "            primary_feature = self.feature_columns[0]\n",
    "\n",
    "        # 自动检测PC值与地质类型的关系\n",
    "        if auto_detect:\n",
    "            pc_geology_relationship = self.auto_detect_pc_geology_relationship(primary_feature)\n",
    "        else:\n",
    "            # 使用默认关系\n",
    "            pc_geology_relationship = {\"low_pc_type\": \"mud\", \"high_pc_type\": \"sand\", \"relationship_type\": \"default\"}\n",
    "            print(f\"使用默认PC值关系：低PC值=泥岩，高PC值=砂岩\")\n",
    "\n",
    "        feature_min = self.data[primary_feature].min()\n",
    "        feature_max = self.data[primary_feature].max()\n",
    "        feature_range = feature_max - feature_min\n",
    "        max_target = self.data[self.target_column].max()\n",
    "\n",
    "        virtual_data = []\n",
    "\n",
    "        print(f\"虚拟点生成配置:\")\n",
    "        print(f\"  主要特征: {primary_feature}\")\n",
    "        print(f\"  数据范围: [{feature_min:.2f}, {feature_max:.2f}]\")\n",
    "        print(f\"  每个区间点数: {n_points}\")\n",
    "        print(f\"  噪音因子: {noise_factor}\")\n",
    "\n",
    "        # === 处理泥岩虚拟点 ===\n",
    "        if mud_range is not None:\n",
    "            # 手动指定泥岩区间\n",
    "            print(f\"  手动设置泥岩虚拟点范围: {mud_range}\")\n",
    "            mud_start, mud_end = mud_range\n",
    "\n",
    "            # 生成泥岩虚拟点\n",
    "            mud_x_values = np.linspace(mud_start, mud_end, n_points)\n",
    "            for x_val in mud_x_values:\n",
    "                virtual_point = {col: 0 for col in self.feature_columns}\n",
    "                virtual_point[primary_feature] = x_val\n",
    "                virtual_point[self.target_column] = abs(np.random.normal(0, noise_factor))\n",
    "                virtual_point[\"is_virtual\"] = True\n",
    "                virtual_point[\"virtual_type\"] = \"mud\"\n",
    "                virtual_data.append(virtual_point)\n",
    "\n",
    "        else:\n",
    "            # 自动策略：根据PC-地质关系自动设置泥岩区间\n",
    "            if placement_strategy == \"conservative\":\n",
    "                # 保守策略：在数据范围内侧放置\n",
    "                margin = feature_range * 0.15  # 15%的内缩边距\n",
    "\n",
    "                if pc_geology_relationship[\"low_pc_type\"] == \"mud\":\n",
    "                    # 低PC值对应泥岩：在最小值右侧设置泥岩虚拟点\n",
    "                    mud_start = feature_min\n",
    "                    mud_end = feature_min + margin\n",
    "                    print(f\"  自动设置泥岩虚拟点（低PC=泥岩）: [{mud_start:.2f}, {mud_end:.2f}]\")\n",
    "                else:\n",
    "                    # 高PC值对应泥岩：在最大值左侧设置泥岩虚拟点\n",
    "                    mud_start = feature_max - margin\n",
    "                    mud_end = feature_max\n",
    "                    print(f\"  自动设置泥岩虚拟点（高PC=泥岩）: [{mud_start:.2f}, {mud_end:.2f}]\")\n",
    "\n",
    "            else:  # extended strategy\n",
    "                # 延伸策略：在数据范围外侧放置\n",
    "                expansion = feature_range * 0.2  # 20%的外延\n",
    "\n",
    "                if pc_geology_relationship[\"low_pc_type\"] == \"mud\":\n",
    "                    # 低PC值对应泥岩：在最小值左侧延伸\n",
    "                    mud_start = feature_min - expansion\n",
    "                    mud_end = feature_min\n",
    "                    print(f\"  自动设置泥岩虚拟点（低PC=泥岩，延伸）: [{mud_start:.2f}, {mud_end:.2f}]\")\n",
    "                else:\n",
    "                    # 高PC值对应泥岩：在最大值右侧延伸\n",
    "                    mud_start = feature_max\n",
    "                    mud_end = feature_max + expansion\n",
    "                    print(f\"  自动设置泥岩虚拟点（高PC=泥岩，延伸）: [{mud_start:.2f}, {mud_end:.2f}]\")\n",
    "\n",
    "            # 生成泥岩虚拟点\n",
    "            mud_x_values = np.linspace(mud_start, mud_end, n_points)\n",
    "            for x_val in mud_x_values:\n",
    "                virtual_point = {col: 0 for col in self.feature_columns}\n",
    "                virtual_point[primary_feature] = x_val\n",
    "                virtual_point[self.target_column] = abs(np.random.normal(0, noise_factor))\n",
    "                virtual_point[\"is_virtual\"] = True\n",
    "                virtual_point[\"virtual_type\"] = \"mud\"\n",
    "                virtual_data.append(virtual_point)\n",
    "\n",
    "        # === 处理砂岩虚拟点 ===\n",
    "        if sand_range is not None:\n",
    "            # 手动指定砂岩区间\n",
    "            print(f\"  手动设置砂岩虚拟点范围: {sand_range}\")\n",
    "            sand_start, sand_end = sand_range\n",
    "\n",
    "            # 生成砂岩虚拟点\n",
    "            sand_x_values = np.linspace(sand_start, sand_end, n_points)\n",
    "            for x_val in sand_x_values:\n",
    "                virtual_point = {col: 0 for col in self.feature_columns}\n",
    "                virtual_point[primary_feature] = x_val\n",
    "                virtual_point[self.target_column] = max_target + abs(np.random.normal(max_target * 0.1, noise_factor))\n",
    "                virtual_point[\"is_virtual\"] = True\n",
    "                virtual_point[\"virtual_type\"] = \"sand\"\n",
    "                virtual_data.append(virtual_point)\n",
    "\n",
    "        else:\n",
    "            # 自动策略：根据PC-地质关系自动设置砂岩区间\n",
    "            if placement_strategy == \"conservative\":\n",
    "                # 保守策略：在数据范围内侧放置\n",
    "                margin = feature_range * 0.15  # 15%的内缩边距\n",
    "\n",
    "                if pc_geology_relationship[\"high_pc_type\"] == \"sand\":\n",
    "                    # 高PC值对应砂岩：在最大值左侧设置砂岩虚拟点\n",
    "                    sand_start = feature_max - margin\n",
    "                    sand_end = feature_max\n",
    "                    print(f\"  自动设置砂岩虚拟点（高PC=砂岩）: [{sand_start:.2f}, {sand_end:.2f}]\")\n",
    "                else:\n",
    "                    # 低PC值对应砂岩：在最小值右侧设置砂岩虚拟点\n",
    "                    sand_start = feature_min\n",
    "                    sand_end = feature_min + margin\n",
    "                    print(f\"  自动设置砂岩虚拟点（低PC=砂岩）: [{sand_start:.2f}, {sand_end:.2f}]\")\n",
    "\n",
    "            else:  # extended strategy\n",
    "                # 延伸策略：在数据范围外侧放置\n",
    "                expansion = feature_range * 0.2  # 20%的外延\n",
    "\n",
    "                if pc_geology_relationship[\"high_pc_type\"] == \"sand\":\n",
    "                    # 高PC值对应砂岩：在最大值右侧延伸\n",
    "                    sand_start = feature_max\n",
    "                    sand_end = feature_max + expansion\n",
    "                    print(f\"  自动设置砂岩虚拟点（高PC=砂岩，延伸）: [{sand_start:.2f}, {sand_end:.2f}]\")\n",
    "                else:\n",
    "                    # 低PC值对应砂岩：在最小值左侧延伸\n",
    "                    sand_start = feature_min - expansion\n",
    "                    sand_end = feature_min\n",
    "                    print(f\"  自动设置砂岩虚拟点（低PC=砂岩，延伸）: [{sand_start:.2f}, {sand_end:.2f}]\")\n",
    "\n",
    "            # 生成砂岩虚拟点\n",
    "            sand_x_values = np.linspace(sand_start, sand_end, n_points)\n",
    "            for x_val in sand_x_values:\n",
    "                virtual_point = {col: 0 for col in self.feature_columns}\n",
    "                virtual_point[primary_feature] = x_val\n",
    "                virtual_point[self.target_column] = max_target + abs(np.random.normal(max_target * 0.1, noise_factor))\n",
    "                virtual_point[\"is_virtual\"] = True\n",
    "                virtual_point[\"virtual_type\"] = \"sand\"\n",
    "                virtual_data.append(virtual_point)\n",
    "\n",
    "        # 合并数据\n",
    "        enhanced_data = self.data.copy()\n",
    "        enhanced_data[\"is_virtual\"] = False\n",
    "        enhanced_data[\"virtual_type\"] = \"real\"\n",
    "\n",
    "        if virtual_data:\n",
    "            virtual_df = pd.DataFrame(virtual_data)\n",
    "            enhanced_data = pd.concat([enhanced_data, virtual_df], ignore_index=True)\n",
    "            print(f\"  成功添加 {len(virtual_data)} 个虚拟点\")\n",
    "\n",
    "            # 统计虚拟点分布\n",
    "            mud_count = sum(1 for vp in virtual_data if vp[\"virtual_type\"] == \"mud\")\n",
    "            sand_count = sum(1 for vp in virtual_data if vp[\"virtual_type\"] == \"sand\")\n",
    "            print(f\"    - 泥岩虚拟点: {mud_count}\")\n",
    "            print(f\"    - 砂岩虚拟点: {sand_count}\")\n",
    "\n",
    "        return enhanced_data, pc_geology_relationship\n",
    "\n",
    "    def prepare_features(self, data, use_features=None, feature_weights=None):\n",
    "        \"\"\"\n",
    "        准备特征，支持多维特征组合\n",
    "\n",
    "        将多个PCA特征线性组合为单一输入特征，用于Sigmoid拟合。\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            包含特征的数据源\n",
    "        use_features : list or None, optional\n",
    "            使用的特征列表，如['PC1', 'PC2']\n",
    "            如果为None，则使用第一个特征\n",
    "        feature_weights : list or None, optional\n",
    "            特征权重列表，与use_features对应\n",
    "            如果为None，则使用等权重\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        np.array\n",
    "            组合后的1D特征数组\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        多特征组合公式：\n",
    "        combined_feature = w1*PC1 + w2*PC2 + ... + wn*PCn\n",
    "        其中 wi 为权重，通常基于PCA的方差贡献比设置\n",
    "        \"\"\"\n",
    "        if use_features is None:\n",
    "            use_features = [self.feature_columns[0]]\n",
    "\n",
    "        if len(use_features) == 1:\n",
    "            return data[use_features[0]].values\n",
    "\n",
    "        # 多维特征线性组合\n",
    "        if feature_weights is None:\n",
    "            feature_weights = [1.0 / len(use_features)] * len(use_features)\n",
    "\n",
    "        combined_features = np.zeros(len(data))\n",
    "        for i, feature in enumerate(use_features):\n",
    "            combined_features += feature_weights[i] * data[feature].values\n",
    "\n",
    "        return combined_features\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        use_features=None,\n",
    "        feature_weights=None,\n",
    "        virtual_points_config=None,\n",
    "        bounds=None,\n",
    "        initial_guess=None,\n",
    "        max_iterations=2000,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        拟合Sigmoid函数\n",
    "\n",
    "        使用非线性最小二乘法拟合三参数Sigmoid函数到数据。\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        use_features : list or None, optional\n",
    "            使用的特征列表，如['PC1']或['PC1', 'PC2']\n",
    "        feature_weights : list or None, optional\n",
    "            特征权重，与use_features对应\n",
    "        virtual_points_config : dict or None, optional\n",
    "            虚拟点配置，支持两种模式：\n",
    "            1. 智能模式: {'smart': True, 'n_points': int, 'noise_factor': float}\n",
    "            2. 传统模式: {'x_mud': value, 'x_sand': value, 'n_points': int}\n",
    "        bounds : tuple or None, optional\n",
    "            参数边界 ((L_min, k_min, x0_min), (L_max, k_max, x0_max))\n",
    "        initial_guess : tuple or None, optional\n",
    "            初始参数猜测 (L, k, x0)\n",
    "        max_iterations : int, default=2000\n",
    "            优化算法最大迭代次数\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            拟合结果字典，包含以下键：\n",
    "            - 'success': bool, 拟合是否成功\n",
    "            - 'params': dict, 拟合参数 {'L': float, 'k': float, 'x0': float}\n",
    "            - 'param_errors': dict, 参数标准误差\n",
    "            - 'r2_score': float, 决定系数\n",
    "            - 'X': np.array, 输入特征\n",
    "            - 'y': np.array, 目标值\n",
    "            - 'y_pred': np.array, 预测值\n",
    "            - 'use_features': list, 使用的特征\n",
    "            - 'feature_weights': list, 特征权重\n",
    "            如果失败，包含 'error': str\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        拟合流程：\n",
    "        1. 数据准备和虚拟点添加\n",
    "        2. 特征组合和参数设置\n",
    "        3. 非线性最小二乘拟合\n",
    "        4. 结果评估和误差计算\n",
    "        \"\"\"\n",
    "        # 准备数据\n",
    "        working_data = self.data.copy()\n",
    "\n",
    "        # 添加虚拟点\n",
    "        if virtual_points_config:\n",
    "            if virtual_points_config.get(\"smart\", False):\n",
    "                # 使用智能模式\n",
    "                config = virtual_points_config.copy()\n",
    "                config.pop(\"smart\")  # 移除smart标志\n",
    "                working_data, pc_relationship = self.add_virtual_points_smart(**config)\n",
    "            else:\n",
    "                # 使用传统模式\n",
    "                working_data = self.add_virtual_points(**virtual_points_config)\n",
    "\n",
    "        # 保存当前工作数据\n",
    "        self.current_data = working_data\n",
    "\n",
    "        # 准备特征\n",
    "        X = self.prepare_features(working_data, use_features, feature_weights)\n",
    "        y = working_data[self.target_column].values\n",
    "\n",
    "        # 设置默认参数\n",
    "        y_max = y.max()\n",
    "        x_min, x_max = X.min(), X.max()\n",
    "        x_range = x_max - x_min\n",
    "\n",
    "        if bounds is None:\n",
    "            bounds = (\n",
    "                [y_max * 0.5, -10, x_min - x_range],  # 下界\n",
    "                [y_max * 2.0, 10, x_max + x_range],  # 上界\n",
    "            )\n",
    "\n",
    "        if initial_guess is None:\n",
    "            initial_guess = [y_max, 1.0, np.median(X)]\n",
    "\n",
    "        try:\n",
    "            # 拟合sigmoid函数\n",
    "            self.fit_params, covariance = curve_fit(\n",
    "                self.sigmoid, X, y, p0=initial_guess, bounds=bounds, maxfev=max_iterations\n",
    "            )\n",
    "\n",
    "            # 计算拟合质量\n",
    "            y_pred = self.sigmoid(X, *self.fit_params)\n",
    "            self.r2_score = r2_score(y, y_pred)\n",
    "\n",
    "            # 计算参数标准误差\n",
    "            param_errors = np.sqrt(np.diag(covariance))\n",
    "\n",
    "            return {\n",
    "                \"success\": True,\n",
    "                \"params\": dict(zip([\"L\", \"k\", \"x0\"], self.fit_params)),\n",
    "                \"param_errors\": dict(zip([\"L_err\", \"k_err\", \"x0_err\"], param_errors)),\n",
    "                \"r2_score\": self.r2_score,\n",
    "                \"X\": X,\n",
    "                \"y\": y,\n",
    "                \"y_pred\": y_pred,\n",
    "                \"use_features\": use_features or [self.feature_columns[0]],\n",
    "                \"feature_weights\": feature_weights,\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e), \"X\": X, \"y\": y}\n",
    "\n",
    "    def predict(self, new_data, use_features=None, feature_weights=None):\n",
    "        \"\"\"\n",
    "        使用拟合的模型进行预测\n",
    "\n",
    "        对新数据应用已拟合的Sigmoid模型进行砂厚预测。\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        new_data : pd.DataFrame or np.array\n",
    "            新的输入数据\n",
    "            - 如果是DataFrame，必须包含use_features中指定的列\n",
    "            - 如果是numpy数组，视为已处理的1D特征\n",
    "        use_features : list or None, optional\n",
    "            使用的特征列表，应与拟合时一致\n",
    "        feature_weights : list or None, optional\n",
    "            特征权重，应与拟合时一致\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        np.array\n",
    "            预测的砂厚值数组\n",
    "\n",
    "        Raises:\n",
    "        -------\n",
    "        ValueError\n",
    "            当模型尚未拟合时抛出异常\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        预测流程：\n",
    "        1. 检查模型是否已拟合\n",
    "        2. 特征准备和组合\n",
    "        3. 应用Sigmoid函数\n",
    "        \"\"\"\n",
    "        if self.fit_params is None:\n",
    "            raise ValueError(\"模型尚未拟合，请先调用fit方法\")\n",
    "\n",
    "        if isinstance(new_data, pd.DataFrame):\n",
    "            X_new = self.prepare_features(new_data, use_features, feature_weights)\n",
    "        else:\n",
    "            X_new = new_data\n",
    "\n",
    "        return self.sigmoid(X_new, *self.fit_params)\n",
    "\n",
    "    def visualize_fit(self, fit_result, figsize=(15, 8), save_path=None):\n",
    "        \"\"\"\n",
    "        可视化拟合结果\n",
    "\n",
    "        生成包含拟合曲线、残差分析和模型信息的综合可视化图表。\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        fit_result : dict\n",
    "            fit方法返回的拟合结果字典\n",
    "        figsize : tuple, default=(15, 8)\n",
    "            图形大小 (width, height)\n",
    "        save_path : str or None, optional\n",
    "            图片保存路径，如果为None则不保存\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        matplotlib.figure.Figure or None\n",
    "            生成的图形对象，如果拟合失败则返回None\n",
    "\n",
    "        Notes:\n",
    "        ------\n",
    "        可视化内容：\n",
    "        1. 左图：散点图 + Sigmoid拟合曲线 + 虚拟点标识\n",
    "        2. 右图：残差分析图\n",
    "        3. 模型参数和质量指标文本框\n",
    "        \"\"\"\n",
    "        if not fit_result[\"success\"]:\n",
    "            print(f\"拟合失败: {fit_result['error']}\")\n",
    "            return None\n",
    "\n",
    "        # 提取数据\n",
    "        X = fit_result[\"X\"]\n",
    "        y = fit_result[\"y\"]\n",
    "        y_pred = fit_result[\"y_pred\"]\n",
    "        params = fit_result[\"params\"]\n",
    "        r2_score_val = fit_result[\"r2_score\"]\n",
    "\n",
    "        # 创建图形\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "        # 左图：拟合结果\n",
    "        if self.current_data is not None and \"is_virtual\" in self.current_data.columns:\n",
    "            # 区分真实点和虚拟点\n",
    "            real_mask = ~self.current_data[\"is_virtual\"]\n",
    "            virtual_mask = self.current_data[\"is_virtual\"]\n",
    "\n",
    "            # 真实点\n",
    "            ax1.scatter(\n",
    "                X[real_mask],\n",
    "                y[real_mask],\n",
    "                c=\"blue\",\n",
    "                alpha=0.7,\n",
    "                s=60,\n",
    "                label=\"真实样本\",\n",
    "                edgecolors=\"black\",\n",
    "                linewidth=0.5,\n",
    "            )\n",
    "\n",
    "            # 虚拟点\n",
    "            if virtual_mask.any():\n",
    "                mud_mask = self.current_data[\"virtual_type\"] == \"mud\"\n",
    "                sand_mask = self.current_data[\"virtual_type\"] == \"sand\"\n",
    "\n",
    "                if mud_mask.any():\n",
    "                    ax1.scatter(X[mud_mask], y[mud_mask], c=\"brown\", alpha=0.5, s=30, marker=\"^\", label=\"虚拟点(泥岩)\")\n",
    "                if sand_mask.any():\n",
    "                    ax1.scatter(\n",
    "                        X[sand_mask], y[sand_mask], c=\"orange\", alpha=0.5, s=30, marker=\"v\", label=\"虚拟点(砂岩)\"\n",
    "                    )\n",
    "        else:\n",
    "            ax1.scatter(X, y, c=\"blue\", alpha=0.7, s=60, label=\"样本点\", edgecolors=\"black\", linewidth=0.5)\n",
    "\n",
    "        # 绘制拟合曲线\n",
    "        X_curve = np.linspace(X.min(), X.max(), 300)\n",
    "        y_curve = self.sigmoid(X_curve, *self.fit_params)\n",
    "        ax1.plot(X_curve, y_curve, \"red\", linewidth=2, label=\"Sigmoid拟合\")\n",
    "\n",
    "        # 添加模型信息\n",
    "        param_text = f\"L = {params['L']:.2f}\\n\"\n",
    "        param_text += f\"k = {params['k']:.3f}\\n\"\n",
    "        param_text += f\"x₀ = {params['x0']:.2f}\\n\"\n",
    "        param_text += f\"R² = {r2_score_val:.3f}\"\n",
    "\n",
    "        ax1.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            param_text,\n",
    "            transform=ax1.transAxes,\n",
    "            verticalalignment=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.8),\n",
    "        )\n",
    "\n",
    "        ax1.set_xlabel(\"特征值\")\n",
    "        ax1.set_ylabel(\"砂厚 (m)\")\n",
    "        ax1.set_title(\"Sigmoid函数拟合结果\")\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # 右图：残差分析\n",
    "        residuals = y - y_pred\n",
    "        ax2.scatter(y_pred, residuals, alpha=0.6, c=\"green\", s=40)\n",
    "        ax2.axhline(y=0, color=\"red\", linestyle=\"--\", alpha=0.8)\n",
    "        ax2.set_xlabel(\"预测值 (m)\")\n",
    "        ax2.set_ylabel(\"残差 (m)\")\n",
    "        ax2.set_title(\"残差分析\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        # 添加残差统计\n",
    "        residual_stats = f\"残差均值: {np.mean(residuals):.3f}\\n\"\n",
    "        residual_stats += f\"残差标准差: {np.std(residuals):.3f}\\n\"\n",
    "        residual_stats += f\"RMSE: {np.sqrt(np.mean(residuals**2)):.3f}\"\n",
    "\n",
    "        ax2.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            residual_stats,\n",
    "            transform=ax2.transAxes,\n",
    "            verticalalignment=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"lightgreen\", alpha=0.8),\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将prepare_sigmoid_data函数合并到主代码中，并复用可视化函数\n",
    "\n",
    "print(\"=== 开始 Sigmoid 建模 ===\")\n",
    "\n",
    "# 1. 准备建模数据（合并原prepare_sigmoid_data函数功能）\n",
    "sigmoid_data = pd.DataFrame()\n",
    "\n",
    "# 添加PCA特征\n",
    "n_components = min(3, well_pca_features.shape[1])\n",
    "for i in range(n_components):\n",
    "    sigmoid_data[f\"PC{i + 1}\"] = well_pca_features[:, i]\n",
    "\n",
    "# 添加砂厚\n",
    "sigmoid_data[\"Sand Thickness\"] = data_well_purpose_surface_filtered[\"Sand Thickness\"].values\n",
    "\n",
    "print(f\"Sigmoid建模数据形状: {sigmoid_data.shape}\")\n",
    "print(f\"可用的PCA特征: {[col for col in sigmoid_data.columns if col.startswith('PC')]}\")\n",
    "print(\"\\n数据预览:\")\n",
    "print(sigmoid_data.head())\n",
    "\n",
    "# 2. 创建Sigmoid模型\n",
    "pc_columns = [col for col in sigmoid_data.columns if col.startswith(\"PC\")]\n",
    "sigmoid_model = SigmoidModel(data=sigmoid_data, feature_columns=pc_columns, target_column=\"Sand Thickness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤1: 可视化原始样本分布\n",
    "print(\"\\n=== 步骤1: 可视化原始样本分布 ===\")\n",
    "\n",
    "# 使用visualize_feature_distribution函数（保持原有功能）\n",
    "fig1 = visualize_feature_distribution(\n",
    "    data=sigmoid_data,\n",
    "    x_feature=\"PC1\",\n",
    "    y_feature=\"Sand Thickness\",\n",
    "    figsize=(10, 6),\n",
    "    point_size=100,\n",
    "    alpha=0.7,\n",
    "    colormap=\"viridis\",\n",
    "    title=\"样本分布: PC1 vs Sand Thickness\",\n",
    "    save_path=os.path.join(output_dir, \"sigmoid_original_distribution.png\"),\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 分析数据特征\n",
    "pc1_min, pc1_max = sigmoid_data[\"PC1\"].min(), sigmoid_data[\"PC1\"].max()\n",
    "pc1_median = sigmoid_data[\"PC1\"].median()\n",
    "sand_thickness_max = sigmoid_data[\"Sand Thickness\"].max()\n",
    "sand_thickness_min = sigmoid_data[\"Sand Thickness\"].min()\n",
    "\n",
    "print(f\"\\n数据特征分析:\")\n",
    "print(f\"PC1范围: {pc1_min:.2f} 到 {pc1_max:.2f}\")\n",
    "print(f\"PC1中位数: {pc1_median:.2f}\")\n",
    "print(f\"砂厚范围: {sand_thickness_min:.2f} 到 {sand_thickness_max:.2f} m\")\n",
    "print(f\"样本数量: {len(sigmoid_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350acce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤2: 使用智能虚拟点并执行拟合\n",
    "print(f\"\\n=== 步骤2: Sigmoid拟合（智能虚拟点稳定器） ===\")\n",
    "\n",
    "# # 1. 手动指定泥岩区间（在PC1的[-5, 0]范围设置10个泥岩虚拟点）\n",
    "# virtual_config_manual_mud = {\n",
    "#     \"smart\": True,\n",
    "#     \"mud_range\": (-5, 0),      # 只设置泥岩虚拟点\n",
    "#     \"sand_range\": None,        # 不设置砂岩虚拟点\n",
    "#     \"n_points\": 10,\n",
    "#     \"noise_factor\": 0.05\n",
    "# }\n",
    "\n",
    "# # 2. 手动指定砂岩和泥岩区间\n",
    "# virtual_config_manual_both = {\n",
    "#     \"smart\": True,\n",
    "#     \"mud_range\": (-2, 0),      # 泥岩虚拟点范围\n",
    "#     \"sand_range\": (2, 5),      # 砂岩虚拟点范围\n",
    "#     \"n_points\": 10,\n",
    "#     \"noise_factor\": 0.05\n",
    "# }\n",
    "\n",
    "# 3. 使用改进的保守自动策略（推荐）\n",
    "virtual_config_conservative = {\n",
    "    \"smart\": True,\n",
    "    \"placement_strategy\": \"conservative\",  # 在数据范围内侧保守放置\n",
    "    \"n_points\": 15,\n",
    "    \"noise_factor\": 0.05,\n",
    "    \"auto_detect\": True,\n",
    "}\n",
    "\n",
    "# # 4. 使用传统的延伸策略\n",
    "# virtual_config_extended = {\n",
    "#     \"smart\": True,\n",
    "#     \"placement_strategy\": \"extended\",  # 在数据范围外侧延伸放置\n",
    "#     \"n_points\": 10,\n",
    "#     \"noise_factor\": 0.05,\n",
    "#     \"auto_detect\": True\n",
    "# }\n",
    "\n",
    "# # 5. 只设置砂岩虚拟点\n",
    "# virtual_config_sand_only = {\n",
    "#     \"smart\": True,\n",
    "#     \"mud_range\": None,         # 不设置泥岩虚拟点\n",
    "#     \"sand_range\": (2, 4),      # 只设置砂岩虚拟点\n",
    "#     \"n_points\": 10,\n",
    "#     \"noise_factor\": 0.05\n",
    "# }\n",
    "\n",
    "print(f\"智能虚拟点配置:\")\n",
    "print(f\"  模式: 智能自动检测\")\n",
    "print(f\"  每侧点数: {virtual_config_conservative['n_points']}\")\n",
    "print(f\"  噪音因子: {virtual_config_conservative['noise_factor']}\")\n",
    "\n",
    "# 执行拟合\n",
    "fit_result = sigmoid_model.fit(\n",
    "    use_features=[\"PC1\"],\n",
    "    virtual_points_config=virtual_config_conservative,\n",
    "    bounds=(\n",
    "        [sand_thickness_max * 0.2, -10, pc1_min - (pc1_max - pc1_min)],  # 下界\n",
    "        [sand_thickness_max * 3.0, 10, pc1_max + (pc1_max - pc1_min)],  # 上界\n",
    "    ),\n",
    "    initial_guess=[sand_thickness_max * 0.7, 1.0, pc1_median],\n",
    "    max_iterations=3000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤3: 可视化拟合结果\n",
    "if fit_result[\"success\"]:\n",
    "    print(\"\\n=== 拟合成功! ===\")\n",
    "\n",
    "    # 可视化拟合结果\n",
    "    fig2 = sigmoid_model.visualize_fit(\n",
    "        fit_result, figsize=(15, 6), save_path=os.path.join(output_dir, \"sigmoid_fit_result.png\")\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # 输出详细的拟合参数\n",
    "    print(\"\\n拟合参数:\")\n",
    "    params = fit_result[\"params\"]\n",
    "    param_errors = fit_result[\"param_errors\"]\n",
    "    for param in [\"L\", \"k\", \"x0\"]:\n",
    "        print(f\"  {param}: {params[param]:.4f} ± {param_errors[param + '_err']:.4f}\")\n",
    "    print(f\"  R² score: {fit_result['r2_score']:.4f}\")\n",
    "\n",
    "    # 解释参数含义\n",
    "    print(f\"\\n参数解释:\")\n",
    "    print(f\"  L = {params['L']:.2f}: 最大砂厚渐近值 (m)\")\n",
    "    print(f\"  k = {params['k']:.3f}: 增长率 ({'正向增长' if params['k'] > 0 else '负向增长'})\")\n",
    "    print(f\"  x₀ = {params['x0']:.2f}: 中点位置（PC1值）\")\n",
    "\n",
    "    # 计算拟合质量指标\n",
    "    rmse = np.sqrt(np.mean((fit_result[\"y\"] - fit_result[\"y_pred\"]) ** 2))\n",
    "    mae = np.mean(np.abs(fit_result[\"y\"] - fit_result[\"y_pred\"]))\n",
    "    print(f\"\\n拟合质量:\")\n",
    "    print(f\"  RMSE: {rmse:.3f} m\")\n",
    "    print(f\"  MAE: {mae:.3f} m\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n=== 拟合失败 ===\")\n",
    "    print(f\"错误信息: {fit_result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤4: 多特征拟合尝试（如果有PC2）\n",
    "if \"PC2\" in sigmoid_data.columns and fit_result[\"success\"]:\n",
    "    print(f\"\\n=== 步骤4: 多特征组合拟合 ===\")\n",
    "\n",
    "    # 使用PC1+PC2组合，权重根据方差贡献比设置\n",
    "    explained_ratio = pca_results[\"explained_variance_ratio\"]\n",
    "    if len(explained_ratio) >= 2:\n",
    "        # 根据方差贡献比设置权重\n",
    "        total_var = explained_ratio[0] + explained_ratio[1]\n",
    "        pc1_weight = explained_ratio[0] / total_var\n",
    "        pc2_weight = explained_ratio[1] / total_var\n",
    "\n",
    "        print(f\"使用PC1+PC2组合:\")\n",
    "        print(f\"  PC1权重: {pc1_weight:.3f} (方差贡献: {explained_ratio[0]:.3f})\")\n",
    "        print(f\"  PC2权重: {pc2_weight:.3f} (方差贡献: {explained_ratio[1]:.3f})\")\n",
    "\n",
    "        # 多特征拟合 - 修正虚拟点配置变量名\n",
    "        fit_result_multi = sigmoid_model.fit(\n",
    "            use_features=[\"PC1\", \"PC2\"],\n",
    "            feature_weights=[pc1_weight, pc2_weight],\n",
    "            virtual_points_config=virtual_config_conservative,  # 使用智能虚拟点配置\n",
    "            bounds=([sand_thickness_max * 0.2, -10, -5], [sand_thickness_max * 3.0, 10, 5]),\n",
    "            max_iterations=3000,\n",
    "        )\n",
    "\n",
    "        if fit_result_multi[\"success\"]:\n",
    "            print(\"多特征拟合成功!\")\n",
    "            fig3 = sigmoid_model.visualize_fit(\n",
    "                fit_result_multi, figsize=(15, 6), save_path=os.path.join(output_dir, \"sigmoid_multi_feature_fit.png\")\n",
    "            )\n",
    "            plt.show()\n",
    "\n",
    "            # 比较单特征和多特征结果\n",
    "            print(f\"\\n性能比较:\")\n",
    "            print(f\"  单特征(PC1) R²: {fit_result['r2_score']:.4f}\")\n",
    "            print(f\"  多特征(PC1+PC2) R²: {fit_result_multi['r2_score']:.4f}\")\n",
    "            print(f\"  R²提升: {fit_result_multi['r2_score'] - fit_result['r2_score']:.4f}\")\n",
    "\n",
    "            # 选择更好的模型\n",
    "            if fit_result_multi[\"r2_score\"] > fit_result[\"r2_score\"]:\n",
    "                print(\"  → 多特征模型表现更好\")\n",
    "                best_fit = fit_result_multi\n",
    "                best_model_name = \"多特征(PC1+PC2)\"\n",
    "            else:\n",
    "                print(\"  → 单特征模型表现更好\")\n",
    "                best_fit = fit_result\n",
    "                best_model_name = \"单特征(PC1)\"\n",
    "        else:\n",
    "            print(f\"多特征拟合失败: {fit_result_multi['error']}\")\n",
    "            best_fit = fit_result\n",
    "            best_model_name = \"单特征(PC1)\"\n",
    "    else:\n",
    "        best_fit = fit_result\n",
    "        best_model_name = \"单特征(PC1)\"\n",
    "else:\n",
    "    best_fit = fit_result\n",
    "    best_model_name = \"单特征(PC1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25027914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤5: 保存模型结果并预测全工区\n",
    "if best_fit[\"success\"]:\n",
    "    print(f\"\\n=== 步骤5: 保存结果并预测全工区 ===\")\n",
    "\n",
    "    # 保存拟合参数和模型信息\n",
    "    fit_summary = {\n",
    "        \"model_type\": \"sigmoid\",\n",
    "        \"best_model\": best_model_name,\n",
    "        \"features_used\": str(best_fit[\"use_features\"]),\n",
    "        \"feature_weights\": str(best_fit.get(\"feature_weights\", \"None\")),\n",
    "        \"n_samples\": len(sigmoid_data),\n",
    "        \"n_virtual_points\": len(sigmoid_model.current_data) - len(sigmoid_data),\n",
    "        \"virtual_config\": str(virtual_config_conservative),\n",
    "        **best_fit[\"params\"],\n",
    "        **best_fit[\"param_errors\"],\n",
    "        \"r2_score\": best_fit[\"r2_score\"],\n",
    "        \"rmse\": np.sqrt(np.mean((best_fit[\"y\"] - best_fit[\"y_pred\"]) ** 2)),\n",
    "        \"mae\": np.mean(np.abs(best_fit[\"y\"] - best_fit[\"y_pred\"])),\n",
    "    }\n",
    "\n",
    "    # 保存模型摘要\n",
    "    summary_df = pd.DataFrame([fit_summary])\n",
    "    summary_df.to_csv(os.path.join(output_dir, \"sigmoid_model_summary.csv\"), index=False)\n",
    "    print(f\"模型摘要已保存到: {os.path.join(output_dir, 'sigmoid_model_summary.csv')}\")\n",
    "\n",
    "    # 对全工区进行预测\n",
    "    print(\"\\n对全工区进行砂厚预测...\")\n",
    "\n",
    "    # 准备全工区PCA特征\n",
    "    seismic_pca_features = pca_results[\"pca\"].transform(pca_results[\"features_scaled\"])\n",
    "    seismic_pca_df = pd.DataFrame()\n",
    "\n",
    "    # 根据最佳模型使用的特征数量准备数据\n",
    "    max_components = len(best_fit[\"use_features\"])\n",
    "    for i in range(max_components):\n",
    "        seismic_pca_df[f\"PC{i + 1}\"] = seismic_pca_features[:, i]\n",
    "\n",
    "    # 使用最佳模型进行预测\n",
    "    predicted_thickness = sigmoid_model.predict(\n",
    "        seismic_pca_df, use_features=best_fit[\"use_features\"], feature_weights=best_fit.get(\"feature_weights\")\n",
    "    )\n",
    "\n",
    "    # 创建预测结果DataFrame\n",
    "    prediction_results = pca_results[\"coords_clean\"].copy()\n",
    "    prediction_results[\"Predicted_Sand_Thickness\"] = predicted_thickness\n",
    "\n",
    "    # 添加模型信息列\n",
    "    prediction_results[\"Model_Type\"] = best_model_name\n",
    "    prediction_results[\"Model_R2\"] = best_fit[\"r2_score\"]\n",
    "\n",
    "    # 保存预测结果\n",
    "    prediction_results.to_csv(os.path.join(output_dir, \"predicted_sand_thickness.csv\"), index=False)\n",
    "    print(f\"预测结果已保存到: {os.path.join(output_dir, 'predicted_sand_thickness.csv')}\")\n",
    "\n",
    "    # 显示预测统计\n",
    "    print(f\"\\n预测结果统计:\")\n",
    "    print(f\"  预测样本数: {len(prediction_results)}\")\n",
    "    print(f\"  预测砂厚范围: {predicted_thickness.min():.2f} - {predicted_thickness.max():.2f} m\")\n",
    "    print(f\"  预测砂厚均值: {predicted_thickness.mean():.2f} m\")\n",
    "    print(f\"  预测砂厚标准差: {predicted_thickness.std():.2f} m\")\n",
    "    print(f\"  使用模型: {best_model_name}\")\n",
    "    print(f\"  模型R²: {best_fit['r2_score']:.4f}\")\n",
    "\n",
    "    # 与真实砂厚对比（在预测范围内）\n",
    "    real_thickness = sigmoid_data[\"Sand Thickness\"].values\n",
    "    print(f\"\\n与井点砂厚对比:\")\n",
    "    print(f\"  井点砂厚范围: {real_thickness.min():.2f} - {real_thickness.max():.2f} m\")\n",
    "    print(f\"  井点砂厚均值: {real_thickness.mean():.2f} m\")\n",
    "    print(\n",
    "        f\"  预测覆盖率: {100 * (predicted_thickness.max() >= real_thickness.max() and predicted_thickness.min() <= real_thickness.min()):.0f}%\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Sigmoid建模完成! ===\")\n",
    "    print(f\"最佳模型: {best_model_name} (R² = {best_fit['r2_score']:.4f})\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n模型拟合失败，无法进行后续预测\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce28f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤6: 使用visualize_attribute_map复用可视化预测结果\n",
    "if best_fit[\"success\"]:\n",
    "    print(f\"\\n=== 步骤6: 可视化预测结果 ===\")\n",
    "\n",
    "    # 1. 使用visualize_attribute_map函数可视化预测结果的空间分布\n",
    "    print(\"生成预测砂厚空间分布图...\")\n",
    "    visualize_attribute_map(\n",
    "        data_points=prediction_results,\n",
    "        attribute_name=\"Predicted_Sand_Thickness\",\n",
    "        attribute_label=\"预测砂厚 (m)\",\n",
    "        real_wells=data_well_purpose_surface_filtered,\n",
    "        pseudo_wells=None,  # 没有虚拟井点\n",
    "        target_column=\"Sand Thickness\",\n",
    "        output_dir=output_dir,\n",
    "        filename_prefix=\"sigmoid_prediction\",\n",
    "        class_thresholds=[1, 10],\n",
    "        figsize=(14, 10),\n",
    "        dpi=300,\n",
    "        cmap=\"viridis\",\n",
    "        point_size=150,\n",
    "        well_size=200,\n",
    "        vrange=None,  # 使用数据自身范围\n",
    "    )\n",
    "\n",
    "    # 2. 创建详细的预测分析图表\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # 子图1: 预测值 vs 真实值（井点处）\n",
    "    plt.subplot(2, 2, 1)\n",
    "    # 在井点位置提取预测值进行对比\n",
    "    well_coords = data_well_purpose_surface_filtered[[\"X\", \"Y\"]].values\n",
    "    pred_coords = prediction_results[[\"X\", \"Y\"]].values\n",
    "\n",
    "    # 找到最近的预测点\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    distances = cdist(well_coords, pred_coords)\n",
    "    closest_indices = np.argmin(distances, axis=1)\n",
    "    well_predictions = predicted_thickness[closest_indices]\n",
    "\n",
    "    plt.scatter(sigmoid_data[\"Sand Thickness\"], well_predictions, alpha=0.7, s=80, edgecolors=\"black\")\n",
    "\n",
    "    # 添加1:1参考线\n",
    "    min_val = min(sigmoid_data[\"Sand Thickness\"].min(), well_predictions.min())\n",
    "    max_val = max(sigmoid_data[\"Sand Thickness\"].max(), well_predictions.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], \"r--\", alpha=0.8, linewidth=2)\n",
    "\n",
    "    plt.xlabel(\"真实砂厚 (m)\")\n",
    "    plt.ylabel(\"预测砂厚 (m)\")\n",
    "    plt.title(\"预测 vs 真实砂厚\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 计算并显示相关系数\n",
    "    correlation = np.corrcoef(sigmoid_data[\"Sand Thickness\"], well_predictions)[0, 1]\n",
    "    plt.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"相关系数: {correlation:.3f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    # 子图2: 预测砂厚直方图对比\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(predicted_thickness, bins=50, alpha=0.7, color=\"skyblue\", label=f\"预测砂厚 (n={len(predicted_thickness)})\")\n",
    "    plt.hist(\n",
    "        sigmoid_data[\"Sand Thickness\"], bins=20, alpha=0.7, color=\"orange\", label=f\"井点砂厚 (n={len(sigmoid_data)})\"\n",
    "    )\n",
    "    plt.xlabel(\"砂厚 (m)\")\n",
    "    plt.ylabel(\"频数\")\n",
    "    plt.title(\"砂厚分布对比\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 子图3: 残差分布\n",
    "    plt.subplot(2, 2, 3)\n",
    "    residuals_well = sigmoid_data[\"Sand Thickness\"].values - well_predictions\n",
    "    plt.hist(residuals_well, bins=15, alpha=0.7, color=\"lightcoral\")\n",
    "    plt.axvline(x=0, color=\"red\", linestyle=\"--\", alpha=0.8)\n",
    "    plt.xlabel(\"残差 (真实 - 预测)\")\n",
    "    plt.ylabel(\"频数\")\n",
    "    plt.title(\"井点处残差分布\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # 添加残差统计\n",
    "    residual_stats = f\"均值: {np.mean(residuals_well):.3f}\\n标准差: {np.std(residuals_well):.3f}\"\n",
    "    plt.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        residual_stats,\n",
    "        transform=plt.gca().transAxes,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    # 子图4: 模型性能摘要\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.axis(\"off\")  # 关闭坐标轴\n",
    "\n",
    "    # 准备性能摘要文本\n",
    "    performance_text = f\"\"\"\n",
    "模型性能摘要\n",
    "\n",
    "最佳模型: {best_model_name}\n",
    "R^2 评分: {best_fit[\"r2_score\"]:.4f}\n",
    "RMSE: {np.sqrt(np.mean((best_fit[\"y\"] - best_fit[\"y_pred\"]) ** 2)):.3f} m\n",
    "MAE: {np.mean(np.abs(best_fit[\"y\"] - best_fit[\"y_pred\"])):.3f} m\n",
    "\n",
    "预测结果统计:\n",
    "1. 预测样本数: {len(prediction_results):,}\n",
    "2. 预测砂厚范围: {predicted_thickness.min():.2f} - {predicted_thickness.max():.2f} m\n",
    "3. 预测砂厚均值: {predicted_thickness.mean():.2f} m\n",
    "4. 预测砂厚标准差: {predicted_thickness.std():.2f} m\n",
    "\n",
    "井点对比:\n",
    "1. 井点砂厚范围: {sigmoid_data[\"Sand Thickness\"].min():.2f} - {sigmoid_data[\"Sand Thickness\"].max():.2f} m\n",
    "2. 井点砂厚均值: {sigmoid_data[\"Sand Thickness\"].mean():.2f} m\n",
    "3. 预测-实际相关系数: {correlation:.3f}\n",
    "    \"\"\"\n",
    "\n",
    "    plt.text(\n",
    "        0.1,\n",
    "        0.9,\n",
    "        performance_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=11,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8),\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"sigmoid_prediction_detailed_analysis.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"预测结果可视化已完成\")\n",
    "    print(f\"  - 空间分布图: sigmoid_prediction_map_with_wells.png\")\n",
    "    print(f\"  - 属性直方图: sigmoid_prediction_attribute_histogram.png\")\n",
    "    print(f\"  - 详细分析图: sigmoid_prediction_detailed_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取样本，准备设置虚拟井\n",
    "print(\"=== 提取样本，准备设置虚拟井 ===\")\n",
    "\n",
    "# 使用筛选后的地震数据区域提取等间距样本\n",
    "seismic_samples = extract_uniform_seismic_samples(\n",
    "    seismic_data=seismic_attr_filtered,\n",
    "    n_rows=20,\n",
    "    n_cols=20,\n",
    "    area_bounds=area_bounds,  # 使用之前定义的区域边界\n",
    ")\n",
    "\n",
    "# 可视化真实井点和采样点\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 绘制地震数据点（使用抽样）\n",
    "sample_ratio = min(1.0, 5000 / len(seismic_attr_filtered))\n",
    "seismic_sample = seismic_attr_filtered.sample(frac=sample_ratio)\n",
    "plt.scatter(seismic_sample[\"X\"], seismic_sample[\"Y\"], color=\"lightgray\", alpha=0.3, s=10, label=\"地震数据(抽样)\")\n",
    "\n",
    "# 绘制真实井点位置\n",
    "plt.scatter(\n",
    "    data_well_purpose_surface_filtered[\"X\"],\n",
    "    data_well_purpose_surface_filtered[\"Y\"],\n",
    "    color=\"red\",\n",
    "    s=100,\n",
    "    marker=\"^\",\n",
    "    label=\"真实井点\",\n",
    ")\n",
    "\n",
    "# 绘制等间距采样点位置\n",
    "plt.scatter(seismic_samples[\"X\"], seismic_samples[\"Y\"], color=\"blue\", s=50, marker=\"o\", label=\"等间距采样点\")\n",
    "\n",
    "# 添加标题和图例\n",
    "plt.title(\"真实井点与等间距采样点分布\", fontsize=16)\n",
    "plt.xlabel(\"X坐标\", fontsize=14)\n",
    "plt.ylabel(\"Y坐标\", fontsize=14)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# 保存图片\n",
    "plt.savefig(os.path.join(output_dir, \"real_wells_and_seismic_samples.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# 保存提取的样本数据\n",
    "seismic_samples.to_csv(os.path.join(output_dir, \"seismic_samples.csv\"), index=False)\n",
    "print(f\"等间距地震样本数据已保存至 {os.path.join(output_dir, 'seismic_samples.csv')}\")\n",
    "\n",
    "print(f\"提取的样本数量: {len(seismic_samples)}\")\n",
    "print(\n",
    "    f\"样本分布区域: X({seismic_samples['X'].min():.1f} - {seismic_samples['X'].max():.1f}), \"\n",
    "    f\"Y({seismic_samples['Y'].min():.1f} - {seismic_samples['Y'].max():.1f})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eccc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Sigmoid模型预测虚拟井砂厚\n",
    "print(\"=== 使用Sigmoid模型预测虚拟井砂厚 ===\")\n",
    "\n",
    "if best_fit[\"success\"]:\n",
    "    # 为地震样本点提取PCA特征\n",
    "    sample_features = seismic_samples[pca_results[\"features_clean\"].columns].values\n",
    "\n",
    "    # 使用相同的标准化器和PCA模型变换样本数据\n",
    "    sample_features_scaled = pca_results[\"scaler\"].transform(sample_features)\n",
    "    sample_pca_features = pca_results[\"pca\"].transform(sample_features_scaled)\n",
    "\n",
    "    # 准备样本的PCA特征DataFrame\n",
    "    sample_pca_df = pd.DataFrame()\n",
    "    max_components = len(best_fit[\"use_features\"])\n",
    "    for i in range(max_components):\n",
    "        sample_pca_df[f\"PC{i + 1}\"] = sample_pca_features[:, i]\n",
    "\n",
    "    # 使用最佳Sigmoid模型进行预测\n",
    "    predicted_sample_thickness = sigmoid_model.predict(\n",
    "        sample_pca_df, use_features=best_fit[\"use_features\"], feature_weights=best_fit.get(\"feature_weights\")\n",
    "    )\n",
    "\n",
    "    # 将预测结果添加到样本数据\n",
    "    seismic_samples[\"Predicted_Sand_Thickness\"] = predicted_sample_thickness\n",
    "\n",
    "    # 将负值预测设为0\n",
    "    negative_count = (predicted_sample_thickness < 0).sum()\n",
    "    if negative_count > 0:\n",
    "        print(f\"注意: {negative_count} 个负的砂厚预测值已被替换为0\")\n",
    "        seismic_samples[\"Predicted_Sand_Thickness\"] = seismic_samples[\"Predicted_Sand_Thickness\"].clip(lower=0)\n",
    "\n",
    "    # 显示预测统计\n",
    "    print(f\"\\n虚拟井砂厚预测统计:\")\n",
    "    print(f\"  样本数量: {len(seismic_samples)}\")\n",
    "    print(\n",
    "        f\"  预测砂厚范围: {seismic_samples['Predicted_Sand_Thickness'].min():.2f} - {seismic_samples['Predicted_Sand_Thickness'].max():.2f} m\"\n",
    "    )\n",
    "    print(f\"  预测砂厚均值: {seismic_samples['Predicted_Sand_Thickness'].mean():.2f} m\")\n",
    "    print(f\"  预测砂厚标准差: {seismic_samples['Predicted_Sand_Thickness'].std():.2f} m\")\n",
    "\n",
    "    # 保存带预测结果的虚拟井数据\n",
    "    seismic_samples.to_csv(os.path.join(output_dir, \"virtual_wells_with_predictions.csv\"), index=False)\n",
    "    print(f\"虚拟井预测结果已保存至 {os.path.join(output_dir, 'virtual_wells_with_predictions.csv')}\")\n",
    "\n",
    "else:\n",
    "    print(\"Sigmoid模型拟合失败，无法生成虚拟井预测\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 虚拟井优化选择（基于距离和砂厚分布）\n",
    "print(\"=== 虚拟井优化选择（基于距离和砂厚分布）===\")\n",
    "\n",
    "if best_fit[\"success\"]:\n",
    "    from scipy.spatial.distance import cdist\n",
    "    import numpy as np\n",
    "\n",
    "    # 准备数据\n",
    "    virtual_wells_data = seismic_samples.copy()  # 避免变量冲突\n",
    "    real_wells_data = data_well_purpose_surface_filtered.copy()\n",
    "\n",
    "    print(f\"开始优化筛选，初始虚拟井数量: {len(virtual_wells_data)}\")\n",
    "\n",
    "    # === 第一层筛选：排除靠近真实井点且砂厚差异大的点 ===\n",
    "    print(\"\\n第一层筛选：排除靠近真实井点且砂厚差异大的点...\")\n",
    "\n",
    "    proximity_radius = 100  # 米，设置排除半径\n",
    "    max_thickness_diff = 5.0  # 米，最大允许砂厚差异（适当放宽）\n",
    "\n",
    "    # 获取真实井点的坐标和砂厚\n",
    "    real_coords = real_wells_data[[\"X\", \"Y\"]].values\n",
    "    real_thickness = real_wells_data[\"Sand Thickness\"].values\n",
    "\n",
    "    # 获取虚拟井的坐标和预测砂厚\n",
    "    virtual_coords = virtual_wells_data[[\"X\", \"Y\"]].values\n",
    "    virtual_thickness = virtual_wells_data[\"Predicted_Sand_Thickness\"].values\n",
    "\n",
    "    # 计算每个虚拟井到所有真实井的距离\n",
    "    distances = cdist(virtual_coords, real_coords)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "    closest_well_indices = np.argmin(distances, axis=1)\n",
    "\n",
    "    # 标记需要排除的虚拟井\n",
    "    exclude_mask = np.zeros(len(virtual_wells_data), dtype=bool)\n",
    "    excluded_count = 0\n",
    "\n",
    "    for i in range(len(virtual_wells_data)):\n",
    "        closest_well_idx = closest_well_indices[i]\n",
    "        distance_to_closest = min_distances[i]\n",
    "\n",
    "        if distance_to_closest <= proximity_radius:\n",
    "            thickness_diff = abs(virtual_thickness[i] - real_thickness[closest_well_idx])\n",
    "            if thickness_diff > max_thickness_diff:\n",
    "                exclude_mask[i] = True\n",
    "                excluded_count += 1\n",
    "\n",
    "    # 应用排除掩码\n",
    "    layer1_filtered = virtual_wells_data[~exclude_mask].copy().reset_index(drop=True)\n",
    "    print(f\"第一层筛选完成：排除了 {excluded_count} 个点，剩余 {len(layer1_filtered)} 个点\")\n",
    "\n",
    "    # === 第二层筛选：基于距离的贪心选择 ===\n",
    "    print(\"\\n第二层筛选：基于距离的贪心选择...\")\n",
    "\n",
    "    min_virtual_distance = 200  # 虚拟井之间最小距离（米）\n",
    "    min_real_distance = 150  # 虚拟井与真实井最小距离（米）\n",
    "\n",
    "    # 计算虚拟井之间的距离矩阵\n",
    "    layer1_coords = layer1_filtered[[\"X\", \"Y\"]].values\n",
    "    virtual_distances = cdist(layer1_coords, layer1_coords)\n",
    "\n",
    "    # 计算虚拟井到真实井的距离\n",
    "    distances_to_real = cdist(layer1_coords, real_coords)\n",
    "    min_distances_to_real = np.min(distances_to_real, axis=1)\n",
    "\n",
    "    # 按砂厚预测值排序，优先选择有代表性的砂厚值\n",
    "    thickness_values = layer1_filtered[\"Predicted_Sand_Thickness\"].values\n",
    "    thickness_order = np.argsort(thickness_values)\n",
    "\n",
    "    selected_indices = []\n",
    "\n",
    "    for idx in thickness_order:\n",
    "        # 检查与真实井的距离\n",
    "        if min_distances_to_real[idx] < min_real_distance:\n",
    "            continue\n",
    "\n",
    "        # 检查与已选虚拟井的距离\n",
    "        too_close = False\n",
    "        for selected_idx in selected_indices:\n",
    "            if virtual_distances[idx, selected_idx] < min_virtual_distance:\n",
    "                too_close = True\n",
    "                break\n",
    "\n",
    "        if not too_close:\n",
    "            selected_indices.append(idx)\n",
    "\n",
    "    layer2_filtered = layer1_filtered.iloc[selected_indices].copy().reset_index(drop=True)\n",
    "    print(f\"第二层筛选完成：选择了 {len(layer2_filtered)} 个距离合适的点\")\n",
    "\n",
    "    # === 第三层筛选：基于砂厚分布的均衡选择 ===\n",
    "    print(\"\\n第三层筛选：基于砂厚分布的均衡选择...\")\n",
    "\n",
    "    # 定义砂厚区间\n",
    "    thickness_bins = [0, 1, 10, 20, np.inf]\n",
    "    bin_labels = [\"0-1m\", \"1-10m\", \"10-20m\", \">20m\"]\n",
    "\n",
    "    # 每个区间最多选择的样本数\n",
    "    max_samples_per_bin = 30\n",
    "    min_samples_per_bin = 5\n",
    "\n",
    "    final_selected_indices = []\n",
    "\n",
    "    for i in range(len(thickness_bins) - 1):\n",
    "        # 获取该区间的虚拟井\n",
    "        bin_mask = (layer2_filtered[\"Predicted_Sand_Thickness\"] >= thickness_bins[i]) & (\n",
    "            layer2_filtered[\"Predicted_Sand_Thickness\"] < thickness_bins[i + 1]\n",
    "        )\n",
    "        bin_indices = layer2_filtered.index[bin_mask].tolist()\n",
    "\n",
    "        if len(bin_indices) == 0:\n",
    "            print(f\"  区间 {bin_labels[i]}: 无可用样本\")\n",
    "            continue\n",
    "\n",
    "        # 如果样本数超过最大限制，随机选择\n",
    "        if len(bin_indices) > max_samples_per_bin:\n",
    "            selected_bin_indices = np.random.choice(bin_indices, max_samples_per_bin, replace=False).tolist()\n",
    "        else:\n",
    "            selected_bin_indices = bin_indices\n",
    "\n",
    "        final_selected_indices.extend(selected_bin_indices)\n",
    "        print(f\"  区间 {bin_labels[i]}: 从 {len(bin_indices)} 个中选择了 {len(selected_bin_indices)} 个\")\n",
    "\n",
    "    # 生成最终优化的虚拟井数据\n",
    "    optimized_virtual_wells = layer2_filtered.loc[final_selected_indices].copy().reset_index(drop=True)\n",
    "\n",
    "    print(f\"\\n虚拟井优化筛选结果:\")\n",
    "    print(f\"  原始虚拟井数量: {len(virtual_wells_data)}\")\n",
    "    print(f\"  第一层筛选后: {len(layer1_filtered)}\")\n",
    "    print(f\"  第二层筛选后: {len(layer2_filtered)}\")\n",
    "    print(f\"  最终优化数量: {len(optimized_virtual_wells)}\")\n",
    "\n",
    "    # 保存优化后的虚拟井\n",
    "    optimized_virtual_wells.to_csv(os.path.join(output_dir, \"optimized_virtual_wells.csv\"), index=False)\n",
    "\n",
    "    # 统计最终分布\n",
    "    print(f\"\\n最终砂厚分布:\")\n",
    "    for i in range(len(thickness_bins) - 1):\n",
    "        bin_mask = (optimized_virtual_wells[\"Predicted_Sand_Thickness\"] >= thickness_bins[i]) & (\n",
    "            optimized_virtual_wells[\"Predicted_Sand_Thickness\"] < thickness_bins[i + 1]\n",
    "        )\n",
    "        bin_count = bin_mask.sum()\n",
    "        bin_percent = bin_count / len(optimized_virtual_wells) * 100 if len(optimized_virtual_wells) > 0 else 0\n",
    "        print(f\"  {bin_labels[i]}: {bin_count} 个 ({bin_percent:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"Sigmoid模型拟合失败，无法进行虚拟井优化\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 虚拟井展示和分析\n",
    "print(\"=== 虚拟井展示和分析 ===\")\n",
    "\n",
    "if best_fit[\"success\"]:\n",
    "    # 1. 为整个地震数据区域预测砂厚\n",
    "    print(\"为整个地震数据区域预测砂厚...\")\n",
    "\n",
    "    # 为地震数据提取PCA特征\n",
    "    seismic_features = seismic_attr_filtered[pca_results[\"features_clean\"].columns].values\n",
    "\n",
    "    # 使用相同的标准化器和PCA模型变换地震数据\n",
    "    seismic_features_scaled = pca_results[\"scaler\"].transform(seismic_features)\n",
    "    seismic_pca_features = pca_results[\"pca\"].transform(seismic_features_scaled)\n",
    "\n",
    "    # 准备地震数据的PCA特征DataFrame\n",
    "    seismic_pca_df = pd.DataFrame()\n",
    "    max_components = len(best_fit[\"use_features\"])\n",
    "    for i in range(max_components):\n",
    "        seismic_pca_df[f\"PC{i + 1}\"] = seismic_pca_features[:, i]\n",
    "\n",
    "    # 使用最佳Sigmoid模型预测整个地震数据区域的砂厚\n",
    "    seismic_predicted_thickness = sigmoid_model.predict(\n",
    "        seismic_pca_df, use_features=best_fit[\"use_features\"], feature_weights=best_fit.get(\"feature_weights\")\n",
    "    )\n",
    "\n",
    "    # 将负值预测设为0\n",
    "    seismic_predicted_thickness = np.maximum(seismic_predicted_thickness, 0)\n",
    "\n",
    "    # 将预测结果添加到地震数据中\n",
    "    seismic_attr_filtered_with_pred = seismic_attr_filtered.copy()\n",
    "    seismic_attr_filtered_with_pred[\"Predicted_Sand_Thickness\"] = seismic_predicted_thickness\n",
    "\n",
    "    print(f\"整个地震数据区域预测完成，预测点数: {len(seismic_attr_filtered_with_pred)}\")\n",
    "\n",
    "    # 2. 使用优化后的虚拟井数据进行可视化\n",
    "    print(\"生成虚拟井砂厚分布图...\")\n",
    "\n",
    "    # 准备真实井点数据\n",
    "    real_wells = data_well_purpose_surface_filtered.copy()\n",
    "\n",
    "    # 使用优化后的虚拟井点数据（而不是原始的seismic_samples）\n",
    "    if \"optimized_virtual_wells\" in locals() and len(optimized_virtual_wells) > 0:\n",
    "        pseudo_wells = optimized_virtual_wells.copy()\n",
    "        print(f\"使用优化后的虚拟井数据: {len(pseudo_wells)} 个\")\n",
    "    else:\n",
    "        pseudo_wells = seismic_samples.copy()\n",
    "        print(f\"使用原始虚拟井数据: {len(pseudo_wells)} 个\")\n",
    "        print(\"警告：未找到优化后的虚拟井数据，使用原始数据\")\n",
    "\n",
    "    # 可视化虚拟井砂厚分布\n",
    "    visualize_attribute_map(\n",
    "        data_points=seismic_attr_filtered_with_pred,\n",
    "        attribute_name=\"Predicted_Sand_Thickness\",\n",
    "        attribute_label=\"预测砂厚 (m)\",\n",
    "        real_wells=real_wells,\n",
    "        pseudo_wells=pseudo_wells,  # 现在使用的是优化后的数据\n",
    "        target_column=\"Sand Thickness\",\n",
    "        output_dir=output_dir,\n",
    "        filename_prefix=\"virtual_wells_optimized\",  # 修改文件名以区分\n",
    "        class_thresholds=[1, 10],\n",
    "        figsize=(16, 14),\n",
    "        dpi=300,\n",
    "        cmap=\"viridis\",\n",
    "        point_size=140,\n",
    "        well_size=200,\n",
    "    )\n",
    "\n",
    "    # 3. 创建真实井和虚拟井砂厚分布对比\n",
    "    print(\"创建真实井和虚拟井砂厚分布对比...\")\n",
    "\n",
    "    # 提取真实井和虚拟井的砂厚数据\n",
    "    real_thickness = real_wells[\"Sand Thickness\"].values\n",
    "    virtual_thickness = pseudo_wells[\"Predicted_Sand_Thickness\"].values\n",
    "\n",
    "    # 设置砂厚区间\n",
    "    max_thickness = max(np.max(real_thickness), np.max(virtual_thickness))\n",
    "    thickness_bins = [0, 1, 10, 20, max_thickness + 1]\n",
    "    thickness_labels = [\"0-1\", \"1-10\", \"10-20\", f\">20\"]\n",
    "\n",
    "    # 计算各区间的井点数量\n",
    "    real_hist, _ = np.histogram(real_thickness, bins=thickness_bins)\n",
    "    virtual_hist, _ = np.histogram(virtual_thickness, bins=thickness_bins)\n",
    "\n",
    "    # 计算百分比\n",
    "    real_percent = real_hist / len(real_thickness) * 100\n",
    "    virtual_percent = virtual_hist / len(virtual_thickness) * 100\n",
    "\n",
    "    # 创建直方图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # 设置柱状图位置\n",
    "    bar_width = 0.35\n",
    "    r1 = np.arange(len(thickness_labels))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "\n",
    "    # 绘制真实井砂厚分布\n",
    "    plt.bar(r1, real_percent, width=bar_width, color=\"crimson\", alpha=0.7, label=\"真实井点砂厚\")\n",
    "\n",
    "    # 绘制虚拟井砂厚分布\n",
    "    plt.bar(r2, virtual_percent, width=bar_width, color=\"royalblue\", alpha=0.7, label=\"虚拟井点砂厚\")\n",
    "\n",
    "    # 添加数据标签\n",
    "    for i, v in enumerate(real_percent):\n",
    "        plt.text(r1[i], v + 1, f\"{v:.1f}%\", ha=\"center\", va=\"bottom\", fontweight=\"bold\", color=\"crimson\")\n",
    "\n",
    "    for i, v in enumerate(virtual_percent):\n",
    "        plt.text(r2[i], v + 1, f\"{v:.1f}%\", ha=\"center\", va=\"bottom\", fontweight=\"bold\", color=\"royalblue\")\n",
    "\n",
    "    # 设置图表属性\n",
    "    plt.xlabel(\"砂厚区间(米)\", fontsize=14)\n",
    "    plt.ylabel(\"百分比(%)\", fontsize=14)\n",
    "    plt.title(\"真实井点与虚拟井点砂厚分布对比\", fontsize=16)\n",
    "    plt.xticks([r + bar_width / 2 for r in range(len(thickness_labels))], thickness_labels)\n",
    "    plt.ylim(0, max(max(real_percent), max(virtual_percent)) * 1.2)\n",
    "\n",
    "    # 添加图例和网格\n",
    "    plt.legend(loc=\"upper right\", fontsize=12)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    # 保存图表\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"real_vs_virtual_thickness_histogram.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # 4. 详细统计信息对比\n",
    "    stats_data = {\n",
    "        \"统计指标\": [\"样本数量\", \"平均值(米)\", \"中位数(米)\", \"标准差(米)\", \"最小值(米)\", \"最大值(米)\"],\n",
    "        \"真实井点\": [\n",
    "            len(real_thickness),\n",
    "            np.mean(real_thickness),\n",
    "            np.median(real_thickness),\n",
    "            np.std(real_thickness),\n",
    "            np.min(real_thickness),\n",
    "            np.max(real_thickness),\n",
    "        ],\n",
    "        \"虚拟井点\": [\n",
    "            len(virtual_thickness),\n",
    "            np.mean(virtual_thickness),\n",
    "            np.median(virtual_thickness),\n",
    "            np.std(virtual_thickness),\n",
    "            np.min(virtual_thickness),\n",
    "            np.max(virtual_thickness),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # 创建DataFrame并打印\n",
    "    stats_df = pd.DataFrame(stats_data)\n",
    "    print(\"\\n砂厚统计信息对比:\")\n",
    "    print(\n",
    "        stats_df.to_string(\n",
    "            index=False,\n",
    "            formatters={\n",
    "                \"真实井点\": lambda x: f\"{x:.2f}\" if isinstance(x, float) else str(x),\n",
    "                \"虚拟井点\": lambda x: f\"{x:.2f}\" if isinstance(x, float) else str(x),\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 保存统计信息\n",
    "    stats_df.to_csv(os.path.join(output_dir, \"real_vs_virtual_thickness_stats.csv\"), index=False)\n",
    "\n",
    "    # 5. 虚拟井质量评估\n",
    "    print(\"\\n虚拟井质量评估:\")\n",
    "\n",
    "    # 计算虚拟井与真实井的距离分布\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    real_coords = real_wells[[\"X\", \"Y\"]].values\n",
    "    virtual_coords = pseudo_wells[[\"X\", \"Y\"]].values\n",
    "\n",
    "    # 计算每个虚拟井到最近真实井的距离\n",
    "    distances = cdist(virtual_coords, real_coords)\n",
    "    min_distances = np.min(distances, axis=1)\n",
    "\n",
    "    print(f\"  虚拟井到最近真实井的距离统计:\")\n",
    "    print(f\"    平均距离: {np.mean(min_distances):.1f} m\")\n",
    "    print(f\"    最小距离: {np.min(min_distances):.1f} m\")\n",
    "    print(f\"    最大距离: {np.max(min_distances):.1f} m\")\n",
    "    print(f\"    中位数距离: {np.median(min_distances):.1f} m\")\n",
    "\n",
    "    # 距离分布直方图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(min_distances, bins=20, alpha=0.7, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.xlabel(\"到最近真实井的距离 (m)\")\n",
    "    plt.ylabel(\"虚拟井数量\")\n",
    "    plt.title(\"虚拟井到最近真实井的距离分布\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(output_dir, \"virtual_wells_distance_distribution.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"虚拟井分析完成，所有结果已保存到输出目录\")\n",
    "    print(f\"  - 虚拟井空间分布图: virtual_wells_map_with_wells.png\")\n",
    "    print(f\"  - 砂厚分布对比图: real_vs_virtual_thickness_histogram.png\")\n",
    "    print(f\"  - 统计信息表: real_vs_virtual_thickness_stats.csv\")\n",
    "    print(f\"  - 距离分布图: virtual_wells_distance_distribution.png\")\n",
    "    print(f\"  - 虚拟井数据: virtual_wells_with_predictions.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"Sigmoid模型拟合失败，无法进行虚拟井分析\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-af",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
