{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac123577",
   "metadata": {},
   "source": [
    "# H6-2 基线测试：回归 & 分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab16758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保src目录在Python路径中\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# 导入模块\n",
    "from src.data_utils import identify_attributes, parse_petrel_file\n",
    "\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"  # 黑体 SimHei 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086c6d3c",
   "metadata": {},
   "source": [
    "## 导入地震数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d5866c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在解析文件: ../data/H6-2_attr\n",
      "正在识别文件属性: ../data/H6-2_attr\n",
      "识别到 END ATTRIBUTES 位于第 31 行\n",
      "识别到 14 个属性:\n",
      "  - Average envelope\n",
      "  - Average instantaneous frequency\n",
      "  - Average instantaneous phase\n",
      "  - Average peak value\n",
      "  - Geometric mean\n",
      "  - Half energy\n",
      "  - Harmonic mean\n",
      "  - Maximum amplitude\n",
      "  - Mean amplitude\n",
      "  - Minimum amplitude\n",
      "  - Most of\n",
      "  - RMS amplitude\n",
      "  - Sum of amplitudes\n",
      "  - Sum of energy\n",
      "解析到数据有 20 列\n",
      "总列数: 20, 其中:\n",
      "  - 3 列为坐标 (X, Y, Z)\n",
      "  - 3 列为占位符\n",
      "  - 14 列为属性\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program2025\\attribute_fusion\\src\\data_utils.py:100: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功读取数据，共 51714 行\n"
     ]
    }
   ],
   "source": [
    "data_H6_2_attr = parse_petrel_file(\"../data/H6-2_attr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f01d17",
   "metadata": {},
   "source": [
    "## 导入井震数据\n",
    "\n",
    "使用 xlsx / csv 数据，注意表名为 Sheet1，注意数据需包含表头\n",
    "\n",
    "请检查 excel 表头和下面代码中的 selected_columns 是否一致\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cef608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Well</th>\n",
       "      <th>Thickness of facies(1: Fine sand)</th>\n",
       "      <th>facies(1: Fine sand)</th>\n",
       "      <th>Average energy</th>\n",
       "      <th>Average envelope</th>\n",
       "      <th>Average instantaneous frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>Average peak value</th>\n",
       "      <th>Half energy</th>\n",
       "      <th>Harmonic mean</th>\n",
       "      <th>Maximum amplitude</th>\n",
       "      <th>Mean amplitude</th>\n",
       "      <th>Minimum amplitude</th>\n",
       "      <th>Most of</th>\n",
       "      <th>RMS amplitude</th>\n",
       "      <th>Sum of amplitudes</th>\n",
       "      <th>Sum of energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>686325.6</td>\n",
       "      <td>3217019.1</td>\n",
       "      <td>-2649.7</td>\n",
       "      <td>H6-2</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89001976.0</td>\n",
       "      <td>11011.2</td>\n",
       "      <td>21.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-4573.6</td>\n",
       "      <td>-1763.2</td>\n",
       "      <td>-8415.1</td>\n",
       "      <td>-14124.2</td>\n",
       "      <td>-13431.1</td>\n",
       "      <td>9511.8</td>\n",
       "      <td>-66162.7</td>\n",
       "      <td>718160960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>686616.5</td>\n",
       "      <td>3217415.2</td>\n",
       "      <td>-2633.0</td>\n",
       "      <td>H6-2</td>\n",
       "      <td>A10</td>\n",
       "      <td>7.87</td>\n",
       "      <td>45.82</td>\n",
       "      <td>76951152.0</td>\n",
       "      <td>11667.5</td>\n",
       "      <td>25.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-43402.7</td>\n",
       "      <td>4934.6</td>\n",
       "      <td>-4832.2</td>\n",
       "      <td>-15217.6</td>\n",
       "      <td>-13626.4</td>\n",
       "      <td>8764.0</td>\n",
       "      <td>-36986.6</td>\n",
       "      <td>724726848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>686278.0</td>\n",
       "      <td>3217627.9</td>\n",
       "      <td>-2650.4</td>\n",
       "      <td>H6-2</td>\n",
       "      <td>A11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6199530.0</td>\n",
       "      <td>2127.4</td>\n",
       "      <td>49.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>-1264.8</td>\n",
       "      <td>4551.3</td>\n",
       "      <td>623.9</td>\n",
       "      <td>-2246.4</td>\n",
       "      <td>-556.0</td>\n",
       "      <td>2459.4</td>\n",
       "      <td>2576.6</td>\n",
       "      <td>26151754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>686149.5</td>\n",
       "      <td>3216665.5</td>\n",
       "      <td>-2642.5</td>\n",
       "      <td>H6-2</td>\n",
       "      <td>A2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5.16</td>\n",
       "      <td>88260688.0</td>\n",
       "      <td>12334.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7747.0</td>\n",
       "      <td>1608.4</td>\n",
       "      <td>-7710.8</td>\n",
       "      <td>-15313.4</td>\n",
       "      <td>-14014.2</td>\n",
       "      <td>9393.7</td>\n",
       "      <td>-57804.2</td>\n",
       "      <td>667979712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>685921.1</td>\n",
       "      <td>3216986.2</td>\n",
       "      <td>-2644.7</td>\n",
       "      <td>H6-2</td>\n",
       "      <td>A4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31338386.0</td>\n",
       "      <td>5349.9</td>\n",
       "      <td>25.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3644.1</td>\n",
       "      <td>7899.5</td>\n",
       "      <td>4837.1</td>\n",
       "      <td>624.7</td>\n",
       "      <td>4900.9</td>\n",
       "      <td>5553.1</td>\n",
       "      <td>15000.3</td>\n",
       "      <td>97357456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X          Y       Z Surface Well  \\\n",
       "0  686325.6  3217019.1 -2649.7    H6-2   A1   \n",
       "1  686616.5  3217415.2 -2633.0    H6-2  A10   \n",
       "2  686278.0  3217627.9 -2650.4    H6-2  A11   \n",
       "3  686149.5  3216665.5 -2642.5    H6-2   A2   \n",
       "4  685921.1  3216986.2 -2644.7    H6-2   A4   \n",
       "\n",
       "   Thickness of facies(1: Fine sand)  facies(1: Fine sand)  Average energy  \\\n",
       "0                               0.00                  0.00      89001976.0   \n",
       "1                               7.87                 45.82      76951152.0   \n",
       "2                               0.00                  0.00       6199530.0   \n",
       "3                               0.75                  5.16      88260688.0   \n",
       "4                               0.00                  0.00      31338386.0   \n",
       "\n",
       "   Average envelope  Average instantaneous frequency  ...  Average peak value  \\\n",
       "0           11011.2                             21.9  ...                 NaN   \n",
       "1           11667.5                             25.9  ...                 NaN   \n",
       "2            2127.4                             49.7  ...                 NaN   \n",
       "3           12334.4                             21.0  ...                 NaN   \n",
       "4            5349.9                             25.9  ...                 NaN   \n",
       "\n",
       "   Half energy  Harmonic mean  Maximum amplitude  Mean amplitude  \\\n",
       "0          5.2        -4573.6            -1763.2         -8415.1   \n",
       "1          4.0       -43402.7             4934.6         -4832.2   \n",
       "2          7.2        -1264.8             4551.3           623.9   \n",
       "3          4.0        -7747.0             1608.4         -7710.8   \n",
       "4          7.0         3644.1             7899.5          4837.1   \n",
       "\n",
       "   Minimum amplitude  Most of  RMS amplitude  Sum of amplitudes  Sum of energy  \n",
       "0           -14124.2 -13431.1         9511.8           -66162.7      718160960  \n",
       "1           -15217.6 -13626.4         8764.0           -36986.6      724726848  \n",
       "2            -2246.4   -556.0         2459.4             2576.6       26151754  \n",
       "3           -15313.4 -14014.2         9393.7           -57804.2      667979712  \n",
       "4              624.7   4900.9         5553.1            15000.3       97357456  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_H6_2_well = \"../data/well_processed.xlsx\"\n",
    "data_H6_2_well = pd.read_excel(file_H6_2_well, sheet_name=\"Sheet1\")\n",
    "\n",
    "# 只选择 Surface 为 H6-2 的行，并丢弃砂厚为 NaN 的行\n",
    "data_H6_2_well_selected = (\n",
    "    data_H6_2_well[data_H6_2_well[\"Surface\"] == \"H6-2\"]\n",
    "    .replace(-999, np.nan)\n",
    "    .dropna(subset=[\"Thickness of facies(1: Fine sand)\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "data_H6_2_well_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d2e20",
   "metadata": {},
   "source": [
    "## 提取共同属性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432b6b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在识别文件属性: ../data/H6-2_attr\n",
      "识别到 END ATTRIBUTES 位于第 31 行\n",
      "识别到 14 个属性:\n",
      "  - Average envelope\n",
      "  - Average instantaneous frequency\n",
      "  - Average instantaneous phase\n",
      "  - Average peak value\n",
      "  - Geometric mean\n",
      "  - Half energy\n",
      "  - Harmonic mean\n",
      "  - Maximum amplitude\n",
      "  - Mean amplitude\n",
      "  - Minimum amplitude\n",
      "  - Most of\n",
      "  - RMS amplitude\n",
      "  - Sum of amplitudes\n",
      "  - Sum of energy\n",
      "地震属性数量: 14\n",
      "Excel属性数量: 14\n",
      "共同属性数量: 13\n",
      "\n",
      "共同属性列表:\n",
      "- Average instantaneous frequency\n",
      "- Mean amplitude\n",
      "- Average envelope\n",
      "- Most of\n",
      "- Average peak value\n",
      "- Sum of amplitudes\n",
      "- Sum of energy\n",
      "- RMS amplitude\n",
      "- Half energy\n",
      "- Minimum amplitude\n",
      "- Average instantaneous phase\n",
      "- Harmonic mean\n",
      "- Maximum amplitude\n"
     ]
    }
   ],
   "source": [
    "# 获取地震属性列表\n",
    "seismic_attr, _ = identify_attributes(\"../data/H6-2_attr\")\n",
    "\n",
    "# 提取Excel的属性列表（从第8列开始的所有列）\n",
    "well_seismic_attr = data_H6_2_well.columns[7:].tolist()\n",
    "\n",
    "# 计算两个列表的交集\n",
    "common_attributes = list(set(seismic_attr) & set(well_seismic_attr))\n",
    "\n",
    "# 打印结果\n",
    "print(f\"地震属性数量: {len(seismic_attr)}\")\n",
    "print(f\"Excel属性数量: {len(well_seismic_attr)}\")\n",
    "print(f\"共同属性数量: {len(common_attributes)}\")\n",
    "print(\"\\n共同属性列表:\")\n",
    "for attr in common_attributes:\n",
    "    print(f\"- {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89798856",
   "metadata": {},
   "source": [
    "## ✅ 总结建议（适用于你的砂厚预测任务）：\n",
    "\n",
    "- **快速筛选** → 用 **相关性 + 方差过滤**\n",
    "- **建模前重要性分析** → 用 **随机森林 / XGBoost 重要性**\n",
    "- **模型训练后解释特征贡献** → 用 **SHAP 排序 + 可视化**\n",
    "- **高维 + 稀疏特征** → 可以用 **LASSO 或 RFE 进一步压缩特征维度**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523bf33",
   "metadata": {},
   "source": [
    "## 函数：分析砂厚与地震属性的相关系数 & 可视化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75329739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlations(\n",
    "    df,\n",
    "    target_col=\"Thickness of LITHOLOGIES(1: sand)\",\n",
    "    start_col_idx=7,\n",
    "    method=\"spearman\",\n",
    "    top_n=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    计算目标列与数据框中指定列开始的所有列的相关系数\n",
    "\n",
    "    参数:\n",
    "        df: 包含数据的DataFrame\n",
    "        target_col: 目标列名\n",
    "        start_col_idx: 从哪一列开始计算相关系数\n",
    "        method: 使用的相关系数方法，'spearman'或'pearson'\n",
    "        top_n: 返回前N个显著相关(p<0.05)的属性，默认不限制\n",
    "\n",
    "    返回:\n",
    "        按相关系数降序排列的DataFrame，包含相关系数、p值和显著性标记\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # 检查方法参数\n",
    "    if method.lower() not in [\"spearman\", \"pearson\"]:\n",
    "        print(f\"不支持的相关系数方法: {method}，使用默认的Spearman\")\n",
    "        method = \"spearman\"\n",
    "\n",
    "    # 显示使用的相关系数方法\n",
    "    print(f\"使用 {method.capitalize()} 相关系数计算\")\n",
    "\n",
    "    # 遍历所有地震属性列\n",
    "    for col in df.columns[start_col_idx:]:\n",
    "        try:\n",
    "            # 移除包含NaN的行以确保数据有效性\n",
    "            valid_data = df[[target_col, col]].dropna()\n",
    "\n",
    "            # 检查有效数据点数量\n",
    "            if len(valid_data) < 3:\n",
    "                print(f\"警告: '{col}' 与 '{target_col}' 的有效数据点少于3个，跳过计算\")\n",
    "                continue\n",
    "\n",
    "            if method.lower() == \"spearman\":\n",
    "                # Spearman相关系数\n",
    "                coef, pval = spearmanr(valid_data[target_col], valid_data[col])\n",
    "            else:\n",
    "                # Pearson相关系数\n",
    "                from scipy.stats import pearsonr\n",
    "\n",
    "                coef, pval = pearsonr(valid_data[target_col], valid_data[col])\n",
    "\n",
    "            # 保存结果\n",
    "            results.append(\n",
    "                {\n",
    "                    \"属性名称\": col,\n",
    "                    f\"{method.capitalize()} 相关系数\": coef,\n",
    "                    \"p-value\": pval,\n",
    "                    \"显著性\": \"**\" if pval < 0.05 else (\"*\" if pval < 0.1 else \"\"),\n",
    "                }\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"计算 '{col}' 列的相关系数时出错: {str(e)}\")\n",
    "\n",
    "    # 检查是否有成功计算的结果\n",
    "    if not results:\n",
    "        print(\"警告: 没有找到可以计算相关系数的有效列\")\n",
    "        return pd.DataFrame()  # 返回空DataFrame\n",
    "\n",
    "    # 转换为DataFrame并排序\n",
    "    result_df = pd.DataFrame(results)\n",
    "    result_df.set_index(\"属性名称\", inplace=True)\n",
    "\n",
    "    # 按相关系数绝对值大小降序排列\n",
    "    result_df = result_df.sort_values(f\"{method.capitalize()} 相关系数\", key=abs, ascending=False)\n",
    "\n",
    "    # 添加相关强度分类\n",
    "    def correlation_strength(r):\n",
    "        \"\"\"根据相关系数的绝对值确定相关强度\"\"\"\n",
    "        r_abs = abs(r)\n",
    "        if r_abs >= 0.8:\n",
    "            return \"极强\"\n",
    "        elif r_abs >= 0.6:\n",
    "            return \"强\"\n",
    "        elif r_abs >= 0.4:\n",
    "            return \"中等\"\n",
    "        elif r_abs >= 0.2:\n",
    "            return \"弱\"\n",
    "        else:\n",
    "            return \"极弱或无\"\n",
    "\n",
    "    result_df[\"相关强度\"] = result_df[f\"{method.capitalize()} 相关系数\"].apply(correlation_strength)\n",
    "\n",
    "    # 筛选显著相关的结果\n",
    "    significant_results = result_df[result_df[\"p-value\"] < 0.05].copy()\n",
    "\n",
    "    # 如果指定了top_n，则只返回前N个显著相关的属性\n",
    "    if top_n is not None and len(significant_results) > 0:\n",
    "        return significant_results.head(top_n)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# 分析结果并可视化\n",
    "def analyze_and_visualize(\n",
    "    df,\n",
    "    target_col=\"Thickness of LITHOLOGIES(1: sand)\",\n",
    "    start_col_idx=7,\n",
    "    method=\"spearman\",\n",
    "    top_n=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    分析相关性并可视化结果\n",
    "\n",
    "    参数:\n",
    "        df: 包含数据的DataFrame\n",
    "        target_col: 目标列名\n",
    "        start_col_idx: 从哪一列开始计算相关系数\n",
    "        method: 使用的相关系数方法，'spearman'或'pearson'\n",
    "        top_n: 可视化展示的属性数量\n",
    "    \"\"\"\n",
    "    # 执行相关性分析\n",
    "    correlation_results = analyze_correlations(df, target_col=target_col, start_col_idx=start_col_idx, method=method)\n",
    "\n",
    "    top_attributes = correlation_results.head(top_n)\n",
    "    plt.figure(figsize=(15, 9))\n",
    "\n",
    "    # 创建水平条形图\n",
    "    bars = plt.barh(\n",
    "        top_attributes.index,\n",
    "        top_attributes[f\"{method.capitalize()} 相关系数\"],\n",
    "        color=[plt.cm.RdYlGn(0.5 * (x + 1)) for x in top_attributes[f\"{method.capitalize()} 相关系数\"]],\n",
    "    )\n",
    "\n",
    "    # 添加零线\n",
    "    plt.axvline(x=0, color=\"gray\", linestyle=\"-\", alpha=0.3)\n",
    "    plt.xlabel(f\"{method.capitalize()} 相关系数\")\n",
    "    plt.title(f\"砂厚与前{top_n}个最相关地震属性 ({method.capitalize()})\")\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.6)\n",
    "\n",
    "    # 获取x轴限制以确定标签位置\n",
    "    x_min, x_max = plt.xlim()\n",
    "\n",
    "    # 在柱状图上标注相关系数值和显著性\n",
    "    for i, bar in enumerate(bars):\n",
    "        attr = top_attributes.index[i]\n",
    "        coef = top_attributes.loc[attr, f\"{method.capitalize()} 相关系数\"]\n",
    "        sig = top_attributes.loc[attr, \"显著性\"]\n",
    "        width = bar.get_width()  # 获取柱的宽度\n",
    "\n",
    "        # 计算标签位置 - 将标签放在柱状图边缘\n",
    "        x_pos = width + np.sign(width) * 0.01 * (x_max - x_min)  # 根据正负值确定方向\n",
    "\n",
    "        # 根据正负值确定对齐方式\n",
    "        ha_value = \"left\" if width >= 0 else \"right\"\n",
    "        color = \"black\"  # 统一使用黑色，因为标签在柱状图外部\n",
    "\n",
    "        plt.text(\n",
    "            x_pos,\n",
    "            i,\n",
    "            f\"{coef:.3f}{sig}\",\n",
    "            va=\"center\",\n",
    "            ha=ha_value,\n",
    "            color=color,\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return correlation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c8552",
   "metadata": {},
   "source": [
    "### 测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b5148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用默认的Spearman相关系数分析并可视化\n",
    "correlation_results_spearman = analyze_and_visualize(\n",
    "    data_H6_2_well_selected, target_col=\"LITHOLOGIES(1: sand)\", top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ac53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_attr = correlation_results_spearman.head(10).index.tolist()\n",
    "top_n_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3c4ba",
   "metadata": {},
   "source": [
    "## AutoFeat 生成组合特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "# 使用井点数据作为训练集，因为只有井点位置有实际的砂厚数据\n",
    "X = data_H6_2_well_selected[top_n_attr].copy()\n",
    "y = data_H6_2_well_selected[\"LITHOLOGIES(1: sand)\"].copy()\n",
    "\n",
    "# 处理可能存在的NaN值\n",
    "X = X.fillna(X.mean())\n",
    "y = y.fillna(y.mean())\n",
    "\n",
    "print(f\"输入特征数量: {X.shape[1]}\")\n",
    "print(f\"训练样本数量: {X.shape[0]}\")\n",
    "\n",
    "# 使用AutoFeat生成组合特征\n",
    "print(\"\\n开始使用AutoFeat生成组合特征...\")\n",
    "autofeat_model = AutoFeatRegressor(\n",
    "    categorical_cols=[],  # 没有分类特征\n",
    "    feateng_cols=X.columns.tolist(),  # 使用所有地震属性作为特征工程的输入列\n",
    "    feateng_steps=3,  # 特征工程的步骤数（决定组合特征的复杂度）\n",
    "    n_jobs=-1,  # 使用所有CPU核心\n",
    "    verbose=1,  # 显示详细信息\n",
    ")\n",
    "\n",
    "# 拟合并转换数据\n",
    "X_new = autofeat_model.fit_transform(X, y)\n",
    "\n",
    "# 保存AutoFeat模型以便后续应用到全区域数据\n",
    "joblib.dump(autofeat_model, \"output/autofeat_pipeline_seismic.pkl\")\n",
    "\n",
    "# 输出生成的特征列表和数量\n",
    "print(\"\\n\\n生成的组合特征列表:\")\n",
    "print(X_new.columns.tolist())\n",
    "print(f\"生成的组合特征数量: {X_new.shape[1]}\")\n",
    "\n",
    "# 将生成的特征名称保存到Excel文件\n",
    "pd.Series(X_new.columns).to_excel(\"output/AutoFeat_生成特征列名.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99afdf",
   "metadata": {},
   "source": [
    "## Baseline 模型测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# 设置随机种子，保证结果可复现\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def train_model_with_grid_search(X_train, X_test, y_train, y_test, model_name, feature_names, is_classification=False):\n",
    "    \"\"\"\n",
    "    使用网格搜索训练模型，同时优化特征选择和超参数\n",
    "\n",
    "    参数:\n",
    "        X_train, X_test: 训练和测试特征\n",
    "        y_train, y_test: 训练和测试标签\n",
    "        model_name: 'rf', 'xgb', 或 'svr'\n",
    "        feature_names: 特征名称列表\n",
    "        is_classification: 是否为分类任务\n",
    "\n",
    "    返回:\n",
    "        最佳模型, 选择的特征, 性能指标\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'=' * 20} 训练 {model_name.upper()} 模型 {'=' * 20}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 特征标准化 - 对SVR是必要的\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 创建Pipeline和参数网格\n",
    "    if model_name.lower() == \"rf\":\n",
    "        # 随机森林模型\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"feature_selection\", SelectKBest(f_regression)),\n",
    "                (\"model\", RandomForestRegressor(random_state=42)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        param_grid = {\n",
    "            \"feature_selection__k\": [3, 5, \"all\"] if X_train.shape[1] > 5 else [3, \"all\"],\n",
    "            \"model__n_estimators\": [100, 200],\n",
    "            \"model__max_depth\": [None, 10, 20],\n",
    "            \"model__min_samples_split\": [2, 5],\n",
    "            \"model__min_samples_leaf\": [1, 2],\n",
    "        }\n",
    "\n",
    "    elif model_name.lower() == \"xgb\":\n",
    "        # XGBoost模型\n",
    "        pipeline = Pipeline(\n",
    "            [\n",
    "                (\"feature_selection\", SelectKBest(f_regression)),\n",
    "                (\"model\", xgb.XGBRegressor(random_state=42)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        param_grid = {\n",
    "            \"feature_selection__k\": [3, 5, \"all\"] if X_train.shape[1] > 5 else [3, \"all\"],\n",
    "            \"model__n_estimators\": [100, 200],\n",
    "            \"model__learning_rate\": [0.01, 0.1],\n",
    "            \"model__max_depth\": [3, 6],\n",
    "            \"model__colsample_bytree\": [0.7, 1.0],\n",
    "        }\n",
    "\n",
    "    elif model_name.lower() == \"svr\":\n",
    "        # SVR模型 - 必须使用标准化后的特征\n",
    "        pipeline = Pipeline([(\"feature_selection\", SelectKBest(f_regression)), (\"model\", SVR())])\n",
    "\n",
    "        param_grid = {\n",
    "            \"feature_selection__k\": [3, 5, \"all\"] if X_train.shape[1] > 5 else [3, \"all\"],\n",
    "            \"model__kernel\": [\"linear\", \"rbf\"],\n",
    "            \"model__C\": [0.1, 1, 10, 100],\n",
    "            \"model__gamma\": [\"scale\", \"auto\", 0.1],\n",
    "        }\n",
    "\n",
    "    # 进行网格搜索\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=3 if X_train.shape[0] >= 10 else 2,  # 小样本时使用更少的折数\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # 使用标准化后的数据训练SVR，使用原始数据训练其他模型\n",
    "    if model_name.lower() == \"svr\":\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "    else:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # 获取最佳参数和模型\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"\\n最佳参数: {best_params}\")\n",
    "\n",
    "    # 获取选择的特征\n",
    "    best_k = best_params[\"feature_selection__k\"]\n",
    "    if best_k == \"all\":\n",
    "        selected_features = feature_names\n",
    "    else:\n",
    "        # 对特征重新打分\n",
    "        feature_selector = SelectKBest(f_regression, k=best_k)\n",
    "        if model_name.lower() == \"svr\":\n",
    "            feature_selector.fit(X_train_scaled, y_train)\n",
    "        else:\n",
    "            feature_selector.fit(X_train, y_train)\n",
    "        selected_indices = feature_selector.get_support(indices=True)\n",
    "        selected_features = [feature_names[i] for i in selected_indices]\n",
    "\n",
    "    print(f\"\\n选择的特征 ({len(selected_features)}个): {selected_features}\")\n",
    "\n",
    "    # 获取最佳模型\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # 预测和评估\n",
    "    if model_name.lower() == \"svr\":\n",
    "        y_pred = best_model.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # 计算指标\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n{model_name.upper()} 评估结果:\")\n",
    "    print(f\"  MSE:  {mse:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\\n\")\n",
    "\n",
    "    # 计算运行时间\n",
    "    end_time = time.time()\n",
    "    run_time = end_time - start_time\n",
    "    print(f\"网格搜索运行时间: {run_time:.2f} 秒\")\n",
    "\n",
    "    # 可视化实际值vs预测值\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], \"r--\")\n",
    "    plt.xlabel(\"实际值\")\n",
    "    plt.ylabel(\"预测值\")\n",
    "    plt.title(f\"{model_name.upper()}: 实际值 vs. 预测值\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 返回最佳模型、选择的特征和度量指标\n",
    "    metrics = {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "    return best_model, selected_features, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb183c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 使用网格搜索优化模型和特征选择\n",
    "# --------------------------\n",
    "\n",
    "print(\"准备使用网格搜索优化模型...\")\n",
    "\n",
    "# 准备数据\n",
    "if \"X_new\" in globals():\n",
    "    X_data = X_new.copy()\n",
    "    print(f\"使用AutoFeat生成的特征 ({X_data.shape[1]} 个特征)\")\n",
    "else:\n",
    "    X_data = data_H6_2_well_selected[top_n_attr].copy()\n",
    "    print(f\"使用原始特征 ({X_data.shape[1]} 个特征)\")\n",
    "\n",
    "# 确定任务类型和目标变量\n",
    "is_classification = False\n",
    "target_column = \"Thickness of LITHOLOGIES(1: sand)\"\n",
    "if \"标签\" in data_H6_2_well_selected.columns:\n",
    "    y_data = data_H6_2_well_selected[\"标签\"].copy()\n",
    "    is_classification = True\n",
    "    target_column = \"标签\"\n",
    "else:\n",
    "    y_data = data_H6_2_well_selected[target_column].copy()\n",
    "\n",
    "# 填充缺失值\n",
    "X_data = X_data.fillna(X_data.mean())\n",
    "y_data = y_data.fillna(y_data.mean() if not is_classification else y_data.mode()[0])\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=RANDOM_SEED)\n",
    "\n",
    "print(f\"训练集样本数: {X_train.shape[0]}\")\n",
    "print(f\"测试集样本数: {X_test.shape[0]}\")\n",
    "\n",
    "# 存储网格搜索结果\n",
    "gs_model_results = {}\n",
    "\n",
    "# 训练并评估随机森林模型\n",
    "rf_best_model, rf_selected_features, rf_metrics = train_model_with_grid_search(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    model_name=\"rf\",\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    is_classification=is_classification,\n",
    ")\n",
    "gs_model_results[\"Random Forest\"] = {\n",
    "    \"model\": rf_best_model,\n",
    "    \"selected_features\": rf_selected_features,\n",
    "    \"metrics\": rf_metrics,\n",
    "}\n",
    "\n",
    "# 训练并评估XGBoost模型\n",
    "xgb_best_model, xgb_selected_features, xgb_metrics = train_model_with_grid_search(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    model_name=\"xgb\",\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    is_classification=is_classification,\n",
    ")\n",
    "gs_model_results[\"XGBoost\"] = {\n",
    "    \"model\": xgb_best_model,\n",
    "    \"selected_features\": xgb_selected_features,\n",
    "    \"metrics\": xgb_metrics,\n",
    "}\n",
    "\n",
    "# 训练并评估SVR模型\n",
    "svr_best_model, svr_selected_features, svr_metrics = train_model_with_grid_search(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    model_name=\"svr\",\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    is_classification=is_classification,\n",
    ")\n",
    "gs_model_results[\"SVR\"] = {\n",
    "    \"model\": svr_best_model,\n",
    "    \"selected_features\": svr_selected_features,\n",
    "    \"metrics\": svr_metrics,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc5ffb",
   "metadata": {},
   "source": [
    "## 目标属性预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 目标属性预测 - 使用最佳模型预测整个区域\n",
    "# --------------------------\n",
    "\n",
    "print(\"\\n========== 使用最佳模型进行全区域预测 ==========\")\n",
    "\n",
    "# 1. 确定最佳模型\n",
    "if \"gs_model_results\" in globals():\n",
    "    # 如果已经进行过网格搜索，使用网格搜索的结果\n",
    "    model_results = gs_model_results\n",
    "else:\n",
    "    # 否则使用全局变量中可能存在的模型结果\n",
    "    model_results = globals().get(\"model_results\", {})\n",
    "\n",
    "if not model_results:\n",
    "    print(\"错误：未找到训练好的模型结果。请先运行模型训练代码。\")\n",
    "else:\n",
    "    # 比较不同模型的性能找出最佳模型\n",
    "    performance_metrics = {}\n",
    "    for model_name, result in model_results.items():\n",
    "        metrics = result[\"metrics\"]\n",
    "        if \"r2\" in metrics:  # 回归模型\n",
    "            performance_metrics[model_name] = metrics[\"r2\"]\n",
    "        elif \"accuracy\" in metrics:  # 分类模型\n",
    "            performance_metrics[model_name] = metrics[\"accuracy\"]\n",
    "\n",
    "    # 找出性能最好的模型\n",
    "    best_model_name = max(performance_metrics.items(), key=lambda x: x[1])[0]\n",
    "    best_model = model_results[best_model_name][\"model\"]\n",
    "    best_features = model_results[best_model_name][\"selected_features\"]\n",
    "\n",
    "    print(f\"\\n选择的最佳模型: {best_model_name}\")\n",
    "    print(f\"R² 或准确率: {performance_metrics[best_model_name]:.4f}\")\n",
    "    print(f\"使用特征数量: {len(best_features)}\")\n",
    "    print(f\"使用的特征: {best_features}\")\n",
    "\n",
    "    # 2. 准备全区域数据进行预测\n",
    "    print(\"\\n准备全区域数据进行预测...\")\n",
    "\n",
    "    # 检查是否存在地震属性数据\n",
    "    if \"data_H6_2_attr\" not in globals() or data_H6_2_attr is None:\n",
    "        print(\"未找到地震属性数据，重新加载...\")\n",
    "        data_H6_2_attr = parse_petrel_file(\"../data/H6-2_attr\")\n",
    "\n",
    "    if data_H6_2_attr is not None:\n",
    "        print(f\"地震属性数据加载成功，共 {len(data_H6_2_attr)} 个点位\")\n",
    "\n",
    "        # 3. 处理全区域数据\n",
    "\n",
    "        # 判断是否需要使用AutoFeat转换\n",
    "        if \"autofeat_model\" in globals() and any(f not in data_H6_2_attr.columns for f in best_features):\n",
    "            print(\"检测到使用了AutoFeat生成的特征，应用AutoFeat转换...\")\n",
    "\n",
    "            # 检查是否有原始特征列表\n",
    "            if \"top_n_attr\" in globals():\n",
    "                # 准备原始特征并处理缺失值\n",
    "                X_seismic_orig = data_H6_2_attr[top_n_attr].copy()\n",
    "\n",
    "                # 检查原始特征中的NaN值并处理\n",
    "                missing_cols = X_seismic_orig.columns[X_seismic_orig.isna().any()].tolist()\n",
    "                if missing_cols:\n",
    "                    print(f\"原始特征中发现以下列存在缺失值: {missing_cols}\")\n",
    "                    for col in missing_cols:\n",
    "                        col_mean = X_seismic_orig[col].mean()\n",
    "                        X_seismic_orig[col].fillna(col_mean, inplace=True)\n",
    "                        print(f\"  - 列 '{col}' 的缺失值已用均值 {col_mean:.4f} 填充\")\n",
    "\n",
    "                # 确保所有NaN都已处理\n",
    "                if X_seismic_orig.isna().any().any():\n",
    "                    print(\"警告：某些原始特征列的均值可能为NaN，使用0填充\")\n",
    "                    X_seismic_orig.fillna(0, inplace=True)\n",
    "\n",
    "                # 应用AutoFeat转换\n",
    "                X_seismic = autofeat_model.transform(X_seismic_orig)\n",
    "                print(f\"AutoFeat转换后的特征数量: {X_seismic.shape[1]}\")\n",
    "\n",
    "                # 检查AutoFeat转换后的NaN值并处理\n",
    "                post_transform_missing = X_seismic.isna().sum().sum()\n",
    "                if post_transform_missing > 0:\n",
    "                    print(f\"AutoFeat转换后发现 {post_transform_missing} 个缺失值，进行处理...\")\n",
    "\n",
    "                    # 查看哪些列有NaN\n",
    "                    missing_cols = X_seismic.columns[X_seismic.isna().any()].tolist()\n",
    "                    print(f\"以下转换后的特征存在缺失值: {missing_cols}\")\n",
    "\n",
    "                    # 填充缺失值\n",
    "                    for col in missing_cols:\n",
    "                        col_mean = X_seismic[col].mean()\n",
    "                        # 如果均值是NaN（可能整列都是NaN），则用0填充\n",
    "                        if pd.isna(col_mean):\n",
    "                            X_seismic[col].fillna(0, inplace=True)\n",
    "                            print(f\"  - 列 '{col}' 的所有值为NaN，用0填充\")\n",
    "                        else:\n",
    "                            X_seismic[col].fillna(col_mean, inplace=True)\n",
    "                            print(f\"  - 列 '{col}' 的缺失值已用均值 {col_mean:.4f} 填充\")\n",
    "\n",
    "                # 只保留模型需要的特征\n",
    "                common_features = [f for f in best_features if f in X_seismic.columns]\n",
    "                if len(common_features) < len(best_features):\n",
    "                    missing_features = set(best_features) - set(common_features)\n",
    "                    print(f\"警告: 有 {len(missing_features)} 个模型所需特征在转换后的数据中不存在:\")\n",
    "                    print(f\"  缺失的特征: {missing_features}\")\n",
    "\n",
    "                X_seismic = X_seismic[common_features]\n",
    "\n",
    "                # 再次检查是否还有NaN\n",
    "                if X_seismic.isna().any().any():\n",
    "                    print(\"警告: 处理后的特征数据仍有NaN值，用0填充\")\n",
    "                    X_seismic.fillna(0, inplace=True)\n",
    "\n",
    "            else:\n",
    "                print(\"错误: 无法找到原始特征列表，无法应用AutoFeat转换\")\n",
    "                # 尝试使用可用的特征继续\n",
    "                seismic_features = [f for f in best_features if f in data_H6_2_attr.columns]\n",
    "                if seismic_features:\n",
    "                    print(f\"尝试使用 {len(seismic_features)} 个可用的非组合特征继续...\")\n",
    "                    X_seismic = data_H6_2_attr[seismic_features].copy()\n",
    "                    X_seismic = X_seismic.fillna(X_seismic.mean())\n",
    "                    # 确保没有NaN\n",
    "                    X_seismic.fillna(0, inplace=True)\n",
    "                else:\n",
    "                    print(\"致命错误: 无法构建预测所需的特征数据\")\n",
    "        else:\n",
    "            # 使用原始特征而不是AutoFeat特征\n",
    "            seismic_features = []\n",
    "            for feature in best_features:\n",
    "                if feature in data_H6_2_attr.columns:\n",
    "                    seismic_features.append(feature)\n",
    "                else:\n",
    "                    print(f\"警告: 特征 '{feature}' 在地震属性数据中不存在\")\n",
    "\n",
    "            if len(seismic_features) == 0:\n",
    "                print(\"错误: 无法在地震属性数据中找到模型所需的特征\")\n",
    "            else:\n",
    "                print(f\"在地震属性数据中找到 {len(seismic_features)}/{len(best_features)} 个特征\")\n",
    "\n",
    "                # 提取特征数据\n",
    "                X_seismic = data_H6_2_attr[seismic_features].copy()\n",
    "\n",
    "                # 处理缺失值\n",
    "                missing_cols = X_seismic.columns[X_seismic.isna().any()].tolist()\n",
    "                if missing_cols:\n",
    "                    print(f\"发现以下列存在缺失值: {missing_cols}\")\n",
    "                    for col in missing_cols:\n",
    "                        col_mean = X_seismic[col].mean()\n",
    "                        if pd.isna(col_mean):  # 如果均值为NaN，用0填充\n",
    "                            X_seismic[col].fillna(0, inplace=True)\n",
    "                            print(f\"  - 列 '{col}' 的所有值为NaN，用0填充\")\n",
    "                        else:\n",
    "                            X_seismic[col].fillna(col_mean, inplace=True)\n",
    "                            print(f\"  - 列 '{col}' 的缺失值已用均值 {col_mean:.4f} 填充\")\n",
    "\n",
    "                # 确保没有NaN\n",
    "                if X_seismic.isna().any().any():\n",
    "                    print(\"警告：某些列的均值可能为NaN，使用0填充\")\n",
    "                    X_seismic.fillna(0, inplace=True)\n",
    "\n",
    "        # 检查特征数据是否已正确准备\n",
    "        if \"X_seismic\" in locals() and not X_seismic.empty:\n",
    "            # 4. 预测目标属性\n",
    "            print(\"\\n使用最佳模型进行预测...\")\n",
    "\n",
    "            # 对于SVR模型，需要标准化数据\n",
    "            if \"SVR\" in str(best_model.__class__) or best_model_name == \"SVR\":\n",
    "                print(\"检测到SVR模型，进行数据标准化...\")\n",
    "                scaler = StandardScaler()\n",
    "                X_seismic_scaled = scaler.fit_transform(X_seismic)\n",
    "\n",
    "                # 将缩放后的数据转换回DataFrame以保持列名\n",
    "                X_seismic = pd.DataFrame(X_seismic_scaled, columns=X_seismic.columns, index=X_seismic.index)\n",
    "\n",
    "            # 获取预测值\n",
    "            y_pred = best_model.predict(X_seismic)\n",
    "\n",
    "            # 5. 将预测结果添加到地震属性数据中\n",
    "            if is_classification:\n",
    "                data_H6_2_attr[\"预测_标签\"] = y_pred\n",
    "                print(f\"成功预测 {len(data_H6_2_attr)} 个点的类别\")\n",
    "            else:\n",
    "                data_H6_2_attr[\"预测_砂厚\"] = y_pred\n",
    "                print(f\"成功预测 {len(data_H6_2_attr)} 个点的砂厚\")\n",
    "\n",
    "            # 6. 保存预测结果\n",
    "            output_file = f\"output/预测结果_{best_model_name}.csv\"\n",
    "            result_df = data_H6_2_attr[[\"X\", \"Y\", \"Z\"] + ([\"预测_标签\"] if is_classification else [\"预测_砂厚\"])]\n",
    "            result_df.to_csv(output_file, index=False)\n",
    "            print(f\"预测结果已保存到 {output_file}\")\n",
    "\n",
    "            # 7. 可视化预测结果分布\n",
    "            plt.figure(figsize=(10, 6))\n",
    "\n",
    "            if is_classification:\n",
    "                # 分类任务的结果分布\n",
    "                sns.countplot(x=\"预测_标签\", data=data_H6_2_attr)\n",
    "                plt.title(f\"预测标签分布 (使用{best_model_name})\")\n",
    "                plt.xlabel(\"预测标签\")\n",
    "                plt.ylabel(\"数量\")\n",
    "            else:\n",
    "                # 回归任务的结果分布\n",
    "                sns.histplot(data_H6_2_attr[\"预测_砂厚\"], kde=True, bins=30)\n",
    "                plt.title(f\"预测砂厚分布 (使用{best_model_name})\")\n",
    "                plt.xlabel(\"预测砂厚\")\n",
    "                plt.ylabel(\"频率\")\n",
    "\n",
    "                # 添加统计信息\n",
    "                mean_val = data_H6_2_attr[\"预测_砂厚\"].mean()\n",
    "                median_val = data_H6_2_attr[\"预测_砂厚\"].median()\n",
    "                min_val = data_H6_2_attr[\"预测_砂厚\"].min()\n",
    "                max_val = data_H6_2_attr[\"预测_砂厚\"].max()\n",
    "\n",
    "                stats_text = (\n",
    "                    f\"平均值: {mean_val:.2f}\\n中位数: {median_val:.2f}\\n最小值: {min_val:.2f}\\n最大值: {max_val:.2f}\"\n",
    "                )\n",
    "                plt.text(\n",
    "                    0.95,\n",
    "                    0.95,\n",
    "                    stats_text,\n",
    "                    transform=plt.gca().transAxes,\n",
    "                    verticalalignment=\"top\",\n",
    "                    horizontalalignment=\"right\",\n",
    "                    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "                )\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"output/预测分布_{best_model_name}.png\", dpi=300)\n",
    "            plt.show()\n",
    "\n",
    "            # 8. 可视化预测结果的空间分布（优化色棒范围）\n",
    "            # 创建平面图\n",
    "            plt.figure(figsize=(12, 10))\n",
    "\n",
    "            # 获取目标列\n",
    "            target_col = \"预测_标签\" if is_classification else \"预测_砂厚\"\n",
    "\n",
    "            # 计算5%和95%分位数以设置色棒范围\n",
    "            if not is_classification:\n",
    "                vmin = np.percentile(data_H6_2_attr[target_col], 5)\n",
    "                vmax = np.percentile(data_H6_2_attr[target_col], 95)\n",
    "                print(f\"色棒范围限制: 5%分位数={vmin:.2f}, 95%分位数={vmax:.2f}\")\n",
    "\n",
    "                # 散点图，颜色表示预测值，并限制色彩范围\n",
    "                scatter = plt.scatter(\n",
    "                    data_H6_2_attr[\"X\"],\n",
    "                    data_H6_2_attr[\"Y\"],\n",
    "                    c=data_H6_2_attr[target_col],\n",
    "                    cmap=\"viridis\",\n",
    "                    s=1,\n",
    "                    alpha=0.7,\n",
    "                    vmin=vmin,\n",
    "                    vmax=vmax,\n",
    "                )\n",
    "            else:\n",
    "                # 分类数据不需要限制范围\n",
    "                scatter = plt.scatter(\n",
    "                    data_H6_2_attr[\"X\"],\n",
    "                    data_H6_2_attr[\"Y\"],\n",
    "                    c=data_H6_2_attr[target_col],\n",
    "                    cmap=\"Set1\",\n",
    "                    s=1,\n",
    "                    alpha=0.7,\n",
    "                )\n",
    "\n",
    "            # 添加颜色条\n",
    "            cbar = plt.colorbar(scatter)\n",
    "            cbar.set_label(\"预测标签\" if is_classification else \"预测砂厚\")\n",
    "\n",
    "            # 设置图表标题和轴标签\n",
    "            plt.title(f\"预测结果的空间分布 ({best_model_name})\")\n",
    "            plt.xlabel(\"X坐标\")\n",
    "            plt.ylabel(\"Y坐标\")\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # 保存图片\n",
    "            plt.savefig(f\"output/预测空间分布_{best_model_name}.png\", dpi=300)\n",
    "            plt.show()\n",
    "\n",
    "            # 如果有井点数据，可视化井点和预测结果的对比（同样优化色棒范围）\n",
    "            if \"data_H6_2_well_selected\" in globals() and len(data_H6_2_well_selected) > 0:\n",
    "                plt.figure(figsize=(12, 10))\n",
    "\n",
    "                # 绘制预测背景，同样限制色彩范围\n",
    "                if not is_classification:\n",
    "                    scatter = plt.scatter(\n",
    "                        data_H6_2_attr[\"X\"],\n",
    "                        data_H6_2_attr[\"Y\"],\n",
    "                        c=data_H6_2_attr[target_col],\n",
    "                        cmap=\"viridis\",\n",
    "                        s=1,\n",
    "                        alpha=0.3,\n",
    "                        vmin=vmin,\n",
    "                        vmax=vmax,\n",
    "                    )\n",
    "                else:\n",
    "                    scatter = plt.scatter(\n",
    "                        data_H6_2_attr[\"X\"],\n",
    "                        data_H6_2_attr[\"Y\"],\n",
    "                        c=data_H6_2_attr[target_col],\n",
    "                        cmap=\"Set1\",\n",
    "                        s=1,\n",
    "                        alpha=0.3,\n",
    "                    )\n",
    "\n",
    "                # 绘制井点位置和实际值\n",
    "                target_well = \"标签\" if is_classification else target_column\n",
    "\n",
    "                # 对于回归任务，也为井点限制色彩范围\n",
    "                if not is_classification:\n",
    "                    well_vmin = min(vmin, data_H6_2_well_selected[target_well].min())\n",
    "                    well_vmax = max(vmax, data_H6_2_well_selected[target_well].max())\n",
    "                    well_scatter = plt.scatter(\n",
    "                        data_H6_2_well_selected[\"X\"],\n",
    "                        data_H6_2_well_selected[\"Y\"],\n",
    "                        c=data_H6_2_well_selected[target_well],\n",
    "                        cmap=\"viridis\",\n",
    "                        s=50,\n",
    "                        edgecolor=\"black\",\n",
    "                        linewidth=1,\n",
    "                        vmin=well_vmin,\n",
    "                        vmax=well_vmax,\n",
    "                    )\n",
    "                else:\n",
    "                    well_scatter = plt.scatter(\n",
    "                        data_H6_2_well_selected[\"X\"],\n",
    "                        data_H6_2_well_selected[\"Y\"],\n",
    "                        c=data_H6_2_well_selected[target_well],\n",
    "                        cmap=\"Set1\",\n",
    "                        s=50,\n",
    "                        edgecolor=\"black\",\n",
    "                        linewidth=1,\n",
    "                    )\n",
    "\n",
    "                # 添加颜色条和图例\n",
    "                cbar = plt.colorbar(scatter)\n",
    "                cbar.set_label(\"预测值\" if is_classification else \"预测砂厚\")\n",
    "\n",
    "                # 添加井名标注\n",
    "                for idx, row in data_H6_2_well_selected.iterrows():\n",
    "                    plt.text(row[\"X\"], row[\"Y\"], row[\"Well\"], fontsize=8)\n",
    "\n",
    "                plt.title(\"预测结果与井点实际值对比\")\n",
    "                plt.xlabel(\"X坐标\")\n",
    "                plt.ylabel(\"Y坐标\")\n",
    "                plt.tight_layout()\n",
    "\n",
    "                # 保存图片\n",
    "                plt.savefig(f\"output/井点对比_{best_model_name}.png\", dpi=300)\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"错误: 无法构建有效的特征数据集\")\n",
    "    else:\n",
    "        print(\"错误: 无法加载地震属性数据\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attr_fusion_20250428",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
