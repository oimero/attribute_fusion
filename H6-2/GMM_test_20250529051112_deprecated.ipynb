{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c69e163",
   "metadata": {},
   "source": [
    "## GMM 扩容 + 监督学习\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb90ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保src目录在Python路径中\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# 导入模块\n",
    "from src.data_utils import filter_anomalous_attributes, identify_attributes, parse_petrel_file\n",
    "from src.feature_selection import (\n",
    "    analyze_attribute_correlations,\n",
    "    analyze_rf_importance_by_group,\n",
    ")\n",
    "from src.gmm_clustering import (\n",
    "    augment_samples_by_pca_mixing,\n",
    "    encode_cluster_features,\n",
    "    evaluate_gmm_clusters,\n",
    "    perform_gmm_clustering,\n",
    ")\n",
    "from src.pca_analysis import perform_pca_analysis\n",
    "from src.regression import (\n",
    "    build_svr_model,\n",
    "    predict_with_model,\n",
    ")\n",
    "\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"  # 黑体 SimHei 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c1279",
   "metadata": {},
   "source": [
    "## 导入地震数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H6_2_attr = parse_petrel_file(\"../data/H6-2_attr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbb335",
   "metadata": {},
   "source": [
    "## 导入井震数据\n",
    "\n",
    "使用 xlsx / csv 数据，注意表名为 Sheet1，注意数据需包含表头\n",
    "\n",
    "请检查 excel 表头和下面代码中的 selected_columns 是否一致\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bab879",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_H6_2_well = \"../data/well_processed.xlsx\"\n",
    "data_H6_2_well = pd.read_excel(file_H6_2_well, sheet_name=\"Sheet1\")\n",
    "\n",
    "# 只选择 Surface 为 H6-2 的行，并丢弃砂厚为 NaN 的行\n",
    "data_H6_2_well_selected = (\n",
    "    data_H6_2_well[data_H6_2_well[\"Surface\"] == \"H6-2\"]\n",
    "    .replace(-999, np.nan)\n",
    "    .dropna(subset=[\"Thickness of facies(1: Fine sand)\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "data_H6_2_well_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f93f71",
   "metadata": {},
   "source": [
    "## 提取共同属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取地震属性列表\n",
    "seismic_attr, _ = identify_attributes(\"../data/H6-2_attr\")\n",
    "\n",
    "# 提取Excel的属性列表（从第8列开始的所有列）\n",
    "well_seismic_attr = data_H6_2_well.columns[7:].tolist()\n",
    "\n",
    "# 计算两个列表的交集\n",
    "common_attributes = list(set(seismic_attr) & set(well_seismic_attr))\n",
    "\n",
    "# 打印结果\n",
    "print(f\"地震属性数量: {len(seismic_attr)}\")\n",
    "print(f\"Excel属性数量: {len(well_seismic_attr)}\")\n",
    "print(f\"共同属性数量: {len(common_attributes)}\")\n",
    "print(\"\\n共同属性列表:\")\n",
    "for attr in common_attributes:\n",
    "    print(f\"- {attr}\")\n",
    "\n",
    "# 筛选出质量良好的属性\n",
    "good_attributes, anomalous_attributes, attribute_stats = filter_anomalous_attributes(\n",
    "    seismic_data=data_H6_2_attr,\n",
    "    well_data=data_H6_2_well_selected,\n",
    "    common_attributes=common_attributes,\n",
    "    ratio_threshold=5.0,  # 均值比值阈值\n",
    "    range_ratio_threshold=10.0,  # 数值范围比值阈值\n",
    "    std_ratio_threshold=10.0,  # 标准差比值阈值\n",
    "    output_dir=output_dir,  # 输出图表目录\n",
    "    verbose=True,  # 打印详细信息\n",
    ")\n",
    "\n",
    "print(\"\\n筛选后保留的质量良好属性:\")\n",
    "for attr in good_attributes:\n",
    "    print(f\"- {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bf0d9",
   "metadata": {},
   "source": [
    "## PCA 降维 + GMM 聚类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bf76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对地震属性数据进行PCA降维\n",
    "pca_results = perform_pca_analysis(\n",
    "    data=data_H6_2_attr,\n",
    "    attribute_columns=good_attributes,\n",
    "    variance_threshold=0.9,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先评估最佳聚类数\n",
    "gmm_evaluation = evaluate_gmm_clusters(features_pca=pca_results[\"features_pca\"], max_clusters=10, output_dir=output_dir)\n",
    "\n",
    "# 使用不同的聚类数执行GMM聚类\n",
    "# 根据BIC/AIC结果选择的最佳聚类数\n",
    "best_n = gmm_evaluation[\"best_n_components\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n = 4  # 如果需要，可以手动设置最佳聚类数\n",
    "\n",
    "gmm_best = perform_gmm_clustering(\n",
    "    features_pca=pca_results[\"features_pca\"],\n",
    "    coords=pca_results[\"coords_clean\"],\n",
    "    n_clusters=best_n,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "gmm_best[\"result_df\"].to_csv(os.path.join(output_dir, \"gmm_best_clusters.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80eea5",
   "metadata": {},
   "source": [
    "## GMM 中心混合扩充样本（于 PCA 空间）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd19edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对井点数据进行PCA降维和GMM聚类\n",
    "# 注意：这里使用pca_results中的PCA模型和标准化器，但我们需要重新应用到井点数据上\n",
    "\n",
    "# 确定属性列 - 必须与PCA中使用的列完全一致\n",
    "attribute_columns = pca_results[\"features_clean\"].columns.tolist()\n",
    "\n",
    "# 不要只提取特征列，而是保留所有需要的列\n",
    "X_well = data_H6_2_well_selected.copy()\n",
    "\n",
    "# 然后对特征列进行预处理\n",
    "for col in attribute_columns:\n",
    "    if pd.isna(X_well[col].mean()):\n",
    "        print(f\"列 '{col}' 的均值为NaN，使用0填充\")\n",
    "        X_well[col] = X_well[col].fillna(0)\n",
    "    else:\n",
    "        # 使用列均值填充\n",
    "        X_well[col] = X_well[col].fillna(X_well[col].mean())\n",
    "\n",
    "# 确保特征列没有剩余的NaN值\n",
    "if X_well[attribute_columns].isna().any().any():\n",
    "    print(\"警告：特征列中仍然存在NaN值，将它们替换为0\")\n",
    "    for col in attribute_columns:\n",
    "        X_well[col] = X_well[col].fillna(0)\n",
    "\n",
    "# 对井点数据进行标准化 - 只标准化特征列\n",
    "X_well_scaled = pca_results[\"scaler\"].transform(X_well[attribute_columns])\n",
    "\n",
    "# 将井点数据投影到PCA空间\n",
    "X_well_pca = pca_results[\"pca\"].transform(X_well_scaled)\n",
    "\n",
    "# 使用已有的GMM模型对井点数据进行聚类\n",
    "cluster_labels_well = gmm_best[\"gmm\"].predict(X_well_pca)\n",
    "cluster_probs_well = gmm_best[\"gmm\"].predict_proba(X_well_pca)\n",
    "\n",
    "# 创建井点数据的聚类结果字典\n",
    "well_cluster_results = {\n",
    "    \"cluster_labels\": cluster_labels_well,\n",
    "    \"cluster_probs\": cluster_probs_well,\n",
    "}\n",
    "\n",
    "# 使用PCA空间中的中心混合法生成伪样本\n",
    "augmented_data = augment_samples_by_pca_mixing(\n",
    "    well_data=X_well,\n",
    "    pca_model=pca_results[\"pca\"],\n",
    "    scaler=pca_results[\"scaler\"],\n",
    "    cluster_results=well_cluster_results,\n",
    "    attribute_columns=attribute_columns,\n",
    "    target_column=\"Thickness of facies(1: Fine sand)\",\n",
    "    min_samples_per_cluster=4,  # 考虑井数据更少，设置更小的阈值\n",
    "    augmentation_factor=2.0,  # 目标是原始样本数的2倍\n",
    "    min_target_per_cluster=4,  # 每个聚类至少4个样本\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 保存扩增后的数据\n",
    "augmented_data.to_csv(os.path.join(output_dir, \"augmented_well_data_pca.csv\"), index=False)\n",
    "\n",
    "# 可视化目标值分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(\n",
    "    data=augmented_data,\n",
    "    x=\"Thickness of facies(1: Fine sand)\",\n",
    "    hue=\"Is_Synthetic\",\n",
    "    element=\"step\",\n",
    "    bins=15,\n",
    "    kde=True,\n",
    ")\n",
    "plt.title(\"原始样本和PCA空间中合成样本的目标值分布\")\n",
    "plt.xlabel(\"砂厚\")\n",
    "plt.savefig(\n",
    "    os.path.join(output_dir, \"pca_augmented_samples_target_dist.png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d5c96",
   "metadata": {},
   "source": [
    "## 数据整理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe4abdd",
   "metadata": {},
   "source": [
    "### 1. 未扩充的原始井点数据 + One-Hot 编码 + 聚类概率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4099ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制原始井点数据\n",
    "original_well_data = X_well.copy()\n",
    "\n",
    "# 添加聚类标签\n",
    "original_well_data[\"Cluster\"] = cluster_labels_well\n",
    "\n",
    "# 添加聚类概率\n",
    "original_well_data[\"cluster_probs\"] = list(cluster_probs_well)\n",
    "\n",
    "# 应用One-Hot编码\n",
    "original_well_data_encoded = encode_cluster_features(\n",
    "    data=original_well_data,\n",
    "    cluster_column=\"Cluster\",\n",
    "    drop_original=False,\n",
    "    prefix=\"Cluster_\",\n",
    ")\n",
    "\n",
    "# 保存处理后的数据\n",
    "output_file = os.path.join(output_dir, \"original_well_data_with_clusters.csv\")\n",
    "original_well_data_encoded.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"原始井点数据（带聚类特征）已保存至: {output_file}\")\n",
    "print(f\"数据形状: {original_well_data_encoded.shape}\")\n",
    "print(f\"包含的特征列数量: {len(original_well_data_encoded.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1418cf62",
   "metadata": {},
   "source": [
    "### 2. 扩充后的数据 + One-Hot 编码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2b2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_well_data_encoded = encode_cluster_features(\n",
    "    data=augmented_data,\n",
    "    cluster_column=\"Cluster\",\n",
    "    drop_original=False,\n",
    "    prefix=\"Cluster_\",\n",
    ")\n",
    "\n",
    "print(\"\\n原始和扩充后井点数据对比:\")\n",
    "print(f\"  - 原始井点数据: {len(original_well_data_encoded)} 行\")\n",
    "print(f\"  - 扩充后数据: {len(augmented_well_data_encoded)} 行\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b646136",
   "metadata": {},
   "source": [
    "### 3. 全体地震数据 + One-Hot 编码 + 聚类概率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接使用gmm_best[\"result_df\"]，它已经包含了坐标和聚类标签\n",
    "seismic_with_clusters = gmm_best[\"result_df\"].copy()\n",
    "\n",
    "# 添加聚类概率\n",
    "seismic_with_clusters[\"cluster_probs\"] = list(gmm_best[\"cluster_probs\"])\n",
    "\n",
    "# 将result_df与原始地震数据合并，以保留所有地震属性\n",
    "# 首先确保坐标列的名称一致\n",
    "coords_columns = [\"X\", \"Y\", \"Z\"]\n",
    "\n",
    "# 将地震属性合并到聚类结果中\n",
    "# 通过坐标列进行合并，这应该是一对一的匹配\n",
    "seismic_data_full = pd.merge(seismic_with_clusters, data_H6_2_attr, on=coords_columns, how=\"left\")\n",
    "\n",
    "# 应用One-Hot编码\n",
    "seismic_data_encoded = encode_cluster_features(\n",
    "    data=seismic_data_full,\n",
    "    cluster_column=\"Cluster\",\n",
    "    drop_original=False,\n",
    "    prefix=\"Cluster_\",\n",
    ")\n",
    "\n",
    "# 保存处理后的数据\n",
    "output_file = os.path.join(output_dir, \"seismic_data_with_clusters.csv\")\n",
    "seismic_data_encoded.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"全体地震数据（带聚类特征）已保存至: {output_file}\")\n",
    "print(f\"数据形状: {seismic_data_encoded.shape}\")\n",
    "print(f\"包含的特征列数量: {len(seismic_data_encoded.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n============ 数据整理完成 ============\")\n",
    "\n",
    "# 展示所有准备好的数据集的前几行\n",
    "print(\"\\n原始井点数据（带聚类特征）前5行:\")\n",
    "display(original_well_data_encoded.head())\n",
    "\n",
    "print(\"\\n扩充后井点数据（带聚类特征）前5行:\")\n",
    "display(augmented_well_data_encoded.head())\n",
    "\n",
    "print(\"\\n全体地震数据（带聚类特征）前5行:\")\n",
    "display(seismic_data_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b323235",
   "metadata": {},
   "source": [
    "## 属性间相关性分析 + RF importance（SVR）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa483d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析原始特征的相关性\n",
    "correlated_attribute_groups = analyze_attribute_correlations(\n",
    "    features_df=pca_results[\"features_clean\"],  # 使用PCA结果中的清理后特征\n",
    "    method=\"pearson\",  # 使用Pearson相关系数\n",
    "    corr_threshold=0.85,  # 相关性阈值设为0.85\n",
    "    output_dir=output_dir,  # 输出目录\n",
    "    figsize=(16, 14),  # 图像尺寸\n",
    ")\n",
    "\n",
    "# 输出每个组的特征数量统计\n",
    "group_sizes = [len(group) for group in correlated_attribute_groups]\n",
    "print(f\"\\n相关属性组统计:\")\n",
    "print(f\"  - 总组数: {len(correlated_attribute_groups)}\")\n",
    "print(f\"  - 最大组大小: {max(group_sizes)} 属性\")\n",
    "print(f\"  - 包含多个属性的组数: {sum(1 for size in group_sizes if size > 1)}\")\n",
    "print(f\"  - 平均组大小: {sum(group_sizes) / len(group_sizes):.2f} 属性\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在井点数据上应用随机森林重要性分析\n",
    "# 使用原始井点数据，不使用扩增数据\n",
    "selected_features = analyze_rf_importance_by_group(\n",
    "    well_data=data_H6_2_well_selected,  # 原始井点数据\n",
    "    attribute_groups=correlated_attribute_groups,  # 前面生成的属性组\n",
    "    target_column=\"Thickness of facies(1: Fine sand)\",\n",
    "    top_n=1,  # 每组选择1个最重要的特征\n",
    "    test_size=0.3,\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    output_dir=output_dir,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd838729",
   "metadata": {},
   "source": [
    "## SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型比较输出目录\n",
    "model_comparison_dir = \"svr_models_comparison\"\n",
    "if not os.path.exists(model_comparison_dir):\n",
    "    os.makedirs(model_comparison_dir)\n",
    "\n",
    "# 1. 原始数据 + selected_features + cluster_probs\n",
    "svr_original_probs = build_svr_model(\n",
    "    data=original_well_data_encoded,\n",
    "    selected_features=selected_features,\n",
    "    target_column=\"Thickness of facies(1: Fine sand)\",\n",
    "    use_cluster_probs=False,\n",
    "    use_onehot=False,\n",
    "    output_dir=model_comparison_dir,\n",
    "    filename_prefix=\"original_with_probs\",\n",
    ")\n",
    "\n",
    "# 2. 原始数据 + selected_features + one-hot\n",
    "svr_original_onehot = build_svr_model(\n",
    "    data=original_well_data_encoded,\n",
    "    selected_features=selected_features,\n",
    "    target_column=\"Thickness of facies(1: Fine sand)\",\n",
    "    use_cluster_probs=False,\n",
    "    use_onehot=True,\n",
    "    output_dir=model_comparison_dir,\n",
    "    filename_prefix=\"original_with_onehot\",\n",
    ")\n",
    "\n",
    "# 3. 扩容数据 + selected_features\n",
    "svr_augmented_base = build_svr_model(\n",
    "    data=augmented_well_data_encoded,\n",
    "    selected_features=selected_features,\n",
    "    target_column=\"Thickness of facies(1: Fine sand)\",\n",
    "    use_cluster_probs=False,\n",
    "    use_onehot=False,\n",
    "    output_dir=model_comparison_dir,\n",
    "    filename_prefix=\"augmented_base\",\n",
    ")\n",
    "\n",
    "# 4. 扩容数据 + selected_features + one-hot\n",
    "svr_augmented_onehot = build_svr_model(\n",
    "    data=augmented_well_data_encoded,\n",
    "    selected_features=selected_features,\n",
    "    target_column=\"Thickness of facies(1: Fine sand)\",\n",
    "    use_cluster_probs=False,\n",
    "    use_onehot=True,\n",
    "    output_dir=model_comparison_dir,\n",
    "    filename_prefix=\"augmented_with_onehot\",\n",
    ")\n",
    "\n",
    "# 创建模型比较结果表\n",
    "models = [\n",
    "    {\"name\": \"原始数据\", \"results\": svr_original_probs},\n",
    "    {\"name\": \"原始数据+模式识别\", \"results\": svr_original_onehot},\n",
    "    {\"name\": \"扩容数据\", \"results\": svr_augmented_base},\n",
    "    {\"name\": \"扩容数据+模式识别\", \"results\": svr_augmented_onehot},\n",
    "]\n",
    "\n",
    "# 创建模型比较表\n",
    "comparison_data = []\n",
    "for model in models:\n",
    "    comparison_data.append(\n",
    "        {\n",
    "            \"模型类型\": model[\"name\"],\n",
    "            \"样本数\": model[\"results\"][\"config\"][\"data_size\"],\n",
    "            \"特征数\": model[\"results\"][\"config\"][\"total_features\"],\n",
    "            \"R²\": model[\"results\"][\"metrics\"][\"r2\"],\n",
    "            \"RMSE\": model[\"results\"][\"metrics\"][\"rmse\"],\n",
    "            \"真实为0预测正确率\": model[\"results\"][\"metrics\"][\"true_negative_rate\"],\n",
    "            \"真实非0预测正确率\": model[\"results\"][\"metrics\"][\"true_positive_rate\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df.to_csv(os.path.join(model_comparison_dir, \"svr_models_comparison.csv\"), index=False)\n",
    "print(\"\\nSVR模型性能比较:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用每个模型对全体地震数据进行预测\n",
    "print(\"\\n======== 使用所有模型进行全区域预测 ========\")\n",
    "\n",
    "for model_info in models:\n",
    "    model_name = model_info[\"name\"]\n",
    "    model_results = model_info[\"results\"]\n",
    "\n",
    "    print(f\"\\n==== 使用{model_name}模型进行预测 ====\")\n",
    "    print(f\"模型R²: {model_results['metrics']['r2']:.4f}\")\n",
    "\n",
    "    # 为每个模型创建单独的预测文件名前缀\n",
    "    filename_prefix = f\"model_{model_name.replace('+', '_').replace(' ', '_').lower()}\"\n",
    "\n",
    "    # 进行预测\n",
    "    predictions = predict_with_model(\n",
    "        model_results=model_results,\n",
    "        data=seismic_data_encoded,\n",
    "        coords_columns=[\"X\", \"Y\", \"Z\"],\n",
    "        output_dir=model_comparison_dir,\n",
    "        filename_prefix=filename_prefix,\n",
    "        threshold_zero=0.1,\n",
    "        verbose=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-af",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
