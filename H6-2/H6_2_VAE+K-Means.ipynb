{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c25782a",
   "metadata": {},
   "source": [
    "# VAE + K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52717610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保src目录在Python路径中\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "# 导入模块\n",
    "from src.data_utils import (\n",
    "    extract_seismic_attributes_for_wells,\n",
    "    extract_uniform_seismic_samples,\n",
    "    filter_anomalous_attributes,\n",
    "    filter_outlier_wells,\n",
    "    filter_seismic_by_wells,\n",
    "    identify_attributes,\n",
    "    parse_petrel_file,\n",
    "    preprocess_features,\n",
    ")\n",
    "from src.feature_selection import select_best_features\n",
    "from src.gmm_clustering import evaluate_gmm_clusters, perform_gmm_clustering\n",
    "from src.pca_analysis import perform_pca_analysis\n",
    "from src.visualization import visualize_attribute_map, visualize_gmm_clustering, visualize_pca_clustering\n",
    "\n",
    "data_dir = \"..\\\\data\"\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"  # 黑体 SimHei 支持中文\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474aaecf",
   "metadata": {},
   "source": [
    "## 导入地震数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deef7e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_seismic_attr = parse_petrel_file(os.path.join(data_dir, \"H6-2_attr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac4b168",
   "metadata": {},
   "source": [
    "## 导入井点位置\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c828d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_well_position = pd.read_excel(os.path.join(data_dir, \"well_without_attr.xlsx\"))\n",
    "\n",
    "# 选择对应层位的行，丢弃砂厚为 NaN 的行\n",
    "data_well_purpose_surface_position = (\n",
    "    data_well_position[data_well_position[\"Surface\"] == \"H6-2\"]\n",
    "    .replace(-999, np.nan)  # 将-999替换为NaN\n",
    "    .dropna(subset=[\"Sand Thickness\"])  # 丢弃砂厚为NaN的行\n",
    "    .reset_index(drop=True)  # 重置索引\n",
    ")\n",
    "data_well_purpose_surface_position.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdeacfb",
   "metadata": {},
   "source": [
    "## 筛除离群井\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe88af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选离群井\n",
    "data_well_purpose_surface_filtered = filter_outlier_wells(data_well_purpose_surface_position, method=\"iqr\")\n",
    "\n",
    "# 显示筛选前后的井点数量\n",
    "print(f\"筛选前井点数量: {len(data_well_purpose_surface_position)}\")\n",
    "print(f\"筛选后井点数量: {len(data_well_purpose_surface_filtered)}\")\n",
    "\n",
    "# 可视化筛选前后的井点分布\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 计算坐标范围（使用所有井点的数据来确定范围）\n",
    "x_min = data_well_purpose_surface_position[\"X\"].min()\n",
    "x_max = data_well_purpose_surface_position[\"X\"].max()\n",
    "y_min = data_well_purpose_surface_position[\"Y\"].min()\n",
    "y_max = data_well_purpose_surface_position[\"Y\"].max()\n",
    "\n",
    "# 可选：添加一些边距使图更美观\n",
    "margin = 0.05  # 5%的边距\n",
    "x_range = x_max - x_min\n",
    "y_range = y_max - y_min\n",
    "x_min -= x_range * margin\n",
    "x_max += x_range * margin\n",
    "y_min -= y_range * margin\n",
    "y_max += y_range * margin\n",
    "\n",
    "# 绘制筛选前的井点分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(data_well_purpose_surface_position[\"X\"], data_well_purpose_surface_position[\"Y\"], c=\"blue\")\n",
    "plt.title(\"筛选前井点分布\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "# 绘制筛选后的井点分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(data_well_purpose_surface_filtered[\"X\"], data_well_purpose_surface_filtered[\"Y\"], c=\"red\")\n",
    "plt.title(\"筛选后井点分布\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"well_filtering_comparison.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417bfe2",
   "metadata": {},
   "source": [
    "## 处理属性缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425febc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先获取地震属性列表\n",
    "attribute_names, _ = identify_attributes(os.path.join(data_dir, \"H6-2_attr\"))\n",
    "\n",
    "# 使用preprocess_features处理地震数据\n",
    "processed_seismic, attr_stats = preprocess_features(\n",
    "    data=data_seismic_attr,\n",
    "    attribute_columns=attribute_names,\n",
    "    missing_values=[-999],\n",
    "    missing_threshold=0.6,  # 缺失值超过60%的列将被删除\n",
    "    outlier_method=\"iqr\",\n",
    "    outlier_threshold=1.5,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# 提取筛选后的属性\n",
    "attribute_names_filtered = [col for col in processed_seismic.columns]\n",
    "\n",
    "# 将处理后的属性数据与原始坐标数据合并\n",
    "processed_seismic_full = data_seismic_attr[[\"X\", \"Y\"]].copy()\n",
    "for col in processed_seismic.columns:\n",
    "    processed_seismic_full[col] = processed_seismic[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea1706",
   "metadata": {},
   "source": [
    "## 根据井点分布，缩小工区范围\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 限制工区范围\n",
    "seismic_attr_filtered, area_bounds = filter_seismic_by_wells(\n",
    "    seismic_data=processed_seismic_full,\n",
    "    well_data=data_well_purpose_surface_filtered,\n",
    "    expansion_factor=1.5,  # 扩展50%\n",
    "    plot=True,\n",
    "    output_dir=output_dir,\n",
    ")\n",
    "\n",
    "# 后续可以直接使用area_bounds中的边界信息\n",
    "print(\"区域边界信息:\")\n",
    "for key, value in area_bounds.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098f98d",
   "metadata": {},
   "source": [
    "## 提取井点处地震属性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为筛选前的井点提取地震属性\n",
    "well_attr = extract_seismic_attributes_for_wells(\n",
    "    well_data=data_well_purpose_surface_position,\n",
    "    seismic_data=processed_seismic_full,\n",
    "    max_distance=50,\n",
    "    num_points=5,\n",
    ")\n",
    "\n",
    "# 为筛选后的井点提取地震属性\n",
    "well_attr_filtered = extract_seismic_attributes_for_wells(\n",
    "    well_data=data_well_purpose_surface_filtered, seismic_data=processed_seismic_full, max_distance=50, num_points=5\n",
    ")\n",
    "\n",
    "# 保存处理结果\n",
    "well_attr.to_excel(os.path.join(data_dir, \"wells_attr.xlsx\"), index=False)\n",
    "print(\"筛选前井点的地震属性已保存到 wells_attr.xlsx\")\n",
    "well_attr_filtered.to_excel(os.path.join(data_dir, \"wells_attr_filtered.xlsx\"), index=False)\n",
    "print(\"筛选后井点的地震属性已保存到 wells_attr_filtered.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97531786",
   "metadata": {},
   "source": [
    "## 生成统计摘要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebefe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出质量良好的属性\n",
    "good_attributes, anomalous_attributes, attribute_stats = filter_anomalous_attributes(\n",
    "    seismic_data=seismic_attr_filtered,\n",
    "    well_data=well_attr_filtered,\n",
    "    common_attributes=attribute_names_filtered,\n",
    "    ratio_threshold=5.0,  # 均值比值阈值\n",
    "    range_ratio_threshold=10.0,  # 数值范围比值阈值\n",
    "    std_ratio_threshold=10.0,  # 标准差比值阈值\n",
    "    output_dir=None,  # 输出图表目录\n",
    "    verbose=True,  # 打印详细信息\n",
    ")\n",
    "\n",
    "print(\"\\n筛选后保留的质量良好属性:\")\n",
    "for attr in good_attributes:\n",
    "    print(f\"- {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f45570c",
   "metadata": {},
   "source": [
    "## VAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4793c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational AutoEncoder (VAE) 用于地震属性向量的降维\n",
    "\n",
    "    该模型使用MLP结构的编码器和解码器，适用于地震属性数据的无监督学习和聚类前的特征提取。\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): 输入特征维度（地震属性数量）\n",
    "        latent_dim (int): 隐变量维度\n",
    "        encoder_dims (List[int], optional): 编码器各层维度，默认为 [64, 32, 16]\n",
    "        decoder_dims (List[int], optional): 解码器各层维度，默认为 [16, 32, 64]\n",
    "        activation (str): 激活函数类型，默认为 'relu'\n",
    "        dropout_rate (float): Dropout比率，默认为 0.1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        latent_dim: int = 8,\n",
    "        encoder_dims: Optional[List[int]] = None,\n",
    "        decoder_dims: Optional[List[int]] = None,\n",
    "        activation: str = \"relu\",\n",
    "        dropout_rate: float = 0.1,\n",
    "    ):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # 默认编码器和解码器维度\n",
    "        if encoder_dims is None:\n",
    "            encoder_dims = [64, 32, 16]\n",
    "        if decoder_dims is None:\n",
    "            decoder_dims = [16, 32, 64]\n",
    "\n",
    "        self.encoder_dims = encoder_dims\n",
    "        self.decoder_dims = decoder_dims\n",
    "\n",
    "        # 选择激活函数\n",
    "        self.activation = self._get_activation_function(activation)\n",
    "\n",
    "        # 构建编码器\n",
    "        self.encoder = self._build_encoder()\n",
    "\n",
    "        # 构建解码器\n",
    "        self.decoder = self._build_decoder()\n",
    "\n",
    "        # 初始化权重\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _get_activation_function(self, activation: str) -> nn.Module:\n",
    "        \"\"\"获取激活函数\"\"\"\n",
    "        activation_dict = {\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"leaky_relu\": nn.LeakyReLU(0.2),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"sigmoid\": nn.Sigmoid(),\n",
    "            \"elu\": nn.ELU(),\n",
    "            \"gelu\": nn.GELU(),\n",
    "        }\n",
    "\n",
    "        if activation.lower() not in activation_dict:\n",
    "            raise ValueError(f\"不支持的激活函数: {activation}. 支持的函数: {list(activation_dict.keys())}\")\n",
    "\n",
    "        return activation_dict[activation.lower()]\n",
    "\n",
    "    def _build_encoder(self) -> nn.ModuleList:\n",
    "        \"\"\"构建编码器网络\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        # 输入层到第一个隐藏层\n",
    "        prev_dim = self.input_dim\n",
    "\n",
    "        # 中间隐藏层\n",
    "        for dim in self.encoder_dims:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "            layers.append(self.activation)\n",
    "            if self.dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(self.dropout_rate))\n",
    "            prev_dim = dim\n",
    "\n",
    "        # 输出层：均值和方差\n",
    "        self.fc_mu = nn.Linear(prev_dim, self.latent_dim)\n",
    "        self.fc_logvar = nn.Linear(prev_dim, self.latent_dim)\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def _build_decoder(self) -> nn.ModuleList:\n",
    "        \"\"\"构建解码器网络\"\"\"\n",
    "        layers = nn.ModuleList()\n",
    "\n",
    "        # 从隐变量开始\n",
    "        prev_dim = self.latent_dim\n",
    "\n",
    "        # 中间隐藏层\n",
    "        for dim in self.decoder_dims:\n",
    "            layers.append(nn.Linear(prev_dim, dim))\n",
    "            layers.append(self.activation)\n",
    "            if self.dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(self.dropout_rate))\n",
    "            prev_dim = dim\n",
    "\n",
    "        # 输出层（重构）\n",
    "        layers.append(nn.Linear(prev_dim, self.input_dim))\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"初始化网络权重\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        编码输入数据\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入数据 [batch_size, input_dim]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: (mu, logvar, z)\n",
    "                - mu: 均值向量 [batch_size, latent_dim]\n",
    "                - logvar: 对数方差向量 [batch_size, latent_dim]\n",
    "                - z: 采样的隐变量 [batch_size, latent_dim]\n",
    "        \"\"\"\n",
    "        # 通过编码器传播\n",
    "        h = x\n",
    "        for layer in self.encoder:\n",
    "            h = layer(h)\n",
    "\n",
    "        # 计算均值和对数方差\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "\n",
    "        # 重参数化\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        return mu, logvar, z\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        重参数化技巧：从正态分布采样隐变量\n",
    "\n",
    "        Args:\n",
    "            mu (torch.Tensor): 均值向量 [batch_size, latent_dim]\n",
    "            logvar (torch.Tensor): 对数方差向量 [batch_size, latent_dim]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 采样的隐变量 z [batch_size, latent_dim]\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            # 训练时进行采样\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return mu + eps * std\n",
    "        else:\n",
    "            # 推理时直接返回均值\n",
    "            return mu\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        解码隐变量\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): 隐变量 [batch_size, latent_dim]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 重构的数据 [batch_size, input_dim]\n",
    "        \"\"\"\n",
    "        h = z\n",
    "        for layer in self.decoder:\n",
    "            h = layer(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入数据 [batch_size, input_dim]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: (x_hat, mu, logvar)\n",
    "                - x_hat: 重构数据 [batch_size, input_dim]\n",
    "                - mu: 均值向量 [batch_size, latent_dim]\n",
    "                - logvar: 对数方差向量 [batch_size, latent_dim]\n",
    "        \"\"\"\n",
    "        # 编码\n",
    "        mu, logvar, z = self.encode(x)\n",
    "\n",
    "        # 解码\n",
    "        x_hat = self.decode(z)\n",
    "\n",
    "        return x_hat, mu, logvar\n",
    "\n",
    "    def get_latent_representation(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        获取输入数据的隐变量表示（用于聚类）\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 输入数据 [batch_size, input_dim]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 隐变量 [batch_size, latent_dim]\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            mu, logvar, z = self.encode(x)\n",
    "            return z\n",
    "\n",
    "    def generate(self, num_samples: int, device: torch.device = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        从隐空间生成新样本\n",
    "\n",
    "        Args:\n",
    "            num_samples (int): 生成样本数量\n",
    "            device (torch.device, optional): 设备\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 生成的样本 [num_samples, input_dim]\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = next(self.parameters()).device\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # 从标准正态分布采样\n",
    "            z = torch.randn(num_samples, self.latent_dim, device=device)\n",
    "            # 解码生成样本\n",
    "            generated = self.decode(z)\n",
    "\n",
    "        return generated\n",
    "\n",
    "    def get_model_info(self) -> dict:\n",
    "        \"\"\"\n",
    "        获取模型结构信息\n",
    "\n",
    "        Returns:\n",
    "            dict: 模型信息字典\n",
    "        \"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "        return {\n",
    "            \"input_dim\": self.input_dim,\n",
    "            \"latent_dim\": self.latent_dim,\n",
    "            \"encoder_dims\": self.encoder_dims,\n",
    "            \"decoder_dims\": self.decoder_dims,\n",
    "            \"total_parameters\": total_params,\n",
    "            \"trainable_parameters\": trainable_params,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "        }\n",
    "\n",
    "\n",
    "def vae_loss_function(\n",
    "    x_hat: torch.Tensor, x: torch.Tensor, mu: torch.Tensor, logvar: torch.Tensor, beta: float = 1.0\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    VAE损失函数\n",
    "\n",
    "    Args:\n",
    "        x_hat (torch.Tensor): 重构数据\n",
    "        x (torch.Tensor): 原始数据\n",
    "        mu (torch.Tensor): 均值向量\n",
    "        logvar (torch.Tensor): 对数方差向量\n",
    "        beta (float): KL散度权重（β-VAE）\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: (total_loss, recon_loss, kl_loss)\n",
    "    \"\"\"\n",
    "    # 重构损失（MSE）\n",
    "    recon_loss = F.mse_loss(x_hat, x, reduction=\"mean\")\n",
    "\n",
    "    # KL散度损失\n",
    "    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # 总损失\n",
    "    total_loss = recon_loss + beta * kl_loss\n",
    "\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "\n",
    "def train_vae(model, data, epochs=100, batch_size=512, lr=1e-3, beta=1.0, verbose=True):\n",
    "    \"\"\"\n",
    "    训练VAE模型\n",
    "\n",
    "    Args:\n",
    "        model: VAE模型\n",
    "        data: 训练数据\n",
    "        epochs: 训练轮数\n",
    "        batch_size: 批次大小\n",
    "        lr: 学习率\n",
    "        beta: KL散度权重\n",
    "        verbose: 是否打印训练信息\n",
    "\n",
    "    Returns:\n",
    "        训练损失历史\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "\n",
    "    # 创建数据加载器\n",
    "    dataset = torch.utils.data.TensorDataset(data)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    loss_history = {\"total\": [], \"recon\": [], \"kl\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_total_loss = 0\n",
    "        epoch_recon_loss = 0\n",
    "        epoch_kl_loss = 0\n",
    "\n",
    "        for batch_idx, (batch_data,) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播\n",
    "            x_hat, mu, logvar = model(batch_data)\n",
    "\n",
    "            # 计算损失\n",
    "            total_loss, recon_loss, kl_loss = vae_loss_function(x_hat, batch_data, mu, logvar, beta)\n",
    "\n",
    "            # 反向传播\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_total_loss += total_loss.item()\n",
    "            epoch_recon_loss += recon_loss.item()\n",
    "            epoch_kl_loss += kl_loss.item()\n",
    "\n",
    "        # 计算平均损失\n",
    "        num_batches = len(dataloader)\n",
    "        avg_total_loss = epoch_total_loss / num_batches\n",
    "        avg_recon_loss = epoch_recon_loss / num_batches\n",
    "        avg_kl_loss = epoch_kl_loss / num_batches\n",
    "\n",
    "        loss_history[\"total\"].append(avg_total_loss)\n",
    "        loss_history[\"recon\"].append(avg_recon_loss)\n",
    "        loss_history[\"kl\"].append(avg_kl_loss)\n",
    "\n",
    "        if verbose and (epoch + 1) % 10 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{epochs}] - Total Loss: {avg_total_loss:.4f}, \"\n",
    "                f\"Recon Loss: {avg_recon_loss:.4f}, KL Loss: {avg_kl_loss:.4f}\"\n",
    "            )\n",
    "\n",
    "    return loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 准备地震属性数据\n",
    "seismic_attrs = processed_seismic_full[good_attributes].copy()\n",
    "print(f\"使用的属性数量: {len(good_attributes)}\")\n",
    "print(f\"地震样本数量: {len(seismic_attrs)}\")\n",
    "\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "seismic_attrs_scaled = scaler.fit_transform(seismic_attrs)\n",
    "seismic_attrs_tensor = torch.FloatTensor(seismic_attrs_scaled).to(device)\n",
    "\n",
    "print(f\"数据形状: {seismic_attrs_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b22ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建VAE模型\n",
    "input_dim = len(good_attributes)\n",
    "latent_dim = 8  # 隐变量维度，可以调整\n",
    "\n",
    "# 根据输入维度自适应调整网络结构\n",
    "if input_dim <= 16:\n",
    "    encoder_dims = [32, 16]\n",
    "    decoder_dims = [16, 32]\n",
    "elif input_dim <= 32:\n",
    "    encoder_dims = [64, 32, 16]\n",
    "    decoder_dims = [16, 32, 64]\n",
    "else:\n",
    "    encoder_dims = [128, 64, 32, 16]\n",
    "    decoder_dims = [16, 32, 64, 128]\n",
    "\n",
    "vae_model = VAE(\n",
    "    input_dim=input_dim,\n",
    "    latent_dim=latent_dim,\n",
    "    encoder_dims=encoder_dims,\n",
    "    decoder_dims=decoder_dims,\n",
    "    activation=\"relu\",\n",
    "    dropout_rate=0.1,\n",
    ").to(device)\n",
    "\n",
    "# 打印模型信息\n",
    "model_info = vae_model.get_model_info()\n",
    "print(\"VAE模型信息:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faaf3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练VAE模型\n",
    "print(\"开始训练VAE模型...\")\n",
    "loss_history = train_vae(\n",
    "    model=vae_model, data=seismic_attrs_tensor, epochs=100, batch_size=512, lr=1e-3, beta=1.0, verbose=True\n",
    ")\n",
    "print(\"VAE训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练损失\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(loss_history[\"total\"])\n",
    "plt.title(\"总损失\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(loss_history[\"recon\"])\n",
    "plt.title(\"重构损失\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(loss_history[\"kl\"])\n",
    "plt.title(\"KL散度损失\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"vae_training_loss.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d80e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取隐变量表示\n",
    "print(\"提取隐变量表示...\")\n",
    "vae_model.eval()\n",
    "with torch.no_grad():\n",
    "    latent_representations = vae_model.get_latent_representation(seismic_attrs_tensor)\n",
    "    latent_numpy = latent_representations.cpu().numpy()\n",
    "\n",
    "print(f\"隐变量形状: {latent_numpy.shape}\")\n",
    "\n",
    "# 可视化隐变量分布（前两个维度）\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(latent_numpy[:, 0], latent_numpy[:, 1], alpha=0.6, s=1)\n",
    "plt.xlabel(\"隐变量维度 1\")\n",
    "plt.ylabel(\"隐变量维度 2\")\n",
    "plt.title(\"隐变量空间分布\")\n",
    "plt.grid(True)\n",
    "\n",
    "# 隐变量各维度的分布\n",
    "plt.subplot(1, 2, 2)\n",
    "for i in range(min(latent_dim, 4)):  # 最多显示前4个维度\n",
    "    plt.hist(latent_numpy[:, i], bins=50, alpha=0.7, label=f\"维度 {i + 1}\")\n",
    "plt.xlabel(\"值\")\n",
    "plt.ylabel(\"频率\")\n",
    "plt.title(\"隐变量各维度分布\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"vae_latent_distribution.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582413e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means聚类函数\n",
    "def perform_kmeans_clustering(data, max_clusters=10, random_state=42):\n",
    "    \"\"\"\n",
    "    执行K-means聚类并评估最优聚类数\n",
    "\n",
    "    Args:\n",
    "        data: 聚类数据\n",
    "        max_clusters: 最大聚类数\n",
    "        random_state: 随机种子\n",
    "\n",
    "    Returns:\n",
    "        最优聚类结果和评估指标\n",
    "    \"\"\"\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    print(\"评估不同聚类数的效果...\")\n",
    "    for n_clusters in cluster_range:\n",
    "        # K-means聚类\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "\n",
    "        # 计算评估指标\n",
    "        inertia = kmeans.inertia_\n",
    "        silhouette_avg = silhouette_score(data, cluster_labels)\n",
    "\n",
    "        inertias.append(inertia)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "        results[n_clusters] = {\n",
    "            \"model\": kmeans,\n",
    "            \"labels\": cluster_labels,\n",
    "            \"inertia\": inertia,\n",
    "            \"silhouette_score\": silhouette_avg,\n",
    "        }\n",
    "\n",
    "        print(f\"聚类数 {n_clusters}: 惯性={inertia:.2f}, 轮廓系数={silhouette_avg:.3f}\")\n",
    "\n",
    "    # 寻找最优聚类数（基于轮廓系数）\n",
    "    best_n_clusters = cluster_range[np.argmax(silhouette_scores)]\n",
    "    print(f\"\\n基于轮廓系数的最优聚类数: {best_n_clusters}\")\n",
    "\n",
    "    return results, inertias, silhouette_scores, best_n_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对隐变量进行K-means聚类\n",
    "clustering_results, inertias, silhouette_scores, best_n_clusters = perform_kmeans_clustering(\n",
    "    data=latent_numpy, max_clusters=3, random_state=42\n",
    ")\n",
    "\n",
    "# 可视化聚类评估指标\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 肘部法则图\n",
    "plt.subplot(1, 3, 1)\n",
    "cluster_range = range(2, len(inertias) + 2)\n",
    "plt.plot(cluster_range, inertias, \"bo-\")\n",
    "plt.xlabel(\"聚类数\")\n",
    "plt.ylabel(\"惯性 (Within-cluster Sum of Squares)\")\n",
    "plt.title(\"肘部法则\")\n",
    "plt.grid(True)\n",
    "\n",
    "# 轮廓系数图\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(cluster_range, silhouette_scores, \"ro-\")\n",
    "plt.xlabel(\"聚类数\")\n",
    "plt.ylabel(\"轮廓系数\")\n",
    "plt.title(\"轮廓系数评估\")\n",
    "plt.axvline(x=best_n_clusters, color=\"g\", linestyle=\"--\", label=f\"最优聚类数: {best_n_clusters}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 聚类结果可视化（使用最优聚类数）\n",
    "plt.subplot(1, 3, 3)\n",
    "best_labels = clustering_results[best_n_clusters][\"labels\"]\n",
    "scatter = plt.scatter(latent_numpy[:, 0], latent_numpy[:, 1], c=best_labels, cmap=\"tab10\", alpha=0.6, s=1)\n",
    "plt.xlabel(\"隐变量维度 1\")\n",
    "plt.ylabel(\"隐变量维度 2\")\n",
    "plt.title(f\"K-means聚类结果 (k={best_n_clusters})\")\n",
    "plt.colorbar(scatter)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"kmeans_evaluation.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取最终聚类结果\n",
    "final_cluster_labels = clustering_results[best_n_clusters][\"labels\"]\n",
    "final_silhouette = clustering_results[best_n_clusters][\"silhouette_score\"]\n",
    "\n",
    "print(f\"最终聚类配置:\")\n",
    "print(f\"  聚类数: {best_n_clusters}\")\n",
    "print(f\"  轮廓系数: {final_silhouette:.4f}\")\n",
    "print(f\"  样本总数: {len(final_cluster_labels)}\")\n",
    "\n",
    "# 统计各聚类的样本数量\n",
    "unique_labels, counts = np.unique(final_cluster_labels, return_counts=True)\n",
    "print(f\"\\n各聚类样本数量:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"  聚类 {label}: {count} 个样本 ({count / len(final_cluster_labels) * 100:.1f}%)\")\n",
    "\n",
    "# 将聚类结果添加到地震数据中\n",
    "seismic_clustered = processed_seismic_full.copy()\n",
    "seismic_clustered[\"Cluster\"] = final_cluster_labels\n",
    "\n",
    "# 保存聚类结果\n",
    "seismic_clustered.to_csv(os.path.join(output_dir, \"seismic_vae_kmeans_clusters.csv\"), index=False)\n",
    "print(f\"\\n聚类结果已保存到: {os.path.join(output_dir, 'seismic_vae_kmeans_clusters.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203abc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空间聚类结果可视化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 主要的聚类空间分布图\n",
    "plt.subplot(2, 3, (1, 4))\n",
    "scatter = plt.scatter(\n",
    "    seismic_clustered[\"X\"], seismic_clustered[\"Y\"], c=seismic_clustered[\"Cluster\"], cmap=\"tab10\", s=10, alpha=0.7\n",
    ")\n",
    "plt.colorbar(scatter, label=\"聚类标签\")\n",
    "plt.xlabel(\"X坐标\")\n",
    "plt.ylabel(\"Y坐标\")\n",
    "plt.title(f\"VAE+K-means聚类空间分布 (k={best_n_clusters})\")\n",
    "\n",
    "# 各个聚类的单独分布\n",
    "for i, cluster_id in enumerate(unique_labels[:4]):  # 最多显示前4个聚类\n",
    "    plt.subplot(2, 3, i + 2)\n",
    "    cluster_data = seismic_clustered[seismic_clustered[\"Cluster\"] == cluster_id]\n",
    "    plt.scatter(cluster_data[\"X\"], cluster_data[\"Y\"], s=1, alpha=0.7)\n",
    "    plt.title(f\"聚类 {cluster_id} ({len(cluster_data)} 样本)\")\n",
    "    plt.xlabel(\"X坐标\")\n",
    "    plt.ylabel(\"Y坐标\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"vae_kmeans_spatial_clusters.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析各聚类的属性特征\n",
    "def analyze_cluster_characteristics(data, cluster_labels, attributes, n_clusters):\n",
    "    \"\"\"\n",
    "    分析各聚类的属性特征\n",
    "    \"\"\"\n",
    "    print(\"各聚类属性特征分析:\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    cluster_stats = {}\n",
    "\n",
    "    for cluster_id in range(n_clusters):\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "        cluster_data = data[cluster_mask]\n",
    "\n",
    "        print(f\"\\n聚类 {cluster_id} (样本数: {np.sum(cluster_mask)}):\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # 计算每个属性的统计信息\n",
    "        stats = {}\n",
    "        for attr in attributes:\n",
    "            attr_values = cluster_data[attr]\n",
    "            stats[attr] = {\n",
    "                \"mean\": attr_values.mean(),\n",
    "                \"std\": attr_values.std(),\n",
    "                \"min\": attr_values.min(),\n",
    "                \"max\": attr_values.max(),\n",
    "            }\n",
    "            print(f\"  {attr}: 均值={stats[attr]['mean']:.3f}, 标准差={stats[attr]['std']:.3f}\")\n",
    "\n",
    "        cluster_stats[cluster_id] = stats\n",
    "\n",
    "    return cluster_stats\n",
    "\n",
    "\n",
    "# 创建聚类特征热力图\n",
    "def plot_cluster_heatmap(cluster_stats, attributes, n_clusters):\n",
    "    \"\"\"\n",
    "    绘制各聚类属性特征的热力图\n",
    "    \"\"\"\n",
    "    # 准备热力图数据\n",
    "    heatmap_data = np.zeros((n_clusters, len(attributes)))\n",
    "\n",
    "    for i, cluster_id in enumerate(range(n_clusters)):\n",
    "        for j, attr in enumerate(attributes):\n",
    "            heatmap_data[i, j] = cluster_stats[cluster_id][attr][\"mean\"]\n",
    "\n",
    "    # 对每个属性进行标准化以便比较\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    heatmap_data_normalized = scaler.fit_transform(heatmap_data.T).T\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.heatmap(\n",
    "        heatmap_data_normalized,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        xticklabels=attributes,\n",
    "        yticklabels=[f\"聚类 {i}\" for i in range(n_clusters)],\n",
    "        cmap=\"RdYlBu_r\",\n",
    "        center=0,\n",
    "    )\n",
    "    plt.title(\"各聚类属性特征热力图 (标准化后)\")\n",
    "    plt.xlabel(\"地震属性\")\n",
    "    plt.ylabel(\"聚类\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"cluster_characteristics_heatmap.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析聚类特征\n",
    "cluster_characteristics = analyze_cluster_characteristics(\n",
    "    data=seismic_clustered, cluster_labels=final_cluster_labels, attributes=good_attributes, n_clusters=best_n_clusters\n",
    ")\n",
    "\n",
    "# 绘制聚类特征热力图\n",
    "plot_cluster_heatmap(cluster_characteristics, good_attributes, best_n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e8ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存VAE模型和聚类结果\n",
    "print(\"保存模型和结果...\")\n",
    "\n",
    "# 保存VAE模型\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": vae_model.state_dict(),\n",
    "        \"model_config\": {\n",
    "            \"input_dim\": input_dim,\n",
    "            \"latent_dim\": latent_dim,\n",
    "            \"encoder_dims\": encoder_dims,\n",
    "            \"decoder_dims\": decoder_dims,\n",
    "        },\n",
    "        \"scaler_params\": {\n",
    "            \"mean\": scaler.mean_.tolist(),  # 转换为Python list\n",
    "            \"scale\": scaler.scale_.tolist(),  # 转换为Python list\n",
    "        },\n",
    "        \"good_attributes\": good_attributes,\n",
    "        \"best_n_clusters\": best_n_clusters,\n",
    "    },\n",
    "    os.path.join(output_dir, \"vae_model.pth\"),\n",
    ")\n",
    "\n",
    "# 保存聚类模型\n",
    "import joblib\n",
    "\n",
    "joblib.dump(clustering_results[best_n_clusters][\"model\"], os.path.join(output_dir, \"kmeans_model.pkl\"))\n",
    "\n",
    "\n",
    "# 定义类型转换函数\n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"\n",
    "    递归转换NumPy类型为Python原生类型\n",
    "    \"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: convert_numpy_types(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "# 保存完整结果摘要\n",
    "results_summary = {\n",
    "    \"vae_config\": model_info,\n",
    "    \"best_n_clusters\": int(best_n_clusters),  # 确保是Python int\n",
    "    \"silhouette_score\": float(final_silhouette),  # 确保是Python float\n",
    "    \"cluster_sizes\": dict(\n",
    "        zip([int(x) for x in unique_labels.tolist()], [int(x) for x in counts.tolist()])\n",
    "    ),  # 转换为Python int\n",
    "    \"good_attributes\": good_attributes,\n",
    "    \"total_samples\": int(len(final_cluster_labels)),  # 确保是Python int\n",
    "}\n",
    "\n",
    "# 应用类型转换\n",
    "results_summary = convert_numpy_types(results_summary)\n",
    "\n",
    "import json\n",
    "\n",
    "with open(os.path.join(output_dir, \"vae_kmeans_results_summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"保存完成!\")\n",
    "print(f\"模型文件: {os.path.join(output_dir, 'vae_model.pth')}\")\n",
    "print(f\"聚类模型: {os.path.join(output_dir, 'kmeans_model.pkl')}\")\n",
    "print(f\"结果摘要: {os.path.join(output_dir, 'vae_kmeans_results_summary.json')}\")\n",
    "print(f\"聚类数据: {os.path.join(output_dir, 'seismic_vae_kmeans_clusters.csv')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-af",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
